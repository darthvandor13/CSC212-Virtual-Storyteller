<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: t5.t5_helper.T5Helper Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacet5.html">t5</a></li><li class="navelem"><a class="el" href="namespacet5_1_1t5__helper.html">t5_helper</a></li><li class="navelem"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html">T5Helper</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="classt5_1_1t5__helper_1_1T5Helper-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">t5.t5_helper.T5Helper Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a517cd37b483b36cc7b3e98ddc94c3c39"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#a517cd37b483b36cc7b3e98ddc94c3c39">get_onnx_path</a> (str output_dir, str model_name_or_path, str suffix=&quot;&quot;, bool new_folder=False)</td></tr>
<tr class="separator:a517cd37b483b36cc7b3e98ddc94c3c39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc0df67f16e2e80ba53124209266217e"><td class="memItemLeft" align="right" valign="top">dict[str, torch.nn.Module]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#adc0df67f16e2e80ba53124209266217e">load_model</a> (str model_name_or_path, str cache_dir, torch.device device, bool merge_encoder_and_decoder_init=True, str model_type=&quot;t5&quot;, str state_dict_path=&quot;&quot;)</td></tr>
<tr class="separator:adc0df67f16e2e80ba53124209266217e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace3b238129c093b23edc8542c6f9d32d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#ace3b238129c093b23edc8542c6f9d32d">export_onnx</a> (<a class="el" href="classt5_1_1t5__encoder_1_1T5Encoder.html">T5Encoder</a>|<a class="el" href="classt5_1_1t5__decoder_1_1T5Decoder.html">T5Decoder</a>|<a class="el" href="classt5_1_1t5__decoder_1_1T5DecoderInit.html">T5DecoderInit</a>|<a class="el" href="classt5_1_1t5__encoder__decoder__init_1_1T5EncoderDecoderInit.html">T5EncoderDecoderInit</a> model, torch.device device, str onnx_model_path, bool verbose=True, bool use_external_data_format=False, bool use_decoder_input_ids=True, bool use_int32_inputs=False)</td></tr>
<tr class="separator:ace3b238129c093b23edc8542c6f9d32d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf90c68b230106a047302d24ba3537aa"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#aaf90c68b230106a047302d24ba3537aa">auto_mixed_precision</a> (OnnxModel onnx_model, list[str] op_block_list=[# noqa:B006 &quot;SimplifiedLayerNormalization&quot;, &quot;SkipSimplifiedLayerNormalization&quot;, &quot;Relu&quot;, &quot;Add&quot;,])</td></tr>
<tr class="separator:aaf90c68b230106a047302d24ba3537aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6da5521c916307b55443d6ff0525303d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#a6da5521c916307b55443d6ff0525303d">optimize_onnx</a> (str onnx_model_path, str optimized_model_path, bool is_float16, int num_attention_heads, int hidden_size, bool use_external_data_format=False, bool <a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#aaf90c68b230106a047302d24ba3537aa">auto_mixed_precision</a>=True, bool use_gpu=False)</td></tr>
<tr class="separator:a6da5521c916307b55443d6ff0525303d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26ec45464245e43fc3c8c80f3d143865"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#a26ec45464245e43fc3c8c80f3d143865">verify_onnx</a> (<a class="el" href="classt5_1_1t5__encoder_1_1T5Encoder.html">T5Encoder</a>|<a class="el" href="classt5_1_1t5__decoder_1_1T5Decoder.html">T5Decoder</a>|<a class="el" href="classt5_1_1t5__decoder_1_1T5DecoderInit.html">T5DecoderInit</a>|<a class="el" href="classt5_1_1t5__encoder__decoder__init_1_1T5EncoderDecoderInit.html">T5EncoderDecoderInit</a> model, InferenceSession ort_session, torch.device device, bool use_int32_inputs)</td></tr>
<tr class="separator:a26ec45464245e43fc3c8c80f3d143865"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a517cd37b483b36cc7b3e98ddc94c3c39"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#a517cd37b483b36cc7b3e98ddc94c3c39">get_onnx_path</a> (str output_dir, str model_name_or_path, str suffix=&quot;&quot;, bool new_folder=False)</td></tr>
<tr class="separator:a517cd37b483b36cc7b3e98ddc94c3c39"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc0df67f16e2e80ba53124209266217e"><td class="memItemLeft" align="right" valign="top">dict[str, torch.nn.Module]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#adc0df67f16e2e80ba53124209266217e">load_model</a> (str model_name_or_path, str cache_dir, torch.device device, bool merge_encoder_and_decoder_init=True, str model_type=&quot;t5&quot;, str state_dict_path=&quot;&quot;)</td></tr>
<tr class="separator:adc0df67f16e2e80ba53124209266217e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace3b238129c093b23edc8542c6f9d32d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#ace3b238129c093b23edc8542c6f9d32d">export_onnx</a> (<a class="el" href="classt5_1_1t5__encoder_1_1T5Encoder.html">T5Encoder</a>|<a class="el" href="classt5_1_1t5__decoder_1_1T5Decoder.html">T5Decoder</a>|<a class="el" href="classt5_1_1t5__decoder_1_1T5DecoderInit.html">T5DecoderInit</a>|<a class="el" href="classt5_1_1t5__encoder__decoder__init_1_1T5EncoderDecoderInit.html">T5EncoderDecoderInit</a> model, torch.device device, str onnx_model_path, bool verbose=True, bool use_external_data_format=False, bool use_decoder_input_ids=True, bool use_int32_inputs=False)</td></tr>
<tr class="separator:ace3b238129c093b23edc8542c6f9d32d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf90c68b230106a047302d24ba3537aa"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#aaf90c68b230106a047302d24ba3537aa">auto_mixed_precision</a> (OnnxModel onnx_model, list[str] op_block_list=[# noqa:B006 &quot;SimplifiedLayerNormalization&quot;, &quot;SkipSimplifiedLayerNormalization&quot;, &quot;Relu&quot;, &quot;Add&quot;,])</td></tr>
<tr class="separator:aaf90c68b230106a047302d24ba3537aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6da5521c916307b55443d6ff0525303d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#a6da5521c916307b55443d6ff0525303d">optimize_onnx</a> (str onnx_model_path, str optimized_model_path, bool is_float16, int num_attention_heads, int hidden_size, bool use_external_data_format=False, bool <a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#aaf90c68b230106a047302d24ba3537aa">auto_mixed_precision</a>=True, bool use_gpu=False)</td></tr>
<tr class="separator:a6da5521c916307b55443d6ff0525303d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a26ec45464245e43fc3c8c80f3d143865"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classt5_1_1t5__helper_1_1T5Helper.html#a26ec45464245e43fc3c8c80f3d143865">verify_onnx</a> (<a class="el" href="classt5_1_1t5__encoder_1_1T5Encoder.html">T5Encoder</a>|<a class="el" href="classt5_1_1t5__decoder_1_1T5Decoder.html">T5Decoder</a>|<a class="el" href="classt5_1_1t5__decoder_1_1T5DecoderInit.html">T5DecoderInit</a>|<a class="el" href="classt5_1_1t5__encoder__decoder__init_1_1T5EncoderDecoderInit.html">T5EncoderDecoderInit</a> model, InferenceSession ort_session, torch.device device, bool use_int32_inputs)</td></tr>
<tr class="separator:a26ec45464245e43fc3c8c80f3d143865"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aaf90c68b230106a047302d24ba3537aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf90c68b230106a047302d24ba3537aa">&#9670;&nbsp;</a></span>auto_mixed_precision() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def t5.t5_helper.T5Helper.auto_mixed_precision </td>
          <td>(</td>
          <td class="paramtype">OnnxModel&#160;</td>
          <td class="paramname"><em>onnx_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[str] &#160;</td>
          <td class="paramname"><em>op_block_list</em> = <code>[&#160;&#160;#&#160;noqa:&#160;B006
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SimplifiedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SkipSimplifiedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Relu&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Add&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;]</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Convert model to mixed precision.
   It detects whether original model has fp16 precision weights, and set parameters for float16 conversion automatically.
Args:
    onnx_model (OnnxModel): optimized ONNX model
    op_block_list (List[str], optional): . Defaults to ["SimplifiedLayerNormalization", "SkipSimplifiedLayerNormalization", "Relu", "Add"]
Returns:
    parameters(dict): a dictionary of parameters used in float16 conversion
</pre> 
</div>
</div>
<a id="aaf90c68b230106a047302d24ba3537aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf90c68b230106a047302d24ba3537aa">&#9670;&nbsp;</a></span>auto_mixed_precision() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def t5.t5_helper.T5Helper.auto_mixed_precision </td>
          <td>(</td>
          <td class="paramtype">OnnxModel&#160;</td>
          <td class="paramname"><em>onnx_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[str] &#160;</td>
          <td class="paramname"><em>op_block_list</em> = <code>[&#160;&#160;#&#160;noqa:&#160;B006
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SimplifiedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SkipSimplifiedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Relu&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Add&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;]</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Convert model to mixed precision.
   It detects whether original model has fp16 precision weights, and set parameters for float16 conversion automatically.
Args:
    onnx_model (OnnxModel): optimized ONNX model
    op_block_list (List[str], optional): . Defaults to ["SimplifiedLayerNormalization", "SkipSimplifiedLayerNormalization", "Relu", "Add"]
Returns:
    parameters(dict): a dictionary of parameters used in float16 conversion
</pre> 
</div>
</div>
<a id="ace3b238129c093b23edc8542c6f9d32d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace3b238129c093b23edc8542c6f9d32d">&#9670;&nbsp;</a></span>export_onnx() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def t5.t5_helper.T5Helper.export_onnx </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classt5_1_1t5__encoder_1_1T5Encoder.html">T5Encoder</a> | <a class="el" href="classt5_1_1t5__decoder_1_1T5Decoder.html">T5Decoder</a> | <a class="el" href="classt5_1_1t5__decoder_1_1T5DecoderInit.html">T5DecoderInit</a> | <a class="el" href="classt5_1_1t5__encoder__decoder__init_1_1T5EncoderDecoderInit.html">T5EncoderDecoderInit</a>&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>verbose</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_decoder_input_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_int32_inputs</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ace3b238129c093b23edc8542c6f9d32d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace3b238129c093b23edc8542c6f9d32d">&#9670;&nbsp;</a></span>export_onnx() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def t5.t5_helper.T5Helper.export_onnx </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classt5_1_1t5__encoder_1_1T5Encoder.html">T5Encoder</a> | <a class="el" href="classt5_1_1t5__decoder_1_1T5Decoder.html">T5Decoder</a> | <a class="el" href="classt5_1_1t5__decoder_1_1T5DecoderInit.html">T5DecoderInit</a> | <a class="el" href="classt5_1_1t5__encoder__decoder__init_1_1T5EncoderDecoderInit.html">T5EncoderDecoderInit</a>&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>verbose</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_decoder_input_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_int32_inputs</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a517cd37b483b36cc7b3e98ddc94c3c39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a517cd37b483b36cc7b3e98ddc94c3c39">&#9670;&nbsp;</a></span>get_onnx_path() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> str t5.t5_helper.T5Helper.get_onnx_path </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>output_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>suffix</em> = <code>&quot;&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>new_folder</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Build onnx path

Args:
    output_dir (str): output directory
    model_name_or_path (str): pretrained model name, or path to the model checkpoint
    suffix (str, optional): suffix like "_encoder" or "_decoder_fp16" will be appended to file name. Defaults to None.
    new_folder (bool, optional): create a new directory for the model. Defaults to False.

Returns:
    str: path of onnx model
</pre> 
</div>
</div>
<a id="a517cd37b483b36cc7b3e98ddc94c3c39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a517cd37b483b36cc7b3e98ddc94c3c39">&#9670;&nbsp;</a></span>get_onnx_path() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> str t5.t5_helper.T5Helper.get_onnx_path </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>output_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>suffix</em> = <code>&quot;&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>new_folder</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Build onnx path

Args:
    output_dir (str): output directory
    model_name_or_path (str): pretrained model name, or path to the model checkpoint
    suffix (str, optional): suffix like "_encoder" or "_decoder_fp16" will be appended to file name. Defaults to None.
    new_folder (bool, optional): create a new directory for the model. Defaults to False.

Returns:
    str: path of onnx model
</pre> 
</div>
</div>
<a id="adc0df67f16e2e80ba53124209266217e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc0df67f16e2e80ba53124209266217e">&#9670;&nbsp;</a></span>load_model() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> dict[str, torch.nn.Module] t5.t5_helper.T5Helper.load_model </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>cache_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>merge_encoder_and_decoder_init</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>model_type</em> = <code>&quot;t5&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>state_dict_path</em> = <code>&quot;&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Load model given a pretrained name or path, then build models for ONNX conversion.

Args:
    model_name_or_path (str): pretrained model name or path
    cache_dir (str): cache directory
    device (torch.device): device to run the model
    merge_encoder_and_decoder_init (bool, optional): Whether merge encoder and decoder initialization into one ONNX model. Defaults to True.
    is_mt5 (bool, optional): whether the model is MT5 instead of T5
Returns:
    Dict[str, torch.nn.Module]: mapping from name to modules for ONNX conversion.
</pre> 
</div>
</div>
<a id="adc0df67f16e2e80ba53124209266217e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc0df67f16e2e80ba53124209266217e">&#9670;&nbsp;</a></span>load_model() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> dict[str, torch.nn.Module] t5.t5_helper.T5Helper.load_model </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>cache_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>merge_encoder_and_decoder_init</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>model_type</em> = <code>&quot;t5&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>state_dict_path</em> = <code>&quot;&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Load model given a pretrained name or path, then build models for ONNX conversion.

Args:
    model_name_or_path (str): pretrained model name or path
    cache_dir (str): cache directory
    device (torch.device): device to run the model
    merge_encoder_and_decoder_init (bool, optional): Whether merge encoder and decoder initialization into one ONNX model. Defaults to True.
    is_mt5 (bool, optional): whether the model is MT5 instead of T5
Returns:
    Dict[str, torch.nn.Module]: mapping from name to modules for ONNX conversion.
</pre> 
</div>
</div>
<a id="a6da5521c916307b55443d6ff0525303d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6da5521c916307b55443d6ff0525303d">&#9670;&nbsp;</a></span>optimize_onnx() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def t5.t5_helper.T5Helper.optimize_onnx </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>optimized_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>is_float16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_attention_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>auto_mixed_precision</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_gpu</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Optimize ONNX model with an option to convert it to use mixed precision.</pre> 
</div>
</div>
<a id="a6da5521c916307b55443d6ff0525303d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6da5521c916307b55443d6ff0525303d">&#9670;&nbsp;</a></span>optimize_onnx() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def t5.t5_helper.T5Helper.optimize_onnx </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>optimized_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>is_float16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_attention_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>auto_mixed_precision</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_gpu</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Optimize ONNX model with an option to convert it to use mixed precision.</pre> 
</div>
</div>
<a id="a26ec45464245e43fc3c8c80f3d143865"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a26ec45464245e43fc3c8c80f3d143865">&#9670;&nbsp;</a></span>verify_onnx() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def t5.t5_helper.T5Helper.verify_onnx </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classt5_1_1t5__encoder_1_1T5Encoder.html">T5Encoder</a> | <a class="el" href="classt5_1_1t5__decoder_1_1T5Decoder.html">T5Decoder</a> | <a class="el" href="classt5_1_1t5__decoder_1_1T5DecoderInit.html">T5DecoderInit</a> | <a class="el" href="classt5_1_1t5__encoder__decoder__init_1_1T5EncoderDecoderInit.html">T5EncoderDecoderInit</a>&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InferenceSession&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_int32_inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compare the result from PyTorch and OnnxRuntime to verify the ONNX model is good.</pre> 
</div>
</div>
<a id="a26ec45464245e43fc3c8c80f3d143865"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a26ec45464245e43fc3c8c80f3d143865">&#9670;&nbsp;</a></span>verify_onnx() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def t5.t5_helper.T5Helper.verify_onnx </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classt5_1_1t5__encoder_1_1T5Encoder.html">T5Encoder</a> | <a class="el" href="classt5_1_1t5__decoder_1_1T5Decoder.html">T5Decoder</a> | <a class="el" href="classt5_1_1t5__decoder_1_1T5DecoderInit.html">T5DecoderInit</a> | <a class="el" href="classt5_1_1t5__encoder__decoder__init_1_1T5EncoderDecoderInit.html">T5EncoderDecoderInit</a>&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InferenceSession&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_int32_inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compare the result from PyTorch and OnnxRuntime to verify the ONNX model is good.</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>chromadb_rest_wrapper/venv/lib/python3.10/site-packages/onnxruntime/transformers/models/t5/<a class="el" href="chromadb__rest__wrapper_2venv_2lib_2python3_810_2site-packages_2onnxruntime_2transformers_2models_2t5_2t5__helper_8py.html">t5_helper.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
