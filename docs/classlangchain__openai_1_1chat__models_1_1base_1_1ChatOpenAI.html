<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: langchain_openai.chat_models.base.ChatOpenAI Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacelangchain__openai.html">langchain_openai</a></li><li class="navelem"><a class="el" href="namespacelangchain__openai_1_1chat__models.html">chat_models</a></li><li class="navelem"><a class="el" href="namespacelangchain__openai_1_1chat__models_1_1base.html">base</a></li><li class="navelem"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html">ChatOpenAI</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-attribs">Static Public Attributes</a> &#124;
<a href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">langchain_openai.chat_models.base.ChatOpenAI Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for langchain_openai.chat_models.base.ChatOpenAI:</div>
<div class="dyncontent">
<div class="center"><img src="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI__inherit__graph.png" border="0" usemap="#alangchain__openai_8chat__models_8base_8ChatOpenAI_inherit__map" alt="Inheritance graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for langchain_openai.chat_models.base.ChatOpenAI:</div>
<div class="dyncontent">
<div class="center"><img src="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI__coll__graph.png" border="0" usemap="#alangchain__openai_8chat__models_8base_8ChatOpenAI_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 1 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:af1a775912380358253a7ab45edd13135"><td class="memItemLeft" align="right" valign="top">Dict[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#af1a775912380358253a7ab45edd13135">lc_secrets</a> (self)</td></tr>
<tr class="separator:af1a775912380358253a7ab45edd13135"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b62eeea46fd6c58bbb6e0442718ec90"><td class="memItemLeft" align="right" valign="top">List[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#a0b62eeea46fd6c58bbb6e0442718ec90">get_lc_namespace</a> (cls)</td></tr>
<tr class="separator:a0b62eeea46fd6c58bbb6e0442718ec90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace4c71ff067b3b9c2bfee19193a72b7b"><td class="memItemLeft" align="right" valign="top">Dict[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#ace4c71ff067b3b9c2bfee19193a72b7b">lc_attributes</a> (self)</td></tr>
<tr class="separator:ace4c71ff067b3b9c2bfee19193a72b7b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8d5806c73e378e8d4a597067fcefdaf"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#a014ae18790a24e890b624c9e05cb1f90">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#ac8d5806c73e378e8d4a597067fcefdaf">is_lc_serializable</a> (cls)</td></tr>
<tr class="separator:ac8d5806c73e378e8d4a597067fcefdaf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a738b575cb431c1a7afff10c017ff63e2"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__core_1_1runnables_1_1base_1_1Runnable.html">Runnable</a>[LanguageModelInput, _DictOrPydantic]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#a738b575cb431c1a7afff10c017ff63e2">with_structured_output</a> (self, Optional[_DictOrPydanticClass] schema=<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#ac33d612d2aa76f40c8311d85dec9522c">None</a>, *Literal[&quot;function_calling&quot;, &quot;json_mode&quot;, &quot;json_schema&quot;] method=&quot;json_schema&quot;, bool include_raw=False, Optional[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#a014ae18790a24e890b624c9e05cb1f90">bool</a>] strict=<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#ac33d612d2aa76f40c8311d85dec9522c">None</a>, **<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a> kwargs)</td></tr>
<tr class="separator:a738b575cb431c1a7afff10c017ff63e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html">langchain_openai.chat_models.base.BaseChatOpenAI</a></td></tr>
<tr class="memitem:a0587453eba744154448d3bec702c8cb0 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a0587453eba744154448d3bec702c8cb0">build_extra</a> (cls, Dict[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>] values)</td></tr>
<tr class="separator:a0587453eba744154448d3bec702c8cb0 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7e82482a93b6eac9d08c1ac55bf6cbbc inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a7e82482a93b6eac9d08c1ac55bf6cbbc">validate_temperature</a> (cls, Dict[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>] values)</td></tr>
<tr class="separator:a7e82482a93b6eac9d08c1ac55bf6cbbc inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aedfb40586667d67d97267b5965d458f9 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">Self&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#aedfb40586667d67d97267b5965d458f9">validate_environment</a> (self)</td></tr>
<tr class="separator:aedfb40586667d67d97267b5965d458f9 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca416859079bcc19b874039ed4fa0116 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">List[int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#aca416859079bcc19b874039ed4fa0116">get_token_ids</a> (self, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a> text)</td></tr>
<tr class="separator:aca416859079bcc19b874039ed4fa0116 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff0770055a75e462b5cba62e1755a476 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#aff0770055a75e462b5cba62e1755a476">get_num_tokens_from_messages</a> (self, List[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>] messages, Optional[Sequence[Union[Dict[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>], Type, Callable, <a class="el" href="classlangchain__core_1_1tools_1_1base_1_1BaseTool.html">BaseTool</a>]]] tools=<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a39227cc8f734636bbb79e33967e34fcd">None</a>)</td></tr>
<tr class="separator:aff0770055a75e462b5cba62e1755a476 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a51e06c264d7bf52df0cb561baca6d920 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__core_1_1runnables_1_1base_1_1Runnable.html">Runnable</a>[LanguageModelInput, <a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a51e06c264d7bf52df0cb561baca6d920">bind_functions</a> (self, Sequence[Union[Dict[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>], Type[<a class="el" href="classpydantic_1_1main_1_1BaseModel.html">BaseModel</a>], Callable, <a class="el" href="classlangchain__core_1_1tools_1_1base_1_1BaseTool.html">BaseTool</a>]] functions, Optional[Union[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1__FunctionCall.html">_FunctionCall</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, Literal[&quot;auto&quot;, &quot;none&quot;]]] function_call=<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a39227cc8f734636bbb79e33967e34fcd">None</a>, **<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a> kwargs)</td></tr>
<tr class="separator:a51e06c264d7bf52df0cb561baca6d920 inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade2f36485a019ff31a51ea33033b667a inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__core_1_1runnables_1_1base_1_1Runnable.html">Runnable</a>[LanguageModelInput, <a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#ade2f36485a019ff31a51ea33033b667a">bind_tools</a> (self, Sequence[Union[Dict[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>], Type, Callable, <a class="el" href="classlangchain__core_1_1tools_1_1base_1_1BaseTool.html">BaseTool</a>]] tools, *Optional[Union[<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, Literal[&quot;auto&quot;, &quot;none&quot;, &quot;required&quot;, &quot;any&quot;], bool]] tool_choice=<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a39227cc8f734636bbb79e33967e34fcd">None</a>, Optional[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#ae03624d1ecfefafbee9a440e21538830">bool</a>] strict=<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a39227cc8f734636bbb79e33967e34fcd">None</a>, Optional[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#ae03624d1ecfefafbee9a440e21538830">bool</a>] parallel_tool_calls=<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a39227cc8f734636bbb79e33967e34fcd">None</a>, **<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a> kwargs)</td></tr>
<tr class="separator:ade2f36485a019ff31a51ea33033b667a inherit pub_methods_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html">langchain_core.language_models.chat_models.BaseChatModel</a></td></tr>
<tr class="memitem:ac849438ef69279f268fde8707305bb2a inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ac849438ef69279f268fde8707305bb2a">raise_deprecation</a> (cls, <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a> values)</td></tr>
<tr class="separator:ac849438ef69279f268fde8707305bb2a inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66a9bdd0c57082986754bda600dae8ab inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a66a9bdd0c57082986754bda600dae8ab">OutputType</a> (self)</td></tr>
<tr class="separator:a66a9bdd0c57082986754bda600dae8ab inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7f8c2cc4a26e9976707d2c61fb19e89 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ac7f8c2cc4a26e9976707d2c61fb19e89">invoke</a> (self, LanguageModelInput input, Optional[RunnableConfig] config=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:ac7f8c2cc4a26e9976707d2c61fb19e89 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b25f07dd72cc1494428db258df52141 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a2b25f07dd72cc1494428db258df52141">ainvoke</a> (self, LanguageModelInput input, Optional[RunnableConfig] config=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a2b25f07dd72cc1494428db258df52141 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada1f2f92a2fcd8774b60f04393256fb7 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">Iterator[BaseMessageChunk]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ada1f2f92a2fcd8774b60f04393256fb7">stream</a> (self, LanguageModelInput input, Optional[RunnableConfig] config=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:ada1f2f92a2fcd8774b60f04393256fb7 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e21a4ff68c4b90a8a4f41746963f916 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">AsyncIterator[BaseMessageChunk]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a6e21a4ff68c4b90a8a4f41746963f916">astream</a> (self, LanguageModelInput input, Optional[RunnableConfig] config=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a6e21a4ff68c4b90a8a4f41746963f916 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f989a0d51f1a9577e5d05f41404c0ba inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8f989a0d51f1a9577e5d05f41404c0ba">generate</a> (self, list[list[BaseMessage]] messages, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] tags=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a>[str, Any]] metadata=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[str] run_name=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[uuid.UUID] run_id=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a8f989a0d51f1a9577e5d05f41404c0ba inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2713f693278f2dd8cf536bc595f1425 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#af2713f693278f2dd8cf536bc595f1425">agenerate</a> (self, list[list[BaseMessage]] messages, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] tags=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a>[str, Any]] metadata=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[str] run_name=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[uuid.UUID] run_id=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:af2713f693278f2dd8cf536bc595f1425 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac244ce3ac312e236ad58bf30b2766948 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ac244ce3ac312e236ad58bf30b2766948">generate_prompt</a> (self, list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] prompts, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:ac244ce3ac312e236ad58bf30b2766948 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65f501d0cbaffa30706877d01d89cae1 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a65f501d0cbaffa30706877d01d89cae1">agenerate_prompt</a> (self, list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] prompts, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a65f501d0cbaffa30706877d01d89cae1 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a881bb6a83ba9c962d2cf142e0e2d5112 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a881bb6a83ba9c962d2cf142e0e2d5112">__call__</a> (self, list[BaseMessage] messages, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a881bb6a83ba9c962d2cf142e0e2d5112 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d014c11202e208de1d52429ce22cc41 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a9d014c11202e208de1d52429ce22cc41">call_as_llm</a> (self, str message, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a9d014c11202e208de1d52429ce22cc41 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a416fa5eb36946a9fd05d45cbfaa71880 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a416fa5eb36946a9fd05d45cbfaa71880">predict</a> (self, str text, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a416fa5eb36946a9fd05d45cbfaa71880 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f77789b282f5a4762d0edd61a8eacd8 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a2f77789b282f5a4762d0edd61a8eacd8">predict_messages</a> (self, list[BaseMessage] messages, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a2f77789b282f5a4762d0edd61a8eacd8 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6388c19ec3a5171e4764c38a651ba220 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a6388c19ec3a5171e4764c38a651ba220">apredict</a> (self, str text, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a6388c19ec3a5171e4764c38a651ba220 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ce9cf41619799218c5cd08b82ac7e57 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a3ce9cf41619799218c5cd08b82ac7e57">apredict_messages</a> (self, list[BaseMessage] messages, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a3ce9cf41619799218c5cd08b82ac7e57 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75830e7f62ab3b08307792385cf68454 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a> (self, **Any kwargs)</td></tr>
<tr class="separator:a75830e7f62ab3b08307792385cf68454 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0584ebeaf94fe4f5ede42df5c4635d2d inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">Runnable[LanguageModelInput, BaseMessage]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a0584ebeaf94fe4f5ede42df5c4635d2d">bind_tools</a> (self, Sequence[Union[typing.Dict[str, Any], type, Callable, BaseTool] # noqa:UP006] tools, **Any kwargs)</td></tr>
<tr class="separator:a0584ebeaf94fe4f5ede42df5c4635d2d inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69c4cb0e6768a99204536ccde028b824 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">Runnable[LanguageModelInput, Union[typing.Dict, <a class="el" href="classpydantic_1_1main_1_1BaseModel.html">BaseModel</a>]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a69c4cb0e6768a99204536ccde028b824">with_structured_output</a> (self, Union[typing.Dict, type] schema, *<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a> include_raw=False, **Any kwargs)</td></tr>
<tr class="separator:a69c4cb0e6768a99204536ccde028b824 inherit pub_methods_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html">langchain_core.language_models.base.BaseLanguageModel</a></td></tr>
<tr class="memitem:a7372e2d3dd1fe0bb947ba445704f62c0 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7372e2d3dd1fe0bb947ba445704f62c0">set_verbose</a> (cls, Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a>] verbose)</td></tr>
<tr class="separator:a7372e2d3dd1fe0bb947ba445704f62c0 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb2e0d0544101ed7216a60648ff8ccec inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">TypeAlias&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#afb2e0d0544101ed7216a60648ff8ccec">InputType</a> (self)</td></tr>
<tr class="separator:afb2e0d0544101ed7216a60648ff8ccec inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a705f1e99b82dd3e0d19335ac47d85af8 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">Runnable[<a class="el" href="namespacelangchain__core_1_1language__models_1_1base.html#a00fb344778dc86fc8afd9cfc29b3b494">LanguageModelInput</a>, Union[dict, <a class="el" href="classpydantic_1_1main_1_1BaseModel.html">BaseModel</a>]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a705f1e99b82dd3e0d19335ac47d85af8">with_structured_output</a> (self, Union[dict, type] schema, **Any kwargs)</td></tr>
<tr class="separator:a705f1e99b82dd3e0d19335ac47d85af8 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af464ecf7fc013bbaa4573b83aecdf626 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#af464ecf7fc013bbaa4573b83aecdf626">get_num_tokens</a> (self, str text)</td></tr>
<tr class="separator:af464ecf7fc013bbaa4573b83aecdf626 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3fa68289b24c36ba84881c769fca8f4 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ab3fa68289b24c36ba84881c769fca8f4">get_num_tokens_from_messages</a> (self, list[BaseMessage] messages, Optional[Sequence] tools=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>)</td></tr>
<tr class="separator:ab3fa68289b24c36ba84881c769fca8f4 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-attribs"></a>
Static Public Attributes</h2></td></tr>
<tr class="memitem:a014ae18790a24e890b624c9e05cb1f90"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#a014ae18790a24e890b624c9e05cb1f90">bool</a></td></tr>
<tr class="separator:a014ae18790a24e890b624c9e05cb1f90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a145042a6839364b019f89d3154f2499b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#a145042a6839364b019f89d3154f2499b">default</a></td></tr>
<tr class="separator:a145042a6839364b019f89d3154f2499b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac33d612d2aa76f40c8311d85dec9522c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#ac33d612d2aa76f40c8311d85dec9522c">None</a></td></tr>
<tr class="separator:ac33d612d2aa76f40c8311d85dec9522c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf331999351c0efa15c4c1b9861bd710"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#abf331999351c0efa15c4c1b9861bd710">alias</a></td></tr>
<tr class="separator:abf331999351c0efa15c4c1b9861bd710"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td colspan="2" onclick="javascript:toggleInherit('pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI')"><img src="closed.png" alt="-"/>&#160;Static Public Attributes inherited from <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html">langchain_openai.chat_models.base.BaseChatOpenAI</a></td></tr>
<tr class="memitem:a1872ca8579e9983d6fbf32bbd9fbad36 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a></td></tr>
<tr class="separator:a1872ca8579e9983d6fbf32bbd9fbad36 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28b2c9d7cb1c81e090bf253d0eb38c53 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a28b2c9d7cb1c81e090bf253d0eb38c53">default</a></td></tr>
<tr class="separator:a28b2c9d7cb1c81e090bf253d0eb38c53 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39227cc8f734636bbb79e33967e34fcd inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a39227cc8f734636bbb79e33967e34fcd">None</a></td></tr>
<tr class="separator:a39227cc8f734636bbb79e33967e34fcd inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18787b3a891fb728935577bab4718548 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a18787b3a891fb728935577bab4718548">exclude</a></td></tr>
<tr class="separator:a18787b3a891fb728935577bab4718548 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53e6d413c045ac3bff8735a30dab16c4 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a></td></tr>
<tr class="separator:a53e6d413c045ac3bff8735a30dab16c4 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c7e6ddc41d2b470343a2206954ada71 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a5c7e6ddc41d2b470343a2206954ada71">alias</a></td></tr>
<tr class="separator:a5c7e6ddc41d2b470343a2206954ada71 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae10da63d68ad726ab83716ae031f48b7 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#ae10da63d68ad726ab83716ae031f48b7">default_factory</a></td></tr>
<tr class="separator:ae10da63d68ad726ab83716ae031f48b7 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae03624d1ecfefafbee9a440e21538830 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#ae03624d1ecfefafbee9a440e21538830">bool</a></td></tr>
<tr class="separator:ae03624d1ecfefafbee9a440e21538830 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff395b097029b970fdb736c16cc851a4 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#aff395b097029b970fdb736c16cc851a4">model_config</a> = <a class="el" href="classpydantic_1_1config_1_1ConfigDict.html">ConfigDict</a>(populate_by_name=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a338ed3c32514080a24e93a9dbb70def1">True</a>)</td></tr>
<tr class="separator:aff395b097029b970fdb736c16cc851a4 inherit pub_static_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td colspan="2" onclick="javascript:toggleInherit('pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel')"><img src="closed.png" alt="-"/>&#160;Static Public Attributes inherited from <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html">langchain_core.language_models.chat_models.BaseChatModel</a></td></tr>
<tr class="memitem:ae86a49547d47ee5d37e5de4511d6dcc8 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ae86a49547d47ee5d37e5de4511d6dcc8">name</a></td></tr>
<tr class="separator:ae86a49547d47ee5d37e5de4511d6dcc8 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd62802c6d8b05f19b8377934270e445 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#afd62802c6d8b05f19b8377934270e445">since</a></td></tr>
<tr class="separator:afd62802c6d8b05f19b8377934270e445 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c727a2c91c467be5ec9880198831cd7 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a5c727a2c91c467be5ec9880198831cd7">removal</a></td></tr>
<tr class="separator:a5c727a2c91c467be5ec9880198831cd7 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37740e205816c167eea0aaf33efade2f inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a37740e205816c167eea0aaf33efade2f">alternative</a></td></tr>
<tr class="separator:a37740e205816c167eea0aaf33efade2f inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5286b5305fcbcbf7c93a97bdf43ad8b inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#aa5286b5305fcbcbf7c93a97bdf43ad8b">default</a></td></tr>
<tr class="separator:aa5286b5305fcbcbf7c93a97bdf43ad8b inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cc2bc655191b554549a0c76122b786b inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></td></tr>
<tr class="separator:a8cc2bc655191b554549a0c76122b786b inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61d7382fe5885461f3f666459c4f9614 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a61d7382fe5885461f3f666459c4f9614">exclude</a></td></tr>
<tr class="separator:a61d7382fe5885461f3f666459c4f9614 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7f8d0efe19d1f2e7e8d639e03688fa9 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#af7f8d0efe19d1f2e7e8d639e03688fa9">model_config</a></td></tr>
<tr class="separator:af7f8d0efe19d1f2e7e8d639e03688fa9 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td colspan="2" onclick="javascript:toggleInherit('pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel')"><img src="closed.png" alt="-"/>&#160;Static Public Attributes inherited from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html">langchain_core.language_models.base.BaseLanguageModel</a></td></tr>
<tr class="memitem:a15a531155fcd2fb285a070e9a31f1492 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a15a531155fcd2fb285a070e9a31f1492">default</a></td></tr>
<tr class="separator:a15a531155fcd2fb285a070e9a31f1492 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7df8406beb8687aa660ecd162c68bc2a inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></td></tr>
<tr class="separator:a7df8406beb8687aa660ecd162c68bc2a inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf4fc9722efcd58dff847b0015165792 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#aaf4fc9722efcd58dff847b0015165792">exclude</a></td></tr>
<tr class="separator:aaf4fc9722efcd58dff847b0015165792 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44631b9ca0352cbd634ebe50a9dca3c9 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a></td></tr>
<tr class="separator:a44631b9ca0352cbd634ebe50a9dca3c9 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad35476617e8f5e4e725b2b75f95f78ce inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ad35476617e8f5e4e725b2b75f95f78ce">default_factory</a></td></tr>
<tr class="separator:ad35476617e8f5e4e725b2b75f95f78ce inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a338ed3c32514080a24e93a9dbb70def1 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a338ed3c32514080a24e93a9dbb70def1">True</a></td></tr>
<tr class="separator:a338ed3c32514080a24e93a9dbb70def1 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2142f5d0cbb2717105aeb5b53d7b48f8 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a2142f5d0cbb2717105aeb5b53d7b48f8">repr</a></td></tr>
<tr class="separator:a2142f5d0cbb2717105aeb5b53d7b48f8 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf486a987306c1af846c57557c76d31b inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a></td></tr>
<tr class="separator:abf486a987306c1af846c57557c76d31b inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13c293f947462f9c167f970c457d0b76 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a13c293f947462f9c167f970c457d0b76">model_config</a></td></tr>
<tr class="separator:a13c293f947462f9c167f970c457d0b76 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html">langchain_openai.chat_models.base.BaseChatOpenAI</a></td></tr>
<tr class="memitem:a7bb4563aeb12b36e9848d40b24110487 inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a7bb4563aeb12b36e9848d40b24110487">openai_organization</a></td></tr>
<tr class="separator:a7bb4563aeb12b36e9848d40b24110487 inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9afe5b095b6bc6b6d490681c823f22b2 inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a9afe5b095b6bc6b6d490681c823f22b2">openai_api_base</a></td></tr>
<tr class="separator:a9afe5b095b6bc6b6d490681c823f22b2 inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a583c2460e94bc93d38f1842afc47e0ca inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a583c2460e94bc93d38f1842afc47e0ca">http_client</a></td></tr>
<tr class="separator:a583c2460e94bc93d38f1842afc47e0ca inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac21495a8e8bb71ba85a74ffa76a0209c inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#ac21495a8e8bb71ba85a74ffa76a0209c">root_client</a></td></tr>
<tr class="separator:ac21495a8e8bb71ba85a74ffa76a0209c inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acbde5f5a1fa44df0f7e3031e311cc617 inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#acbde5f5a1fa44df0f7e3031e311cc617">client</a></td></tr>
<tr class="separator:acbde5f5a1fa44df0f7e3031e311cc617 inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a077ccad57d97a34d5f221c0a1ee0b27e inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a077ccad57d97a34d5f221c0a1ee0b27e">http_async_client</a></td></tr>
<tr class="separator:a077ccad57d97a34d5f221c0a1ee0b27e inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a115d8db58aa7ef3466dd452df6caba7a inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a115d8db58aa7ef3466dd452df6caba7a">root_async_client</a></td></tr>
<tr class="separator:a115d8db58aa7ef3466dd452df6caba7a inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c59d4a8a71953e2c940aab6a027f85b inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a3c59d4a8a71953e2c940aab6a027f85b">async_client</a></td></tr>
<tr class="separator:a3c59d4a8a71953e2c940aab6a027f85b inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a838de2ab94b421751e31e20d1b747dba inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a838de2ab94b421751e31e20d1b747dba">model_name</a></td></tr>
<tr class="separator:a838de2ab94b421751e31e20d1b747dba inherit pub_attribs_classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html">langchain_core.language_models.chat_models.BaseChatModel</a></td></tr>
<tr class="memitem:a2ba23caed0e36512d90f1c30b3fdaa21 inherit pub_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a2ba23caed0e36512d90f1c30b3fdaa21">disable_streaming</a></td></tr>
<tr class="separator:a2ba23caed0e36512d90f1c30b3fdaa21 inherit pub_attribs_classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">OpenAI chat model integration.

.. dropdown:: Setup
    :open:

    Install ``langchain-openai`` and set environment variable ``OPENAI_API_KEY``.

    .. code-block:: bash

        pip install -U langchain-openai
        export OPENAI_API_KEY="your-api-key"

.. dropdown:: Key init args — completion params

    model: str
        Name of OpenAI model to use.
    temperature: float
        Sampling temperature.
    max_tokens: Optional[int]
        Max number of tokens to generate.
    logprobs: Optional[bool]
        Whether to return logprobs.
    stream_options: Dict
        Configure streaming outputs, like whether to return token usage when
        streaming (``{"include_usage": True}``).
    use_responses_api: Optional[bool]
        Whether to use the responses API.

    See full list of supported init args and their descriptions in the params section.

.. dropdown:: Key init args — client params

    timeout: Union[float, Tuple[float, float], Any, None]
        Timeout for requests.
    max_retries: Optional[int]
        Max number of retries.
    api_key: Optional[str]
        OpenAI API key. If not passed in will be read from env var OPENAI_API_KEY.
    base_url: Optional[str]
        Base URL for API requests. Only specify if using a proxy or service
        emulator.
    organization: Optional[str]
        OpenAI organization ID. If not passed in will be read from env
        var OPENAI_ORG_ID.

    See full list of supported init args and their descriptions in the params section.

.. dropdown:: Instantiate

    .. code-block:: python

        from langchain_openai import ChatOpenAI

        llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0,
            max_tokens=None,
            timeout=None,
            max_retries=2,
            # api_key="...",
            # base_url="...",
            # organization="...",
            # other params...
        )

    **NOTE**: Any param which is not explicitly supported will be passed directly to the
    ``openai.OpenAI.chat.completions.create(...)`` API every time to the model is
    invoked. For example:

    .. code-block:: python

        from langchain_openai import ChatOpenAI
        import openai

        ChatOpenAI(..., frequency_penalty=0.2).invoke(...)

        # results in underlying API call of:

        openai.OpenAI(..).chat.completions.create(..., frequency_penalty=0.2)

        # which is also equivalent to:

        ChatOpenAI(...).invoke(..., frequency_penalty=0.2)

.. dropdown:: Invoke

    .. code-block:: python

        messages = [
            (
                "system",
                "You are a helpful translator. Translate the user sentence to French.",
            ),
            ("human", "I love programming."),
        ]
        llm.invoke(messages)

    .. code-block:: pycon

        AIMessage(
            content="J'adore la programmation.",
            response_metadata={
                "token_usage": {
                    "completion_tokens": 5,
                    "prompt_tokens": 31,
                    "total_tokens": 36,
                },
                "model_name": "gpt-4o",
                "system_fingerprint": "fp_43dfabdef1",
                "finish_reason": "stop",
                "logprobs": None,
            },
            id="run-012cffe2-5d3d-424d-83b5-51c6d4a593d1-0",
            usage_metadata={"input_tokens": 31, "output_tokens": 5, "total_tokens": 36},
        )

.. dropdown:: Stream

    .. code-block:: python

        for chunk in llm.stream(messages):
            print(chunk.text(), end="")

    .. code-block:: python

        AIMessageChunk(content="", id="run-9e1517e3-12bf-48f2-bb1b-2e824f7cd7b0")
        AIMessageChunk(content="J", id="run-9e1517e3-12bf-48f2-bb1b-2e824f7cd7b0")
        AIMessageChunk(content="'adore", id="run-9e1517e3-12bf-48f2-bb1b-2e824f7cd7b0")
        AIMessageChunk(content=" la", id="run-9e1517e3-12bf-48f2-bb1b-2e824f7cd7b0")
        AIMessageChunk(
            content=" programmation", id="run-9e1517e3-12bf-48f2-bb1b-2e824f7cd7b0"
        )
        AIMessageChunk(content=".", id="run-9e1517e3-12bf-48f2-bb1b-2e824f7cd7b0")
        AIMessageChunk(
            content="",
            response_metadata={"finish_reason": "stop"},
            id="run-9e1517e3-12bf-48f2-bb1b-2e824f7cd7b0",
        )

    .. code-block:: python

        stream = llm.stream(messages)
        full = next(stream)
        for chunk in stream:
            full += chunk
        full

    .. code-block:: python

        AIMessageChunk(
            content="J'adore la programmation.",
            response_metadata={"finish_reason": "stop"},
            id="run-bf917526-7f58-4683-84f7-36a6b671d140",
        )

.. dropdown:: Async

    .. code-block:: python

        await llm.ainvoke(messages)

        # stream:
        # async for chunk in (await llm.astream(messages))

        # batch:
        # await llm.abatch([messages])

    .. code-block:: python

        AIMessage(
            content="J'adore la programmation.",
            response_metadata={
                "token_usage": {
                    "completion_tokens": 5,
                    "prompt_tokens": 31,
                    "total_tokens": 36,
                },
                "model_name": "gpt-4o",
                "system_fingerprint": "fp_43dfabdef1",
                "finish_reason": "stop",
                "logprobs": None,
            },
            id="run-012cffe2-5d3d-424d-83b5-51c6d4a593d1-0",
            usage_metadata={"input_tokens": 31, "output_tokens": 5, "total_tokens": 36},
        )

.. dropdown:: Tool calling

    .. code-block:: python

        from pydantic import BaseModel, Field


        class GetWeather(BaseModel):
            '''Get the current weather in a given location'''

            location: str = Field(
                ..., description="The city and state, e.g. San Francisco, CA"
            )


        class GetPopulation(BaseModel):
            '''Get the current population in a given location'''

            location: str = Field(
                ..., description="The city and state, e.g. San Francisco, CA"
            )


        llm_with_tools = llm.bind_tools(
            [GetWeather, GetPopulation]
            # strict = True  # enforce tool args schema is respected
        )
        ai_msg = llm_with_tools.invoke(
            "Which city is hotter today and which is bigger: LA or NY?"
        )
        ai_msg.tool_calls

    .. code-block:: python

        [
            {
                "name": "GetWeather",
                "args": {"location": "Los Angeles, CA"},
                "id": "call_6XswGD5Pqk8Tt5atYr7tfenU",
            },
            {
                "name": "GetWeather",
                "args": {"location": "New York, NY"},
                "id": "call_ZVL15vA8Y7kXqOy3dtmQgeCi",
            },
            {
                "name": "GetPopulation",
                "args": {"location": "Los Angeles, CA"},
                "id": "call_49CFW8zqC9W7mh7hbMLSIrXw",
            },
            {
                "name": "GetPopulation",
                "args": {"location": "New York, NY"},
                "id": "call_6ghfKxV264jEfe1mRIkS3PE7",
            },
        ]

    Note that ``openai &gt;= 1.32`` supports a ``parallel_tool_calls`` parameter
    that defaults to ``True``. This parameter can be set to ``False`` to
    disable parallel tool calls:

    .. code-block:: python

        ai_msg = llm_with_tools.invoke(
            "What is the weather in LA and NY?", parallel_tool_calls=False
        )
        ai_msg.tool_calls

    .. code-block:: python

        [
            {
                "name": "GetWeather",
                "args": {"location": "Los Angeles, CA"},
                "id": "call_4OoY0ZR99iEvC7fevsH8Uhtz",
            }
        ]

    Like other runtime parameters, ``parallel_tool_calls`` can be bound to a model
    using ``llm.bind(parallel_tool_calls=False)`` or during instantiation by
    setting ``model_kwargs``.

    See ``ChatOpenAI.bind_tools()`` method for more.

.. dropdown:: Built-in tools

    .. versionadded:: 0.3.9

    You can access `built-in tools &lt;https://platform.openai.com/docs/guides/tools?api-mode=responses&gt;`_
    supported by the OpenAI Responses API. See LangChain
    `docs &lt;https://python.langchain.com/docs/integrations/chat/openai/&gt;`_ for more
    detail.

    .. code-block:: python

        from langchain_openai import ChatOpenAI

        llm = ChatOpenAI(model="gpt-4o-mini")

        tool = {"type": "web_search_preview"}
        llm_with_tools = llm.bind_tools([tool])

        response = llm_with_tools.invoke("What was a positive news story from today?")
        response.content

    .. code-block:: python

        [
            {
                "type": "text",
                "text": "Today, a heartwarming story emerged from ...",
                "annotations": [
                    {
                        "end_index": 778,
                        "start_index": 682,
                        "title": "Title of story",
                        "type": "url_citation",
                        "url": "&lt;url of story&gt;",
                    }
                ],
            }
        ]

.. dropdown:: Managing conversation state

    .. versionadded:: 0.3.9

    OpenAI's Responses API supports management of
    `conversation state &lt;https://platform.openai.com/docs/guides/conversation-state?api-mode=responses&gt;`_.
    Passing in response IDs from previous messages will continue a conversational
    thread. See LangChain
    `docs &lt;https://python.langchain.com/docs/integrations/chat/openai/&gt;`_ for more
    detail.

    .. code-block:: python

        from langchain_openai import ChatOpenAI

        llm = ChatOpenAI(model="gpt-4o-mini", use_responses_api=True)
        response = llm.invoke("Hi, I'm Bob.")
        response.text()

    .. code-block:: python

        "Hi Bob! How can I assist you today?"

    .. code-block:: python

        second_response = llm.invoke(
            "What is my name?", previous_response_id=response.response_metadata["id"]
        )
        second_response.text()

    .. code-block:: python

        "Your name is Bob. How can I help you today, Bob?"

.. dropdown:: Structured output

    .. code-block:: python

        from typing import Optional

        from pydantic import BaseModel, Field


        class Joke(BaseModel):
            '''Joke to tell user.'''

            setup: str = Field(description="The setup of the joke")
            punchline: str = Field(description="The punchline to the joke")
            rating: Optional[int] = Field(description="How funny the joke is, from 1 to 10")


        structured_llm = llm.with_structured_output(Joke)
        structured_llm.invoke("Tell me a joke about cats")

    .. code-block:: python

        Joke(
            setup="Why was the cat sitting on the computer?",
            punchline="To keep an eye on the mouse!",
            rating=None,
        )

    See ``ChatOpenAI.with_structured_output()`` for more.

.. dropdown:: JSON mode

    .. code-block:: python

        json_llm = llm.bind(response_format={"type": "json_object"})
        ai_msg = json_llm.invoke(
            "Return a JSON object with key 'random_ints' and a value of 10 random ints in [0-99]"
        )
        ai_msg.content

    .. code-block:: python

        '\\n{\\n  "random_ints": [23, 87, 45, 12, 78, 34, 56, 90, 11, 67]\\n}'

.. dropdown:: Image input

    .. code-block:: python

        import base64
        import httpx
        from langchain_core.messages import HumanMessage

        image_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
        image_data = base64.b64encode(httpx.get(image_url).content).decode("utf-8")
        message = HumanMessage(
            content=[
                {"type": "text", "text": "describe the weather in this image"},
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_data}"},
                },
            ]
        )
        ai_msg = llm.invoke([message])
        ai_msg.content

    .. code-block:: python

        "The weather in the image appears to be clear and pleasant. The sky is mostly blue with scattered, light clouds, suggesting a sunny day with minimal cloud cover. There is no indication of rain or strong winds, and the overall scene looks bright and calm. The lush green grass and clear visibility further indicate good weather conditions."

.. dropdown:: Token usage

    .. code-block:: python

        ai_msg = llm.invoke(messages)
        ai_msg.usage_metadata

    .. code-block:: python

        {"input_tokens": 28, "output_tokens": 5, "total_tokens": 33}

    When streaming, set the ``stream_usage`` kwarg:

    .. code-block:: python

        stream = llm.stream(messages, stream_usage=True)
        full = next(stream)
        for chunk in stream:
            full += chunk
        full.usage_metadata

    .. code-block:: python

        {"input_tokens": 28, "output_tokens": 5, "total_tokens": 33}

    Alternatively, setting ``stream_usage`` when instantiating the model can be
    useful when incorporating ``ChatOpenAI`` into LCEL chains-- or when using
    methods like ``.with_structured_output``, which generate chains under the
    hood.

    .. code-block:: python

        llm = ChatOpenAI(model="gpt-4o", stream_usage=True)
        structured_llm = llm.with_structured_output(...)

.. dropdown:: Logprobs

    .. code-block:: python

        logprobs_llm = llm.bind(logprobs=True)
        ai_msg = logprobs_llm.invoke(messages)
        ai_msg.response_metadata["logprobs"]

    .. code-block:: python

        {
            "content": [
                {
                    "token": "J",
                    "bytes": [74],
                    "logprob": -4.9617593e-06,
                    "top_logprobs": [],
                },
                {
                    "token": "'adore",
                    "bytes": [39, 97, 100, 111, 114, 101],
                    "logprob": -0.25202933,
                    "top_logprobs": [],
                },
                {
                    "token": " la",
                    "bytes": [32, 108, 97],
                    "logprob": -0.20141791,
                    "top_logprobs": [],
                },
                {
                    "token": " programmation",
                    "bytes": [
                        32,
                        112,
                        114,
                        111,
                        103,
                        114,
                        97,
                        109,
                        109,
                        97,
                        116,
                        105,
                        111,
                        110,
                    ],
                    "logprob": -1.9361265e-07,
                    "top_logprobs": [],
                },
                {
                    "token": ".",
                    "bytes": [46],
                    "logprob": -1.2233183e-05,
                    "top_logprobs": [],
                },
            ]
        }

.. dropdown:: Response metadata

    .. code-block:: python

        ai_msg = llm.invoke(messages)
        ai_msg.response_metadata

    .. code-block:: python

        {
            "token_usage": {
                "completion_tokens": 5,
                "prompt_tokens": 28,
                "total_tokens": 33,
            },
            "model_name": "gpt-4o",
            "system_fingerprint": "fp_319be4768e",
            "finish_reason": "stop",
            "logprobs": None,
        }</pre> </div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a0b62eeea46fd6c58bbb6e0442718ec90"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b62eeea46fd6c58bbb6e0442718ec90">&#9670;&nbsp;</a></span>get_lc_namespace()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> List[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>] langchain_openai.chat_models.base.ChatOpenAI.get_lc_namespace </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get the namespace of the langchain object.</pre> 
</div>
</div>
<a id="ac8d5806c73e378e8d4a597067fcefdaf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac8d5806c73e378e8d4a597067fcefdaf">&#9670;&nbsp;</a></span>is_lc_serializable()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#a014ae18790a24e890b624c9e05cb1f90">bool</a> langchain_openai.chat_models.base.ChatOpenAI.is_lc_serializable </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return whether this model can be serialized by Langchain.</pre> 
</div>
</div>
<a id="ace4c71ff067b3b9c2bfee19193a72b7b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace4c71ff067b3b9c2bfee19193a72b7b">&#9670;&nbsp;</a></span>lc_attributes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Dict[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>] langchain_openai.chat_models.base.ChatOpenAI.lc_attributes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af1a775912380358253a7ab45edd13135"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af1a775912380358253a7ab45edd13135">&#9670;&nbsp;</a></span>lc_secrets()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Dict[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>, <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a53e6d413c045ac3bff8735a30dab16c4">str</a>] langchain_openai.chat_models.base.ChatOpenAI.lc_secrets </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a738b575cb431c1a7afff10c017ff63e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a738b575cb431c1a7afff10c017ff63e2">&#9670;&nbsp;</a></span>with_structured_output()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> <a class="el" href="classlangchain__core_1_1runnables_1_1base_1_1Runnable.html">Runnable</a>[LanguageModelInput, _DictOrPydantic] langchain_openai.chat_models.base.ChatOpenAI.with_structured_output </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[_DictOrPydanticClass] &#160;</td>
          <td class="paramname"><em>schema</em> = <code><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#ac33d612d2aa76f40c8311d85dec9522c">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Literal[&quot;function_calling&quot;, &quot;json_mode&quot;, &quot;json_schema&quot;] &#160;</td>
          <td class="paramname"><em>method</em> = <code>&quot;json_schema&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#a014ae18790a24e890b624c9e05cb1f90">bool</a> &#160;</td>
          <td class="paramname"><em>include_raw</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#a014ae18790a24e890b624c9e05cb1f90">bool</a>] &#160;</td>
          <td class="paramname"><em>strict</em> = <code><a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1ChatOpenAI.html#ac33d612d2aa76f40c8311d85dec9522c">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**<a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a1872ca8579e9983d6fbf32bbd9fbad36">Any</a>&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Model wrapper that returns outputs formatted to match the given schema.

Args:
    schema:
        The output schema. Can be passed in as:

        - a JSON Schema,
        - a TypedDict class,
        - or a Pydantic class,
        - an OpenAI function/tool schema.

        If ``schema`` is a Pydantic class then the model output will be a
        Pydantic instance of that class, and the model-generated fields will be
        validated by the Pydantic class. Otherwise the model output will be a
        dict and will not be validated. See :meth:`langchain_core.utils.function_calling.convert_to_openai_tool`
        for more on how to properly specify types and descriptions of
        schema fields when specifying a Pydantic or TypedDict class.

    method: The method for steering model generation, one of:

        - "json_schema":
            Uses OpenAI's Structured Output API:
            https://platform.openai.com/docs/guides/structured-outputs
            Supported for "gpt-4o-mini", "gpt-4o-2024-08-06", "o1", and later
            models.
        - "function_calling":
            Uses OpenAI's tool-calling (formerly called function calling)
            API: https://platform.openai.com/docs/guides/function-calling
        - "json_mode":
            Uses OpenAI's JSON mode. Note that if using JSON mode then you
            must include instructions for formatting the output into the
            desired schema into the model call:
            https://platform.openai.com/docs/guides/structured-outputs/json-mode

        Learn more about the differences between the methods and which models
        support which methods here:

        - https://platform.openai.com/docs/guides/structured-outputs/structured-outputs-vs-json-mode
        - https://platform.openai.com/docs/guides/structured-outputs/function-calling-vs-response-format

    include_raw:
        If False then only the parsed structured output is returned. If
        an error occurs during model output parsing it will be raised. If True
        then both the raw model response (a BaseMessage) and the parsed model
        response will be returned. If an error occurs during output parsing it
        will be caught and returned as well. The final output is always a dict
        with keys "raw", "parsed", and "parsing_error".
    strict:

        - True:
            Model output is guaranteed to exactly match the schema.
            The input schema will also be validated according to
            https://platform.openai.com/docs/guides/structured-outputs/supported-schemas
        - False:
            Input schema will not be validated and model output will not be
            validated.
        - None:
            ``strict`` argument will not be passed to the model.

        If schema is specified via TypedDict or JSON schema, ``strict`` is not
        enabled by default. Pass ``strict=True`` to enable it.

        Note: ``strict`` can only be non-null if ``method`` is
        ``"json_schema"`` or ``"function_calling"``.

    kwargs: Additional keyword args aren't supported.

Returns:
    A Runnable that takes same inputs as a :class:`langchain_core.language_models.chat.BaseChatModel`.

    | If ``include_raw`` is False and ``schema`` is a Pydantic class, Runnable outputs an instance of ``schema`` (i.e., a Pydantic object). Otherwise, if ``include_raw`` is False then Runnable outputs a dict.

    | If ``include_raw`` is True, then Runnable outputs a dict with keys:

    - "raw": BaseMessage
    - "parsed": None if there was a parsing error, otherwise the type depends on the ``schema`` as described above.
    - "parsing_error": Optional[BaseException]

.. versionchanged:: 0.1.20

    Added support for TypedDict class ``schema``.

.. versionchanged:: 0.1.21

    Support for ``strict`` argument added.
    Support for ``method="json_schema"`` added.

.. versionchanged:: 0.3.0

    ``method`` default changed from "function_calling" to "json_schema".

.. dropdown:: Example: schema=Pydantic class, method="json_schema", include_raw=False, strict=True

    Note, OpenAI has a number of restrictions on what types of schemas can be
    provided if ``strict`` = True. When using Pydantic, our model cannot
    specify any Field metadata (like min/max constraints) and fields cannot
    have default values.

    See all constraints here: https://platform.openai.com/docs/guides/structured-outputs/supported-schemas

    .. code-block:: python

        from typing import Optional

        from langchain_openai import ChatOpenAI
        from pydantic import BaseModel, Field


        class AnswerWithJustification(BaseModel):
            '''An answer to the user question along with justification for the answer.'''

            answer: str
            justification: Optional[str] = Field(
                default=..., description="A justification for the answer."
            )


        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        structured_llm = llm.with_structured_output(AnswerWithJustification)

        structured_llm.invoke(
            "What weighs more a pound of bricks or a pound of feathers"
        )

        # -&gt; AnswerWithJustification(
        #     answer='They weigh the same',
        #     justification='Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.'
        # )

.. dropdown:: Example: schema=Pydantic class, method="function_calling", include_raw=False, strict=False

    .. code-block:: python

        from typing import Optional

        from langchain_openai import ChatOpenAI
        from pydantic import BaseModel, Field


        class AnswerWithJustification(BaseModel):
            '''An answer to the user question along with justification for the answer.'''

            answer: str
            justification: Optional[str] = Field(
                default=..., description="A justification for the answer."
            )


        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        structured_llm = llm.with_structured_output(
            AnswerWithJustification, method="function_calling"
        )

        structured_llm.invoke(
            "What weighs more a pound of bricks or a pound of feathers"
        )

        # -&gt; AnswerWithJustification(
        #     answer='They weigh the same',
        #     justification='Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.'
        # )

.. dropdown:: Example: schema=Pydantic class, method="json_schema", include_raw=True

    .. code-block:: python

        from langchain_openai import ChatOpenAI
        from pydantic import BaseModel


        class AnswerWithJustification(BaseModel):
            '''An answer to the user question along with justification for the answer.'''

            answer: str
            justification: str


        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        structured_llm = llm.with_structured_output(
            AnswerWithJustification, include_raw=True
        )

        structured_llm.invoke(
            "What weighs more a pound of bricks or a pound of feathers"
        )
        # -&gt; {
        #     'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Ao02pnFYXD6GN1yzc0uXPsvF', 'function': {'arguments': '{"answer":"They weigh the same.","justification":"Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ."}', 'name': 'AnswerWithJustification'}, 'type': 'function'}]}),
        #     'parsed': AnswerWithJustification(answer='They weigh the same.', justification='Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.'),
        #     'parsing_error': None
        # }

.. dropdown:: Example: schema=TypedDict class, method="json_schema", include_raw=False, strict=False

    .. code-block:: python

        # IMPORTANT: If you are using Python &lt;=3.8, you need to import Annotated
        # from typing_extensions, not from typing.
        from typing_extensions import Annotated, TypedDict

        from langchain_openai import ChatOpenAI


        class AnswerWithJustification(TypedDict):
            '''An answer to the user question along with justification for the answer.'''

            answer: str
            justification: Annotated[
                Optional[str], None, "A justification for the answer."
            ]


        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        structured_llm = llm.with_structured_output(AnswerWithJustification)

        structured_llm.invoke(
            "What weighs more a pound of bricks or a pound of feathers"
        )
        # -&gt; {
        #     'answer': 'They weigh the same',
        #     'justification': 'Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume and density of the two substances differ.'
        # }

.. dropdown:: Example: schema=OpenAI function schema, method="json_schema", include_raw=False

    .. code-block:: python

        from langchain_openai import ChatOpenAI

        oai_schema = {
            'name': 'AnswerWithJustification',
            'description': 'An answer to the user question along with justification for the answer.',
            'parameters': {
                'type': 'object',
                'properties': {
                    'answer': {'type': 'string'},
                    'justification': {'description': 'A justification for the answer.', 'type': 'string'}
                },
               'required': ['answer']
           }
       }

        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        structured_llm = llm.with_structured_output(oai_schema)

        structured_llm.invoke(
            "What weighs more a pound of bricks or a pound of feathers"
        )
        # -&gt; {
        #     'answer': 'They weigh the same',
        #     'justification': 'Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume and density of the two substances differ.'
        # }

.. dropdown:: Example: schema=Pydantic class, method="json_mode", include_raw=True

    .. code-block::

        from langchain_openai import ChatOpenAI
        from pydantic import BaseModel

        class AnswerWithJustification(BaseModel):
            answer: str
            justification: str

        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        structured_llm = llm.with_structured_output(
            AnswerWithJustification,
            method="json_mode",
            include_raw=True
        )

        structured_llm.invoke(
            "Answer the following question. "
            "Make sure to return a JSON blob with keys 'answer' and 'justification'.\\n\\n"
            "What's heavier a pound of bricks or a pound of feathers?"
        )
        # -&gt; {
        #     'raw': AIMessage(content='{\\n    "answer": "They are both the same weight.",\\n    "justification": "Both a pound of bricks and a pound of feathers weigh one pound. The difference lies in the volume and density of the materials, not the weight." \\n}'),
        #     'parsed': AnswerWithJustification(answer='They are both the same weight.', justification='Both a pound of bricks and a pound of feathers weigh one pound. The difference lies in the volume and density of the materials, not the weight.'),
        #     'parsing_error': None
        # }

.. dropdown:: Example: schema=None, method="json_mode", include_raw=True

    .. code-block::

        structured_llm = llm.with_structured_output(method="json_mode", include_raw=True)

        structured_llm.invoke(
            "Answer the following question. "
            "Make sure to return a JSON blob with keys 'answer' and 'justification'.\\n\\n"
            "What's heavier a pound of bricks or a pound of feathers?"
        )
        # -&gt; {
        #     'raw': AIMessage(content='{\\n    "answer": "They are both the same weight.",\\n    "justification": "Both a pound of bricks and a pound of feathers weigh one pound. The difference lies in the volume and density of the materials, not the weight." \\n}'),
        #     'parsed': {
        #         'answer': 'They are both the same weight.',
        #         'justification': 'Both a pound of bricks and a pound of feathers weigh one pound. The difference lies in the volume and density of the materials, not the weight.'
        #     },
        #     'parsing_error': None
        # }
</pre> 
<p>Reimplemented from <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#a135e2fd23624a756b1bcdf61b162976d">langchain_openai.chat_models.base.BaseChatOpenAI</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="abf331999351c0efa15c4c1b9861bd710"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf331999351c0efa15c4c1b9861bd710">&#9670;&nbsp;</a></span>alias</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_openai.chat_models.base.ChatOpenAI.alias</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a014ae18790a24e890b624c9e05cb1f90"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a014ae18790a24e890b624c9e05cb1f90">&#9670;&nbsp;</a></span>bool</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_openai.chat_models.base.ChatOpenAI.bool</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a145042a6839364b019f89d3154f2499b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a145042a6839364b019f89d3154f2499b">&#9670;&nbsp;</a></span>default</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_openai.chat_models.base.ChatOpenAI.default</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ac33d612d2aa76f40c8311d85dec9522c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac33d612d2aa76f40c8311d85dec9522c">&#9670;&nbsp;</a></span>None</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_openai.chat_models.base.ChatOpenAI.None</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>py3_env/lib/python3.10/site-packages/langchain_openai/chat_models/<a class="el" href="py3__env_2lib_2python3_810_2site-packages_2langchain__openai_2chat__models_2base_8py.html">base.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
