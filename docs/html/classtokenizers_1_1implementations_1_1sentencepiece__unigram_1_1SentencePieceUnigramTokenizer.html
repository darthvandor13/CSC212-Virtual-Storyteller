<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacetokenizers.html">tokenizers</a></li><li class="navelem"><a class="el" href="namespacetokenizers_1_1implementations.html">implementations</a></li><li class="navelem"><a class="el" href="namespacetokenizers_1_1implementations_1_1sentencepiece__unigram.html">sentencepiece_unigram</a></li><li class="navelem"><a class="el" href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer.html">SentencePieceUnigramTokenizer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer:</div>
<div class="dyncontent">
<div class="center"><img src="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer__inherit__graph.png" border="0" usemap="#atokenizers_8implementations_8sentencepiece__unigram_8SentencePieceUnigramTokenizer_inherit__map" alt="Inheritance graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer:</div>
<div class="dyncontent">
<div class="center"><img src="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer__coll__graph.png" border="0" usemap="#atokenizers_8implementations_8sentencepiece__unigram_8SentencePieceUnigramTokenizer_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 1 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:aac946dd6b22e1a4f3fe958c002f43690"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer.html#aac946dd6b22e1a4f3fe958c002f43690">__init__</a> (self, Optional[List[Tuple[str, float]]] vocab=None, str replacement=&quot;▁&quot;, bool add_prefix_space=True)</td></tr>
<tr class="separator:aac946dd6b22e1a4f3fe958c002f43690"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9bfe3f796dfa94f48b55994cd5edefc6"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer.html#a9bfe3f796dfa94f48b55994cd5edefc6">train</a> (self, Union[str, List[str]] files, int vocab_size=8000, bool show_progress=True, Optional[List[Union[str, AddedToken]]] special_tokens=None, Optional[List[str]] initial_alphabet=None, Optional[str] unk_token=None)</td></tr>
<tr class="separator:a9bfe3f796dfa94f48b55994cd5edefc6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab27bda6452d65136b9a2a559064c10cb"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer.html#ab27bda6452d65136b9a2a559064c10cb">train_from_iterator</a> (self, Union[Iterator[str], Iterator[Iterator[str]]] iterator, int vocab_size=8000, bool show_progress=True, Optional[List[Union[str, AddedToken]]] special_tokens=None, Optional[List[str]] initial_alphabet=None, Optional[str] unk_token=None, Optional[int] length=None)</td></tr>
<tr class="separator:ab27bda6452d65136b9a2a559064c10cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac946dd6b22e1a4f3fe958c002f43690"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer.html#aac946dd6b22e1a4f3fe958c002f43690">__init__</a> (self, Optional[List[Tuple[str, float]]] vocab=None, str replacement=&quot;▁&quot;, bool add_prefix_space=True)</td></tr>
<tr class="separator:aac946dd6b22e1a4f3fe958c002f43690"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9bfe3f796dfa94f48b55994cd5edefc6"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer.html#a9bfe3f796dfa94f48b55994cd5edefc6">train</a> (self, Union[str, List[str]] files, int vocab_size=8000, bool show_progress=True, Optional[List[Union[str, AddedToken]]] special_tokens=None, Optional[List[str]] initial_alphabet=None, Optional[str] unk_token=None)</td></tr>
<tr class="separator:a9bfe3f796dfa94f48b55994cd5edefc6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab27bda6452d65136b9a2a559064c10cb"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer.html#ab27bda6452d65136b9a2a559064c10cb">train_from_iterator</a> (self, Union[Iterator[str], Iterator[Iterator[str]]] iterator, int vocab_size=8000, bool show_progress=True, Optional[List[Union[str, AddedToken]]] special_tokens=None, Optional[List[str]] initial_alphabet=None, Optional[str] unk_token=None, Optional[int] length=None)</td></tr>
<tr class="separator:ab27bda6452d65136b9a2a559064c10cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html">tokenizers.implementations.base_tokenizer.BaseTokenizer</a></td></tr>
<tr class="memitem:a1e640d61ccda155abe971e66c73914c9 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a1e640d61ccda155abe971e66c73914c9">__init__</a> (self, Tokenizer tokenizer, parameters=None)</td></tr>
<tr class="separator:a1e640d61ccda155abe971e66c73914c9 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd6f541668f2e6ac61e49e004ae34e27 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#acd6f541668f2e6ac61e49e004ae34e27">__repr__</a> (self)</td></tr>
<tr class="separator:acd6f541668f2e6ac61e49e004ae34e27 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b1779a483f5c76d9cc300ac1c3bd374 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a8b1779a483f5c76d9cc300ac1c3bd374">num_special_tokens_to_add</a> (self, bool is_pair)</td></tr>
<tr class="separator:a8b1779a483f5c76d9cc300ac1c3bd374 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa36c0ef94a6bc9db024d2d51f088fa01 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Dict[str, int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#aa36c0ef94a6bc9db024d2d51f088fa01">get_vocab</a> (self, bool with_added_tokens=True)</td></tr>
<tr class="separator:aa36c0ef94a6bc9db024d2d51f088fa01 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad87a910892da1c3dbcaa2bb5f841b97c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Dict[int, AddedToken]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#ad87a910892da1c3dbcaa2bb5f841b97c">get_added_tokens_decoder</a> (self)</td></tr>
<tr class="separator:ad87a910892da1c3dbcaa2bb5f841b97c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91072a1720207d48045b0628a1a7b7d4 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a91072a1720207d48045b0628a1a7b7d4">get_vocab_size</a> (self, bool with_added_tokens=True)</td></tr>
<tr class="separator:a91072a1720207d48045b0628a1a7b7d4 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e63da6c97bb366cd7067c163397517b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a9e63da6c97bb366cd7067c163397517b">enable_padding</a> (self, Optional[str] direction=&quot;right&quot;, Optional[int] pad_to_multiple_of=None, Optional[int] pad_id=0, Optional[int] pad_type_id=0, Optional[str] pad_token=&quot;[PAD]&quot;, Optional[int] length=None)</td></tr>
<tr class="separator:a9e63da6c97bb366cd7067c163397517b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e8ebaa5cacd213627df7fea6da9db53 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a3e8ebaa5cacd213627df7fea6da9db53">no_padding</a> (self)</td></tr>
<tr class="separator:a3e8ebaa5cacd213627df7fea6da9db53 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a802d42ff0d7eb907e1028b1ae48f3344 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Optional[dict]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a802d42ff0d7eb907e1028b1ae48f3344">padding</a> (self)</td></tr>
<tr class="separator:a802d42ff0d7eb907e1028b1ae48f3344 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0168a42b4b3f0278893d6a7d6c0e2da6 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a0168a42b4b3f0278893d6a7d6c0e2da6">enable_truncation</a> (self, int max_length, Optional[int] stride=0, Optional[str] strategy=&quot;longest_first&quot;)</td></tr>
<tr class="separator:a0168a42b4b3f0278893d6a7d6c0e2da6 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0356bcd0bcbc202656e899642e41b43 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#ab0356bcd0bcbc202656e899642e41b43">no_truncation</a> (self)</td></tr>
<tr class="separator:ab0356bcd0bcbc202656e899642e41b43 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9af3f663c58e78dbef0e1e2f78acc9cb inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Optional[dict]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a9af3f663c58e78dbef0e1e2f78acc9cb">truncation</a> (self)</td></tr>
<tr class="separator:a9af3f663c58e78dbef0e1e2f78acc9cb inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a333136d500cd957e288b58e9c3899a91 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a333136d500cd957e288b58e9c3899a91">add_tokens</a> (self, List[Union[str, AddedToken]] tokens)</td></tr>
<tr class="separator:a333136d500cd957e288b58e9c3899a91 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c4c375bb3c68efc4fff8c673a9a39e8 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c4c375bb3c68efc4fff8c673a9a39e8">add_special_tokens</a> (self, List[Union[str, AddedToken]] special_tokens)</td></tr>
<tr class="separator:a2c4c375bb3c68efc4fff8c673a9a39e8 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0da8a9804f324fbadfe8d80c0383d4c8 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a0da8a9804f324fbadfe8d80c0383d4c8">normalize</a> (self, str sequence)</td></tr>
<tr class="separator:a0da8a9804f324fbadfe8d80c0383d4c8 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20a78c701b6956f698e94781102f3d39 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Encoding&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a20a78c701b6956f698e94781102f3d39">encode</a> (self, <a class="el" href="namespacetokenizers.html#a15a8be396c7e3214864966f5dcf0c987">InputSequence</a> sequence, Optional[<a class="el" href="namespacetokenizers.html#a15a8be396c7e3214864966f5dcf0c987">InputSequence</a>] pair=None, bool is_pretokenized=False, bool <a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c4c375bb3c68efc4fff8c673a9a39e8">add_special_tokens</a>=True)</td></tr>
<tr class="separator:a20a78c701b6956f698e94781102f3d39 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade14ad37c8ff8134293ac3a8edd93e93 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">List[Encoding]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#ade14ad37c8ff8134293ac3a8edd93e93">encode_batch</a> (self, List[<a class="el" href="namespacetokenizers.html#a7a534e859bfbca24df73b12fa4426153">EncodeInput</a>] inputs, bool is_pretokenized=False, bool <a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c4c375bb3c68efc4fff8c673a9a39e8">add_special_tokens</a>=True)</td></tr>
<tr class="separator:ade14ad37c8ff8134293ac3a8edd93e93 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28d23fa4a07d0a3438905b59b0e19e81 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a28d23fa4a07d0a3438905b59b0e19e81">decode</a> (self, List[int] ids, Optional[bool] skip_special_tokens=True)</td></tr>
<tr class="separator:a28d23fa4a07d0a3438905b59b0e19e81 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03919a78c7b07867ca70054a2b982005 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a03919a78c7b07867ca70054a2b982005">decode_batch</a> (self, List[List[int]] sequences, Optional[bool] skip_special_tokens=True)</td></tr>
<tr class="separator:a03919a78c7b07867ca70054a2b982005 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed638ebb841cf7ccf39d42e08edf7ea0 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Optional[int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#aed638ebb841cf7ccf39d42e08edf7ea0">token_to_id</a> (self, str token)</td></tr>
<tr class="separator:aed638ebb841cf7ccf39d42e08edf7ea0 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8267e8cdc7a0d6158772eed05be6d71e inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Optional[str]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a8267e8cdc7a0d6158772eed05be6d71e">id_to_token</a> (self, int id)</td></tr>
<tr class="separator:a8267e8cdc7a0d6158772eed05be6d71e inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3390e87baff6db726ea0cfef2fded947 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a3390e87baff6db726ea0cfef2fded947">save_model</a> (self, str directory, Optional[str] prefix=None)</td></tr>
<tr class="separator:a3390e87baff6db726ea0cfef2fded947 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79f7735979dbada94631cb2524c7df1c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a79f7735979dbada94631cb2524c7df1c">save</a> (self, str path, bool pretty=True)</td></tr>
<tr class="separator:a79f7735979dbada94631cb2524c7df1c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5dbcbdbc16897dee33d9e77fc46b77f1 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a5dbcbdbc16897dee33d9e77fc46b77f1">to_str</a> (self, bool pretty=False)</td></tr>
<tr class="separator:a5dbcbdbc16897dee33d9e77fc46b77f1 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c8286e05e5440ffba8fb4475929df19 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Encoding&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c8286e05e5440ffba8fb4475929df19">post_process</a> (self, Encoding encoding, Optional[Encoding] pair=None, bool <a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c4c375bb3c68efc4fff8c673a9a39e8">add_special_tokens</a>=True)</td></tr>
<tr class="separator:a2c8286e05e5440ffba8fb4475929df19 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acafa2a1528ec286850d26a67a70d1b4e inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Model&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#acafa2a1528ec286850d26a67a70d1b4e">model</a> (self)</td></tr>
<tr class="separator:acafa2a1528ec286850d26a67a70d1b4e inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b0c7fcffe954b6e682e54d91db28f16 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a4b0c7fcffe954b6e682e54d91db28f16">model</a> (self, Model model)</td></tr>
<tr class="separator:a4b0c7fcffe954b6e682e54d91db28f16 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b6e6515568bdf9cc1c7a23d65846e3b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Normalizer&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a5b6e6515568bdf9cc1c7a23d65846e3b">normalizer</a> (self)</td></tr>
<tr class="separator:a5b6e6515568bdf9cc1c7a23d65846e3b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc663792601cd27b31b8f0b6ef62045c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#abc663792601cd27b31b8f0b6ef62045c">normalizer</a> (self, Normalizer normalizer)</td></tr>
<tr class="separator:abc663792601cd27b31b8f0b6ef62045c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2143b3fcd914c1781ad6d4ea360b27e3 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">PreTokenizer&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2143b3fcd914c1781ad6d4ea360b27e3">pre_tokenizer</a> (self)</td></tr>
<tr class="separator:a2143b3fcd914c1781ad6d4ea360b27e3 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a053a989e27fd094f463b8bac2f7cdb7b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a053a989e27fd094f463b8bac2f7cdb7b">pre_tokenizer</a> (self, PreTokenizer pre_tokenizer)</td></tr>
<tr class="separator:a053a989e27fd094f463b8bac2f7cdb7b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bb8093855cb299a37f553bd5c021acc inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">PostProcessor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a5bb8093855cb299a37f553bd5c021acc">post_processor</a> (self)</td></tr>
<tr class="separator:a5bb8093855cb299a37f553bd5c021acc inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab01858aa2380ec0f6e1d8c493ac06aa9 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#ab01858aa2380ec0f6e1d8c493ac06aa9">post_processor</a> (self, PostProcessor post_processor)</td></tr>
<tr class="separator:ab01858aa2380ec0f6e1d8c493ac06aa9 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81846c1bc4bfcde77bc61717a23d762c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Decoder&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a81846c1bc4bfcde77bc61717a23d762c">decoder</a> (self)</td></tr>
<tr class="separator:a81846c1bc4bfcde77bc61717a23d762c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8aef5cca2e5dcffe2f9f83575dad12fe inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a8aef5cca2e5dcffe2f9f83575dad12fe">decoder</a> (self, Decoder decoder)</td></tr>
<tr class="separator:a8aef5cca2e5dcffe2f9f83575dad12fe inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1e640d61ccda155abe971e66c73914c9 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a1e640d61ccda155abe971e66c73914c9">__init__</a> (self, Tokenizer tokenizer, parameters=None)</td></tr>
<tr class="separator:a1e640d61ccda155abe971e66c73914c9 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd6f541668f2e6ac61e49e004ae34e27 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#acd6f541668f2e6ac61e49e004ae34e27">__repr__</a> (self)</td></tr>
<tr class="separator:acd6f541668f2e6ac61e49e004ae34e27 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b1779a483f5c76d9cc300ac1c3bd374 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a8b1779a483f5c76d9cc300ac1c3bd374">num_special_tokens_to_add</a> (self, bool is_pair)</td></tr>
<tr class="separator:a8b1779a483f5c76d9cc300ac1c3bd374 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa36c0ef94a6bc9db024d2d51f088fa01 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Dict[str, int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#aa36c0ef94a6bc9db024d2d51f088fa01">get_vocab</a> (self, bool with_added_tokens=True)</td></tr>
<tr class="separator:aa36c0ef94a6bc9db024d2d51f088fa01 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad87a910892da1c3dbcaa2bb5f841b97c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Dict[int, AddedToken]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#ad87a910892da1c3dbcaa2bb5f841b97c">get_added_tokens_decoder</a> (self)</td></tr>
<tr class="separator:ad87a910892da1c3dbcaa2bb5f841b97c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a91072a1720207d48045b0628a1a7b7d4 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a91072a1720207d48045b0628a1a7b7d4">get_vocab_size</a> (self, bool with_added_tokens=True)</td></tr>
<tr class="separator:a91072a1720207d48045b0628a1a7b7d4 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e63da6c97bb366cd7067c163397517b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a9e63da6c97bb366cd7067c163397517b">enable_padding</a> (self, Optional[str] direction=&quot;right&quot;, Optional[int] pad_to_multiple_of=None, Optional[int] pad_id=0, Optional[int] pad_type_id=0, Optional[str] pad_token=&quot;[PAD]&quot;, Optional[int] length=None)</td></tr>
<tr class="separator:a9e63da6c97bb366cd7067c163397517b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e8ebaa5cacd213627df7fea6da9db53 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a3e8ebaa5cacd213627df7fea6da9db53">no_padding</a> (self)</td></tr>
<tr class="separator:a3e8ebaa5cacd213627df7fea6da9db53 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a802d42ff0d7eb907e1028b1ae48f3344 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Optional[dict]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a802d42ff0d7eb907e1028b1ae48f3344">padding</a> (self)</td></tr>
<tr class="separator:a802d42ff0d7eb907e1028b1ae48f3344 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0168a42b4b3f0278893d6a7d6c0e2da6 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a0168a42b4b3f0278893d6a7d6c0e2da6">enable_truncation</a> (self, int max_length, Optional[int] stride=0, Optional[str] strategy=&quot;longest_first&quot;)</td></tr>
<tr class="separator:a0168a42b4b3f0278893d6a7d6c0e2da6 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0356bcd0bcbc202656e899642e41b43 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#ab0356bcd0bcbc202656e899642e41b43">no_truncation</a> (self)</td></tr>
<tr class="separator:ab0356bcd0bcbc202656e899642e41b43 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9af3f663c58e78dbef0e1e2f78acc9cb inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Optional[dict]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a9af3f663c58e78dbef0e1e2f78acc9cb">truncation</a> (self)</td></tr>
<tr class="separator:a9af3f663c58e78dbef0e1e2f78acc9cb inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a333136d500cd957e288b58e9c3899a91 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a333136d500cd957e288b58e9c3899a91">add_tokens</a> (self, List[Union[str, AddedToken]] tokens)</td></tr>
<tr class="separator:a333136d500cd957e288b58e9c3899a91 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c4c375bb3c68efc4fff8c673a9a39e8 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c4c375bb3c68efc4fff8c673a9a39e8">add_special_tokens</a> (self, List[Union[str, AddedToken]] special_tokens)</td></tr>
<tr class="separator:a2c4c375bb3c68efc4fff8c673a9a39e8 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0da8a9804f324fbadfe8d80c0383d4c8 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a0da8a9804f324fbadfe8d80c0383d4c8">normalize</a> (self, str sequence)</td></tr>
<tr class="separator:a0da8a9804f324fbadfe8d80c0383d4c8 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20a78c701b6956f698e94781102f3d39 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Encoding&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a20a78c701b6956f698e94781102f3d39">encode</a> (self, <a class="el" href="namespacetokenizers.html#a15a8be396c7e3214864966f5dcf0c987">InputSequence</a> sequence, Optional[<a class="el" href="namespacetokenizers.html#a15a8be396c7e3214864966f5dcf0c987">InputSequence</a>] pair=None, bool is_pretokenized=False, bool <a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c4c375bb3c68efc4fff8c673a9a39e8">add_special_tokens</a>=True)</td></tr>
<tr class="separator:a20a78c701b6956f698e94781102f3d39 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ade14ad37c8ff8134293ac3a8edd93e93 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">List[Encoding]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#ade14ad37c8ff8134293ac3a8edd93e93">encode_batch</a> (self, List[<a class="el" href="namespacetokenizers.html#a7a534e859bfbca24df73b12fa4426153">EncodeInput</a>] inputs, bool is_pretokenized=False, bool <a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c4c375bb3c68efc4fff8c673a9a39e8">add_special_tokens</a>=True)</td></tr>
<tr class="separator:ade14ad37c8ff8134293ac3a8edd93e93 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28d23fa4a07d0a3438905b59b0e19e81 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a28d23fa4a07d0a3438905b59b0e19e81">decode</a> (self, List[int] ids, Optional[bool] skip_special_tokens=True)</td></tr>
<tr class="separator:a28d23fa4a07d0a3438905b59b0e19e81 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03919a78c7b07867ca70054a2b982005 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a03919a78c7b07867ca70054a2b982005">decode_batch</a> (self, List[List[int]] sequences, Optional[bool] skip_special_tokens=True)</td></tr>
<tr class="separator:a03919a78c7b07867ca70054a2b982005 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed638ebb841cf7ccf39d42e08edf7ea0 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Optional[int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#aed638ebb841cf7ccf39d42e08edf7ea0">token_to_id</a> (self, str token)</td></tr>
<tr class="separator:aed638ebb841cf7ccf39d42e08edf7ea0 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8267e8cdc7a0d6158772eed05be6d71e inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Optional[str]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a8267e8cdc7a0d6158772eed05be6d71e">id_to_token</a> (self, int id)</td></tr>
<tr class="separator:a8267e8cdc7a0d6158772eed05be6d71e inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3390e87baff6db726ea0cfef2fded947 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a3390e87baff6db726ea0cfef2fded947">save_model</a> (self, str directory, Optional[str] prefix=None)</td></tr>
<tr class="separator:a3390e87baff6db726ea0cfef2fded947 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79f7735979dbada94631cb2524c7df1c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a79f7735979dbada94631cb2524c7df1c">save</a> (self, str path, bool pretty=True)</td></tr>
<tr class="separator:a79f7735979dbada94631cb2524c7df1c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5dbcbdbc16897dee33d9e77fc46b77f1 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a5dbcbdbc16897dee33d9e77fc46b77f1">to_str</a> (self, bool pretty=False)</td></tr>
<tr class="separator:a5dbcbdbc16897dee33d9e77fc46b77f1 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2c8286e05e5440ffba8fb4475929df19 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Encoding&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c8286e05e5440ffba8fb4475929df19">post_process</a> (self, Encoding encoding, Optional[Encoding] pair=None, bool <a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2c4c375bb3c68efc4fff8c673a9a39e8">add_special_tokens</a>=True)</td></tr>
<tr class="separator:a2c8286e05e5440ffba8fb4475929df19 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acafa2a1528ec286850d26a67a70d1b4e inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Model&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#acafa2a1528ec286850d26a67a70d1b4e">model</a> (self)</td></tr>
<tr class="separator:acafa2a1528ec286850d26a67a70d1b4e inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b0c7fcffe954b6e682e54d91db28f16 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a4b0c7fcffe954b6e682e54d91db28f16">model</a> (self, Model model)</td></tr>
<tr class="separator:a4b0c7fcffe954b6e682e54d91db28f16 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b6e6515568bdf9cc1c7a23d65846e3b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Normalizer&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a5b6e6515568bdf9cc1c7a23d65846e3b">normalizer</a> (self)</td></tr>
<tr class="separator:a5b6e6515568bdf9cc1c7a23d65846e3b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc663792601cd27b31b8f0b6ef62045c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#abc663792601cd27b31b8f0b6ef62045c">normalizer</a> (self, Normalizer normalizer)</td></tr>
<tr class="separator:abc663792601cd27b31b8f0b6ef62045c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2143b3fcd914c1781ad6d4ea360b27e3 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">PreTokenizer&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a2143b3fcd914c1781ad6d4ea360b27e3">pre_tokenizer</a> (self)</td></tr>
<tr class="separator:a2143b3fcd914c1781ad6d4ea360b27e3 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a053a989e27fd094f463b8bac2f7cdb7b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a053a989e27fd094f463b8bac2f7cdb7b">pre_tokenizer</a> (self, PreTokenizer pre_tokenizer)</td></tr>
<tr class="separator:a053a989e27fd094f463b8bac2f7cdb7b inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bb8093855cb299a37f553bd5c021acc inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">PostProcessor&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a5bb8093855cb299a37f553bd5c021acc">post_processor</a> (self)</td></tr>
<tr class="separator:a5bb8093855cb299a37f553bd5c021acc inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab01858aa2380ec0f6e1d8c493ac06aa9 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#ab01858aa2380ec0f6e1d8c493ac06aa9">post_processor</a> (self, PostProcessor post_processor)</td></tr>
<tr class="separator:ab01858aa2380ec0f6e1d8c493ac06aa9 inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81846c1bc4bfcde77bc61717a23d762c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">Decoder&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a81846c1bc4bfcde77bc61717a23d762c">decoder</a> (self)</td></tr>
<tr class="separator:a81846c1bc4bfcde77bc61717a23d762c inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8aef5cca2e5dcffe2f9f83575dad12fe inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer.html#a8aef5cca2e5dcffe2f9f83575dad12fe">decoder</a> (self, Decoder decoder)</td></tr>
<tr class="separator:a8aef5cca2e5dcffe2f9f83575dad12fe inherit pub_methods_classtokenizers_1_1implementations_1_1base__tokenizer_1_1BaseTokenizer"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a83b24d9957da91430dd6310209573361"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer.html#a83b24d9957da91430dd6310209573361">from_spm</a> (str filename)</td></tr>
<tr class="separator:a83b24d9957da91430dd6310209573361"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83b24d9957da91430dd6310209573361"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classtokenizers_1_1implementations_1_1sentencepiece__unigram_1_1SentencePieceUnigramTokenizer.html#a83b24d9957da91430dd6310209573361">from_spm</a> (str filename)</td></tr>
<tr class="separator:a83b24d9957da91430dd6310209573361"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">SentencePiece Unigram Tokenizer

Represents the Unigram algorithm, with the pretokenization used by SentencePiece
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="aac946dd6b22e1a4f3fe958c002f43690"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac946dd6b22e1a4f3fe958c002f43690">&#9670;&nbsp;</a></span>__init__() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[Tuple[str, float]]] &#160;</td>
          <td class="paramname"><em>vocab</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>replacement</em> = <code>&quot;▁&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>add_prefix_space</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aac946dd6b22e1a4f3fe958c002f43690"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac946dd6b22e1a4f3fe958c002f43690">&#9670;&nbsp;</a></span>__init__() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[Tuple[str, float]]] &#160;</td>
          <td class="paramname"><em>vocab</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>replacement</em> = <code>&quot;▁&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>add_prefix_space</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a83b24d9957da91430dd6310209573361"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83b24d9957da91430dd6310209573361">&#9670;&nbsp;</a></span>from_spm() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer.from_spm </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>filename</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a83b24d9957da91430dd6310209573361"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83b24d9957da91430dd6310209573361">&#9670;&nbsp;</a></span>from_spm() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer.from_spm </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>filename</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a9bfe3f796dfa94f48b55994cd5edefc6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9bfe3f796dfa94f48b55994cd5edefc6">&#9670;&nbsp;</a></span>train() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer.train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[str, List[str]]&#160;</td>
          <td class="paramname"><em>files</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>vocab_size</em> = <code>8000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>show_progress</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[Union[str, AddedToken]]] &#160;</td>
          <td class="paramname"><em>special_tokens</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[str]] &#160;</td>
          <td class="paramname"><em>initial_alphabet</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>unk_token</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Train the model using the given files

Args:
    files (:obj:`List[str]`):
        A list of path to the files that we should use for training
    vocab_size (:obj:`int`):
        The size of the final vocabulary, including all tokens and alphabet.
    show_progress (:obj:`bool`):
        Whether to show progress bars while training.
    special_tokens (:obj:`List[Union[str, AddedToken]]`, `optional`):
        A list of special tokens the model should know of.
    initial_alphabet (:obj:`List[str]`, `optional`):
        A list of characters to include in the initial alphabet, even
        if not seen in the training dataset.
        If the strings contain more than one character, only the first one
        is kept.
    unk_token (:obj:`str`, `optional`):
        The unknown token to be used by the model.
</pre> 
</div>
</div>
<a id="a9bfe3f796dfa94f48b55994cd5edefc6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9bfe3f796dfa94f48b55994cd5edefc6">&#9670;&nbsp;</a></span>train() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer.train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[str, List[str]]&#160;</td>
          <td class="paramname"><em>files</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>vocab_size</em> = <code>8000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>show_progress</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[Union[str, AddedToken]]] &#160;</td>
          <td class="paramname"><em>special_tokens</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[str]] &#160;</td>
          <td class="paramname"><em>initial_alphabet</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>unk_token</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Train the model using the given files

Args:
    files (:obj:`List[str]`):
        A list of path to the files that we should use for training
    vocab_size (:obj:`int`):
        The size of the final vocabulary, including all tokens and alphabet.
    show_progress (:obj:`bool`):
        Whether to show progress bars while training.
    special_tokens (:obj:`List[Union[str, AddedToken]]`, `optional`):
        A list of special tokens the model should know of.
    initial_alphabet (:obj:`List[str]`, `optional`):
        A list of characters to include in the initial alphabet, even
        if not seen in the training dataset.
        If the strings contain more than one character, only the first one
        is kept.
    unk_token (:obj:`str`, `optional`):
        The unknown token to be used by the model.
</pre> 
</div>
</div>
<a id="ab27bda6452d65136b9a2a559064c10cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab27bda6452d65136b9a2a559064c10cb">&#9670;&nbsp;</a></span>train_from_iterator() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer.train_from_iterator </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[Iterator[str], Iterator[Iterator[str]]]&#160;</td>
          <td class="paramname"><em>iterator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>vocab_size</em> = <code>8000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>show_progress</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[Union[str, AddedToken]]] &#160;</td>
          <td class="paramname"><em>special_tokens</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[str]] &#160;</td>
          <td class="paramname"><em>initial_alphabet</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>unk_token</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[int] &#160;</td>
          <td class="paramname"><em>length</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Train the model using the given iterator

Args:
    iterator (:obj:`Union[Iterator[str], Iterator[Iterator[str]]]`):
        Any iterator over strings or list of strings
    vocab_size (:obj:`int`):
        The size of the final vocabulary, including all tokens and alphabet.
    show_progress (:obj:`bool`):
        Whether to show progress bars while training.
    special_tokens (:obj:`List[Union[str, AddedToken]]`, `optional`):
        A list of special tokens the model should know of.
    initial_alphabet (:obj:`List[str]`, `optional`):
        A list of characters to include in the initial alphabet, even
        if not seen in the training dataset.
        If the strings contain more than one character, only the first one
        is kept.
    unk_token (:obj:`str`, `optional`):
        The unknown token to be used by the model.
    length (:obj:`int`, `optional`):
        The total number of sequences in the iterator. This is used to
        provide meaningful progress tracking
</pre> 
</div>
</div>
<a id="ab27bda6452d65136b9a2a559064c10cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab27bda6452d65136b9a2a559064c10cb">&#9670;&nbsp;</a></span>train_from_iterator() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def tokenizers.implementations.sentencepiece_unigram.SentencePieceUnigramTokenizer.train_from_iterator </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[Iterator[str], Iterator[Iterator[str]]]&#160;</td>
          <td class="paramname"><em>iterator</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>vocab_size</em> = <code>8000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>show_progress</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[Union[str, AddedToken]]] &#160;</td>
          <td class="paramname"><em>special_tokens</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[List[str]] &#160;</td>
          <td class="paramname"><em>initial_alphabet</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>unk_token</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[int] &#160;</td>
          <td class="paramname"><em>length</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Train the model using the given iterator

Args:
    iterator (:obj:`Union[Iterator[str], Iterator[Iterator[str]]]`):
        Any iterator over strings or list of strings
    vocab_size (:obj:`int`):
        The size of the final vocabulary, including all tokens and alphabet.
    show_progress (:obj:`bool`):
        Whether to show progress bars while training.
    special_tokens (:obj:`List[Union[str, AddedToken]]`, `optional`):
        A list of special tokens the model should know of.
    initial_alphabet (:obj:`List[str]`, `optional`):
        A list of characters to include in the initial alphabet, even
        if not seen in the training dataset.
        If the strings contain more than one character, only the first one
        is kept.
    unk_token (:obj:`str`, `optional`):
        The unknown token to be used by the model.
    length (:obj:`int`, `optional`):
        The total number of sequences in the iterator. This is used to
        provide meaningful progress tracking
</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>chromadb_rest_wrapper/venv/lib/python3.10/site-packages/tokenizers/implementations/<a class="el" href="chromadb__rest__wrapper_2venv_2lib_2python3_810_2site-packages_2tokenizers_2implementations_2sentencepiece__unigram_8py.html">sentencepiece_unigram.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
