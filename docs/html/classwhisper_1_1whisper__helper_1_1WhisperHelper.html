<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: whisper.whisper_helper.WhisperHelper Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacewhisper.html">whisper</a></li><li class="navelem"><a class="el" href="namespacewhisper_1_1whisper__helper.html">whisper_helper</a></li><li class="navelem"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html">WhisperHelper</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="classwhisper_1_1whisper__helper_1_1WhisperHelper-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">whisper.whisper_helper.WhisperHelper Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a59524c9280508e9413b406fd34ab94b4"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#a59524c9280508e9413b406fd34ab94b4">get_onnx_path</a> (str output_dir, str model_name_or_path, str suffix=&quot;&quot;, bool new_folder=False)</td></tr>
<tr class="separator:a59524c9280508e9413b406fd34ab94b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaef7ebf9cf0e083f2dfffda9d60f292a"><td class="memItemLeft" align="right" valign="top">torch.nn.Module&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#aaef7ebf9cf0e083f2dfffda9d60f292a">load_model_openai</a> (str model_name_or_path, str cache_dir, torch.device device)</td></tr>
<tr class="separator:aaef7ebf9cf0e083f2dfffda9d60f292a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9415e344ea12a2cd93d1f6815260f24d"><td class="memItemLeft" align="right" valign="top">dict[str, torch.nn.Module]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#a9415e344ea12a2cd93d1f6815260f24d">load_model</a> (str model_name_or_path, str model_impl, str cache_dir, torch.device device, bool merge_encoder_and_decoder_init=True)</td></tr>
<tr class="separator:a9415e344ea12a2cd93d1f6815260f24d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:accb96d0f31a4201db304b844b9946a54"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#accb96d0f31a4201db304b844b9946a54">export_onnx</a> (<a class="el" href="classwhisper_1_1whisper__encoder_1_1WhisperEncoder.html">WhisperEncoder</a>|<a class="el" href="classwhisper_1_1whisper__decoder_1_1WhisperDecoder.html">WhisperDecoder</a>|<a class="el" href="classwhisper_1_1whisper__decoder_1_1WhisperDecoderInit.html">WhisperDecoderInit</a>|<a class="el" href="classwhisper_1_1whisper__encoder__decoder__init_1_1WhisperEncoderDecoderInit.html">WhisperEncoderDecoderInit</a> model, torch.device device, str onnx_model_path, bool verbose=True, bool use_external_data_format=False, bool use_decoder_input_ids=True, bool use_int32_inputs=False)</td></tr>
<tr class="separator:accb96d0f31a4201db304b844b9946a54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab054a6e48432392a1f2460c408e78c8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#aab054a6e48432392a1f2460c408e78c8">auto_mixed_precision</a> (OnnxModel onnx_model, tuple[str] op_block_list=(&quot;SimplifiedLayerNormalization&quot;, &quot;SkipSimplifiedLayerNormalization&quot;, &quot;Relu&quot;, &quot;Add&quot;,))</td></tr>
<tr class="separator:aab054a6e48432392a1f2460c408e78c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac561a74fb2fa264fcfa62cb11413679d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#ac561a74fb2fa264fcfa62cb11413679d">optimize_onnx</a> (str onnx_model_path, str optimized_model_path, bool is_float16, int num_attention_heads, int hidden_size, bool use_external_data_format=False, bool <a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#aab054a6e48432392a1f2460c408e78c8">auto_mixed_precision</a>=True, bool use_gpu=False, str provider=&quot;cpu&quot;)</td></tr>
<tr class="separator:ac561a74fb2fa264fcfa62cb11413679d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc547d80fb6a1639d6d747da18c397fb"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#afc547d80fb6a1639d6d747da18c397fb">pt_transcription_for_verify_onnx</a> (WhisperProcessor processor, torch.nn.Module pt_model, torch.device device, int batch_size=1, bool prompt_mode=False)</td></tr>
<tr class="separator:afc547d80fb6a1639d6d747da18c397fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d34c919a8a91aaec3a8866d90d7cdc3"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#a8d34c919a8a91aaec3a8866d90d7cdc3">select_transcription_options</a> (int batch_size, bool prompt_mode)</td></tr>
<tr class="separator:a8d34c919a8a91aaec3a8866d90d7cdc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af762d2b4ffcd9dfd40a2acfa1a12eb12"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#af762d2b4ffcd9dfd40a2acfa1a12eb12">verify_onnx</a> (str model_name_or_path, str cache_dir, InferenceSession ort_session, torch.device device, int batch_size=1, bool prompt_mode=False)</td></tr>
<tr class="separator:af762d2b4ffcd9dfd40a2acfa1a12eb12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59524c9280508e9413b406fd34ab94b4"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#a59524c9280508e9413b406fd34ab94b4">get_onnx_path</a> (str output_dir, str model_name_or_path, str suffix=&quot;&quot;, bool new_folder=False)</td></tr>
<tr class="separator:a59524c9280508e9413b406fd34ab94b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaef7ebf9cf0e083f2dfffda9d60f292a"><td class="memItemLeft" align="right" valign="top">torch.nn.Module&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#aaef7ebf9cf0e083f2dfffda9d60f292a">load_model_openai</a> (str model_name_or_path, str cache_dir, torch.device device)</td></tr>
<tr class="separator:aaef7ebf9cf0e083f2dfffda9d60f292a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9415e344ea12a2cd93d1f6815260f24d"><td class="memItemLeft" align="right" valign="top">dict[str, torch.nn.Module]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#a9415e344ea12a2cd93d1f6815260f24d">load_model</a> (str model_name_or_path, str model_impl, str cache_dir, torch.device device, bool merge_encoder_and_decoder_init=True)</td></tr>
<tr class="separator:a9415e344ea12a2cd93d1f6815260f24d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:accb96d0f31a4201db304b844b9946a54"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#accb96d0f31a4201db304b844b9946a54">export_onnx</a> (<a class="el" href="classwhisper_1_1whisper__encoder_1_1WhisperEncoder.html">WhisperEncoder</a>|<a class="el" href="classwhisper_1_1whisper__decoder_1_1WhisperDecoder.html">WhisperDecoder</a>|<a class="el" href="classwhisper_1_1whisper__decoder_1_1WhisperDecoderInit.html">WhisperDecoderInit</a>|<a class="el" href="classwhisper_1_1whisper__encoder__decoder__init_1_1WhisperEncoderDecoderInit.html">WhisperEncoderDecoderInit</a> model, torch.device device, str onnx_model_path, bool verbose=True, bool use_external_data_format=False, bool use_decoder_input_ids=True, bool use_int32_inputs=False)</td></tr>
<tr class="separator:accb96d0f31a4201db304b844b9946a54"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aab054a6e48432392a1f2460c408e78c8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#aab054a6e48432392a1f2460c408e78c8">auto_mixed_precision</a> (OnnxModel onnx_model, tuple[str] op_block_list=(&quot;SimplifiedLayerNormalization&quot;, &quot;SkipSimplifiedLayerNormalization&quot;, &quot;Relu&quot;, &quot;Add&quot;,))</td></tr>
<tr class="separator:aab054a6e48432392a1f2460c408e78c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac561a74fb2fa264fcfa62cb11413679d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#ac561a74fb2fa264fcfa62cb11413679d">optimize_onnx</a> (str onnx_model_path, str optimized_model_path, bool is_float16, int num_attention_heads, int hidden_size, bool use_external_data_format=False, bool <a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#aab054a6e48432392a1f2460c408e78c8">auto_mixed_precision</a>=True, bool use_gpu=False, str provider=&quot;cpu&quot;)</td></tr>
<tr class="separator:ac561a74fb2fa264fcfa62cb11413679d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc547d80fb6a1639d6d747da18c397fb"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#afc547d80fb6a1639d6d747da18c397fb">pt_transcription_for_verify_onnx</a> (WhisperProcessor processor, torch.nn.Module pt_model, torch.device device, int batch_size=1, bool prompt_mode=False)</td></tr>
<tr class="separator:afc547d80fb6a1639d6d747da18c397fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d34c919a8a91aaec3a8866d90d7cdc3"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#a8d34c919a8a91aaec3a8866d90d7cdc3">select_transcription_options</a> (int batch_size, bool prompt_mode)</td></tr>
<tr class="separator:a8d34c919a8a91aaec3a8866d90d7cdc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af762d2b4ffcd9dfd40a2acfa1a12eb12"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classwhisper_1_1whisper__helper_1_1WhisperHelper.html#af762d2b4ffcd9dfd40a2acfa1a12eb12">verify_onnx</a> (str model_name_or_path, str cache_dir, InferenceSession ort_session, torch.device device, int batch_size=1, bool prompt_mode=False)</td></tr>
<tr class="separator:af762d2b4ffcd9dfd40a2acfa1a12eb12"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aab054a6e48432392a1f2460c408e78c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab054a6e48432392a1f2460c408e78c8">&#9670;&nbsp;</a></span>auto_mixed_precision() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.auto_mixed_precision </td>
          <td>(</td>
          <td class="paramtype">OnnxModel&#160;</td>
          <td class="paramname"><em>onnx_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">tuple[str] &#160;</td>
          <td class="paramname"><em>op_block_list</em> = <code>(
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SimplifiedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SkipSimplifiedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Relu&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Add&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;)</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Convert model to mixed precision.
   It detects whether original model has fp16 precision weights, and set parameters for float16 conversion automatically.
Args:
    onnx_model (OnnxModel): optimized ONNX model
    op_block_list (List[str], optional): . Defaults to ["SimplifiedLayerNormalization", "SkipSimplifiedLayerNormalization", "Relu", "Add"]
Returns:
    parameters(dict): a dictionary of parameters used in float16 conversion
</pre> 
</div>
</div>
<a id="aab054a6e48432392a1f2460c408e78c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab054a6e48432392a1f2460c408e78c8">&#9670;&nbsp;</a></span>auto_mixed_precision() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.auto_mixed_precision </td>
          <td>(</td>
          <td class="paramtype">OnnxModel&#160;</td>
          <td class="paramname"><em>onnx_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">tuple[str] &#160;</td>
          <td class="paramname"><em>op_block_list</em> = <code>(
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SimplifiedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SkipSimplifiedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Relu&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Add&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;)</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Convert model to mixed precision.
   It detects whether original model has fp16 precision weights, and set parameters for float16 conversion automatically.
Args:
    onnx_model (OnnxModel): optimized ONNX model
    op_block_list (List[str], optional): . Defaults to ["SimplifiedLayerNormalization", "SkipSimplifiedLayerNormalization", "Relu", "Add"]
Returns:
    parameters(dict): a dictionary of parameters used in float16 conversion
</pre> 
</div>
</div>
<a id="accb96d0f31a4201db304b844b9946a54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#accb96d0f31a4201db304b844b9946a54">&#9670;&nbsp;</a></span>export_onnx() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.export_onnx </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classwhisper_1_1whisper__encoder_1_1WhisperEncoder.html">WhisperEncoder</a> | <a class="el" href="classwhisper_1_1whisper__decoder_1_1WhisperDecoder.html">WhisperDecoder</a> | <a class="el" href="classwhisper_1_1whisper__decoder_1_1WhisperDecoderInit.html">WhisperDecoderInit</a> | <a class="el" href="classwhisper_1_1whisper__encoder__decoder__init_1_1WhisperEncoderDecoderInit.html">WhisperEncoderDecoderInit</a>&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>verbose</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_decoder_input_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_int32_inputs</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="accb96d0f31a4201db304b844b9946a54"></a>
<h2 class="memtitle"><span class="permalink"><a href="#accb96d0f31a4201db304b844b9946a54">&#9670;&nbsp;</a></span>export_onnx() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.export_onnx </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classwhisper_1_1whisper__encoder_1_1WhisperEncoder.html">WhisperEncoder</a> | <a class="el" href="classwhisper_1_1whisper__decoder_1_1WhisperDecoder.html">WhisperDecoder</a> | <a class="el" href="classwhisper_1_1whisper__decoder_1_1WhisperDecoderInit.html">WhisperDecoderInit</a> | <a class="el" href="classwhisper_1_1whisper__encoder__decoder__init_1_1WhisperEncoderDecoderInit.html">WhisperEncoderDecoderInit</a>&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>verbose</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_decoder_input_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_int32_inputs</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a59524c9280508e9413b406fd34ab94b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59524c9280508e9413b406fd34ab94b4">&#9670;&nbsp;</a></span>get_onnx_path() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> str whisper.whisper_helper.WhisperHelper.get_onnx_path </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>output_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>suffix</em> = <code>&quot;&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>new_folder</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Build onnx path

Args:
    output_dir (str): output directory
    model_name_or_path (str): pretrained model name, or path to the model checkpoint
    suffix (str, optional): suffix like "_encoder" or "_decoder_fp16" will be appended to file name. Defaults to None.
    new_folder (bool, optional): create a new directory for the model. Defaults to False.

Returns:
    str: path of onnx model
</pre> 
</div>
</div>
<a id="a59524c9280508e9413b406fd34ab94b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59524c9280508e9413b406fd34ab94b4">&#9670;&nbsp;</a></span>get_onnx_path() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> str whisper.whisper_helper.WhisperHelper.get_onnx_path </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>output_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>suffix</em> = <code>&quot;&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>new_folder</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Build onnx path

Args:
    output_dir (str): output directory
    model_name_or_path (str): pretrained model name, or path to the model checkpoint
    suffix (str, optional): suffix like "_encoder" or "_decoder_fp16" will be appended to file name. Defaults to None.
    new_folder (bool, optional): create a new directory for the model. Defaults to False.

Returns:
    str: path of onnx model
</pre> 
</div>
</div>
<a id="a9415e344ea12a2cd93d1f6815260f24d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9415e344ea12a2cd93d1f6815260f24d">&#9670;&nbsp;</a></span>load_model() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> dict[str, torch.nn.Module] whisper.whisper_helper.WhisperHelper.load_model </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_impl</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>cache_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>merge_encoder_and_decoder_init</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Load model given a pretrained name or path, then build models for ONNX conversion.

Args:
    model_name_or_path (str): pretrained model name or path
    cache_dir (str): cache directory
    device (torch.device): device to run the model
    merge_encoder_and_decoder_init (bool, optional): Whether merge encoder and decoder initialization into one ONNX model. Defaults to True.
Returns:
    Dict[str, torch.nn.Module]: mapping from name to modules for ONNX conversion.
</pre> 
</div>
</div>
<a id="a9415e344ea12a2cd93d1f6815260f24d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9415e344ea12a2cd93d1f6815260f24d">&#9670;&nbsp;</a></span>load_model() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> dict[str, torch.nn.Module] whisper.whisper_helper.WhisperHelper.load_model </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_impl</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>cache_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>merge_encoder_and_decoder_init</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Load model given a pretrained name or path, then build models for ONNX conversion.

Args:
    model_name_or_path (str): pretrained model name or path
    cache_dir (str): cache directory
    device (torch.device): device to run the model
    merge_encoder_and_decoder_init (bool, optional): Whether merge encoder and decoder initialization into one ONNX model. Defaults to True.
Returns:
    Dict[str, torch.nn.Module]: mapping from name to modules for ONNX conversion.
</pre> 
</div>
</div>
<a id="aaef7ebf9cf0e083f2dfffda9d60f292a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaef7ebf9cf0e083f2dfffda9d60f292a">&#9670;&nbsp;</a></span>load_model_openai() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> torch.nn.Module whisper.whisper_helper.WhisperHelper.load_model_openai </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>cache_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Load model given a pretrained name or path, then build models for ONNX conversion.

Args:
    model_name_or_path (str): pretrained model name or path
    cache_dir (str): cache directory
    device (torch.device): device to run the model
    merge_encoder_and_decoder_init (bool, optional): Whether merge encoder and decoder initialization into one ONNX model. Defaults to True.
Returns:
    Dict[str, torch.nn.Module]: mapping from name to modules for ONNX conversion.
</pre> 
</div>
</div>
<a id="aaef7ebf9cf0e083f2dfffda9d60f292a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaef7ebf9cf0e083f2dfffda9d60f292a">&#9670;&nbsp;</a></span>load_model_openai() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> torch.nn.Module whisper.whisper_helper.WhisperHelper.load_model_openai </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>cache_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Load model given a pretrained name or path, then build models for ONNX conversion.

Args:
    model_name_or_path (str): pretrained model name or path
    cache_dir (str): cache directory
    device (torch.device): device to run the model
    merge_encoder_and_decoder_init (bool, optional): Whether merge encoder and decoder initialization into one ONNX model. Defaults to True.
Returns:
    Dict[str, torch.nn.Module]: mapping from name to modules for ONNX conversion.
</pre> 
</div>
</div>
<a id="ac561a74fb2fa264fcfa62cb11413679d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac561a74fb2fa264fcfa62cb11413679d">&#9670;&nbsp;</a></span>optimize_onnx() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.optimize_onnx </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>optimized_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>is_float16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_attention_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>auto_mixed_precision</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_gpu</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>provider</em> = <code>&quot;cpu&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Optimize ONNX model with an option to convert it to use mixed precision.</pre> 
</div>
</div>
<a id="ac561a74fb2fa264fcfa62cb11413679d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac561a74fb2fa264fcfa62cb11413679d">&#9670;&nbsp;</a></span>optimize_onnx() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.optimize_onnx </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>optimized_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>is_float16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_attention_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>auto_mixed_precision</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_gpu</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>provider</em> = <code>&quot;cpu&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Optimize ONNX model with an option to convert it to use mixed precision.</pre> 
</div>
</div>
<a id="afc547d80fb6a1639d6d747da18c397fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afc547d80fb6a1639d6d747da18c397fb">&#9670;&nbsp;</a></span>pt_transcription_for_verify_onnx() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.pt_transcription_for_verify_onnx </td>
          <td>(</td>
          <td class="paramtype">WhisperProcessor&#160;</td>
          <td class="paramname"><em>processor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.nn.Module&#160;</td>
          <td class="paramname"><em>pt_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>batch_size</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>prompt_mode</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="afc547d80fb6a1639d6d747da18c397fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afc547d80fb6a1639d6d747da18c397fb">&#9670;&nbsp;</a></span>pt_transcription_for_verify_onnx() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.pt_transcription_for_verify_onnx </td>
          <td>(</td>
          <td class="paramtype">WhisperProcessor&#160;</td>
          <td class="paramname"><em>processor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.nn.Module&#160;</td>
          <td class="paramname"><em>pt_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>batch_size</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>prompt_mode</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a8d34c919a8a91aaec3a8866d90d7cdc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d34c919a8a91aaec3a8866d90d7cdc3">&#9670;&nbsp;</a></span>select_transcription_options() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.select_transcription_options </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>prompt_mode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a8d34c919a8a91aaec3a8866d90d7cdc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d34c919a8a91aaec3a8866d90d7cdc3">&#9670;&nbsp;</a></span>select_transcription_options() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.select_transcription_options </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>prompt_mode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="af762d2b4ffcd9dfd40a2acfa1a12eb12"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af762d2b4ffcd9dfd40a2acfa1a12eb12">&#9670;&nbsp;</a></span>verify_onnx() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.verify_onnx </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>cache_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InferenceSession&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>batch_size</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>prompt_mode</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compare the result from PyTorch and ONNX Runtime to verify the ONNX model is good.</pre> 
</div>
</div>
<a id="af762d2b4ffcd9dfd40a2acfa1a12eb12"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af762d2b4ffcd9dfd40a2acfa1a12eb12">&#9670;&nbsp;</a></span>verify_onnx() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def whisper.whisper_helper.WhisperHelper.verify_onnx </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>cache_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InferenceSession&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>batch_size</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>prompt_mode</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compare the result from PyTorch and ONNX Runtime to verify the ONNX model is good.</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>chromadb_rest_wrapper/venv/lib/python3.10/site-packages/onnxruntime/transformers/models/whisper/<a class="el" href="chromadb__rest__wrapper_2venv_2lib_2python3_810_2site-packages_2onnxruntime_2transformers_2models_2whisper_2whisper__helper_8py.html">whisper_helper.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
