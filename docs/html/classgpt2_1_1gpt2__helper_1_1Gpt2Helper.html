<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: gpt2.gpt2_helper.Gpt2Helper Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacegpt2.html">gpt2</a></li><li class="navelem"><a class="el" href="namespacegpt2_1_1gpt2__helper.html">gpt2_helper</a></li><li class="navelem"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html">Gpt2Helper</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">gpt2.gpt2_helper.Gpt2Helper Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a346eb791dab571f1f11b1c9676767f3a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a346eb791dab571f1f11b1c9676767f3a">get_dummy_inputs</a> (int batch_size, int past_sequence_length, int sequence_length, int num_attention_heads, int hidden_size, int num_layer, int vocab_size, torch.device device, bool float16=False, bool has_position_ids=True, bool has_attention_mask=True, torch.dtype input_ids_dtype=torch.int32, torch.dtype position_ids_dtype=torch.int32, torch.dtype attention_mask_dtype=torch.int32, bool left_side_padding=True)</td></tr>
<tr class="separator:a346eb791dab571f1f11b1c9676767f3a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27f40b2bcd85189e4ae2b91436db4863"><td class="memItemLeft" align="right" valign="top">dict[str, list[int]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a27f40b2bcd85189e4ae2b91436db4863">get_output_shapes</a> (int batch_size, int past_sequence_length, int sequence_length, GPT2Config config, str model_class=&quot;GPT2LMHeadModel&quot;)</td></tr>
<tr class="separator:a27f40b2bcd85189e4ae2b91436db4863"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af387e3526f829df8c587ab168aac7647"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#af387e3526f829df8c587ab168aac7647">auto_increase_buffer_size</a> (output_buffers, output_shapes)</td></tr>
<tr class="separator:af387e3526f829df8c587ab168aac7647"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e16cfeea9618d6f00015948862af62a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a3e16cfeea9618d6f00015948862af62a">get_output_buffers</a> (output_shapes, device, is_float16=False)</td></tr>
<tr class="separator:a3e16cfeea9618d6f00015948862af62a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03680dc6cc867f388c79f8781eabccfb"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a03680dc6cc867f388c79f8781eabccfb">diff_outputs</a> (torch_outputs, ort_outputs, relative=False)</td></tr>
<tr class="separator:a03680dc6cc867f388c79f8781eabccfb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64155a123341cdd2eb7482a13921d6d1"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a64155a123341cdd2eb7482a13921d6d1">compare_outputs</a> (torch_outputs, ort_outputs, rtol=1e-03, atol=1e-03, **kwargs)</td></tr>
<tr class="separator:a64155a123341cdd2eb7482a13921d6d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4f679570c9e0dc6d688362160e899bc"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#ae4f679570c9e0dc6d688362160e899bc">compare_outputs_v2</a> (torch_outputs, ort_outputs, atol=1e-06)</td></tr>
<tr class="separator:ae4f679570c9e0dc6d688362160e899bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c2274b1205a9d61a09908d46507a004"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a9c2274b1205a9d61a09908d46507a004">export_onnx</a> (model, device, str onnx_model_path, bool verbose=False, bool use_external_data_format=False, bool has_position_ids=True, bool has_attention_mask=True, torch.dtype input_ids_dtype=torch.int32, torch.dtype position_ids_dtype=torch.int32, torch.dtype attention_mask_dtype=torch.int32)</td></tr>
<tr class="separator:a9c2274b1205a9d61a09908d46507a004"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cf9247468ab12ea15129bc0b26fa883"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a6cf9247468ab12ea15129bc0b26fa883">optimize_onnx</a> (onnx_model_path, optimized_model_path, is_float16, num_attention_heads, hidden_size, use_external_data_format=False, <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a5af264c33515195b79acb995314fb682">auto_mixed_precision</a>=False, stage=0, **kwargs)</td></tr>
<tr class="separator:a6cf9247468ab12ea15129bc0b26fa883"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5af264c33515195b79acb995314fb682"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a5af264c33515195b79acb995314fb682">auto_mixed_precision</a> (OnnxModel onnx_model, list[str] op_block_list=[# noqa:B006 &quot;Add&quot;, &quot;LayerNormalization&quot;, &quot;SkipLayerNormalization&quot;, &quot;FastGelu&quot;, &quot;EmbedLayerNormalization&quot;,])</td></tr>
<tr class="separator:a5af264c33515195b79acb995314fb682"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af64512ae0fcb757e27cc2cb10a855f77"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#af64512ae0fcb757e27cc2cb10a855f77">pytorch_inference</a> (model, <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a> inputs, int total_runs=0)</td></tr>
<tr class="separator:af64512ae0fcb757e27cc2cb10a855f77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5ad28464860ff0d926f71c5b6a1ebe1"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#aa5ad28464860ff0d926f71c5b6a1ebe1">onnxruntime_inference</a> (ort_session, <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a> inputs, int total_runs=0)</td></tr>
<tr class="separator:aa5ad28464860ff0d926f71c5b6a1ebe1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79464ad545285ccfcd5681a4dcfc9b72"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a79464ad545285ccfcd5681a4dcfc9b72">prepare_io_binding</a> (ort_session, input_ids, position_ids, attention_mask, past, output_buffers, output_shapes)</td></tr>
<tr class="separator:a79464ad545285ccfcd5681a4dcfc9b72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c9cec46430b390cddbe0e90b80572b8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a9c9cec46430b390cddbe0e90b80572b8">get_outputs_from_io_binding_buffer</a> (ort_session, output_buffers, output_shapes, return_numpy=True)</td></tr>
<tr class="separator:a9c9cec46430b390cddbe0e90b80572b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaee6fa3bc141f892959ca46779734529"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#aaee6fa3bc141f892959ca46779734529">onnxruntime_inference_with_binded_io</a> (ort_session, <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a> inputs, dict[str, torch.Tensor] output_buffers, dict[str, list[int]] output_shapes, int total_runs=0, bool return_numpy=True, bool include_copy_output_latency=False)</td></tr>
<tr class="separator:aaee6fa3bc141f892959ca46779734529"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff4fef15a9a834210c4f08349f8b26a4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#aff4fef15a9a834210c4f08349f8b26a4">save_outputs</a> (i, ort_outputs, torch_outputs)</td></tr>
<tr class="separator:aff4fef15a9a834210c4f08349f8b26a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0385c861419a62dd154bf49989c1ded3"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a0385c861419a62dd154bf49989c1ded3">save_inputs</a> (i, dummy_inputs, ort_outputs, torch_outputs)</td></tr>
<tr class="separator:a0385c861419a62dd154bf49989c1ded3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abca7263a2addd80a7f674b16a7144964"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#abca7263a2addd80a7f674b16a7144964">test_parity</a> (ort_session, model, device, is_float16=False, rtol=5e-4, atol=5e-4, test_cases_per_run=10000, total_runs=1, use_io_binding=True, model_class=&quot;GPT2LMHeadModel&quot;, has_position_ids=True, has_attention_mask=True, input_ids_dtype=torch.int32, position_ids_dtype=torch.int32, attention_mask_dtype=torch.int32, stage=0, verbose=False, enable_pickle_output=False)</td></tr>
<tr class="separator:abca7263a2addd80a7f674b16a7144964"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a640d5447e300b36c9f0b0a4a9294aa9e"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a640d5447e300b36c9f0b0a4a9294aa9e">test_performance</a> (ort_session, model, device, is_float16=False, total_runs=100, use_io_binding=True, model_class=&quot;GPT2LMHeadModel&quot;, has_position_ids=True, has_attention_mask=True, input_ids_dtype=torch.int32, position_ids_dtype=torch.int32, attention_mask_dtype=torch.int32, batch_size=8, sequence_length=1, past_sequence_length=32)</td></tr>
<tr class="separator:a640d5447e300b36c9f0b0a4a9294aa9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4774e0364f42d2f480f13e20af6ac8ee"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a4774e0364f42d2f480f13e20af6ac8ee">torchscript</a> (model, config, device, has_position_ids=True, has_attention_mask=True)</td></tr>
<tr class="separator:a4774e0364f42d2f480f13e20af6ac8ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0841a5445e7719cedf909b59ae8e1ef"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#aa0841a5445e7719cedf909b59ae8e1ef">get_onnx_paths</a> (output_dir, model_name_or_path, str model_class=&quot;GPT2LMHeadModel&quot;, has_past=True, new_folder=False, remove_existing=[&quot;raw&quot;, &quot;fp32&quot;, &quot;fp16&quot;, &quot;int8&quot;])</td></tr>
<tr class="separator:aa0841a5445e7719cedf909b59ae8e1ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a346eb791dab571f1f11b1c9676767f3a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a346eb791dab571f1f11b1c9676767f3a">get_dummy_inputs</a> (int batch_size, int past_sequence_length, int sequence_length, int num_attention_heads, int hidden_size, int num_layer, int vocab_size, torch.device device, bool float16=False, bool has_position_ids=True, bool has_attention_mask=True, torch.dtype input_ids_dtype=torch.int32, torch.dtype position_ids_dtype=torch.int32, torch.dtype attention_mask_dtype=torch.int32, bool left_side_padding=True)</td></tr>
<tr class="separator:a346eb791dab571f1f11b1c9676767f3a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27f40b2bcd85189e4ae2b91436db4863"><td class="memItemLeft" align="right" valign="top">dict[str, list[int]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a27f40b2bcd85189e4ae2b91436db4863">get_output_shapes</a> (int batch_size, int past_sequence_length, int sequence_length, GPT2Config config, str model_class=&quot;GPT2LMHeadModel&quot;)</td></tr>
<tr class="separator:a27f40b2bcd85189e4ae2b91436db4863"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af387e3526f829df8c587ab168aac7647"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#af387e3526f829df8c587ab168aac7647">auto_increase_buffer_size</a> (output_buffers, output_shapes)</td></tr>
<tr class="separator:af387e3526f829df8c587ab168aac7647"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e16cfeea9618d6f00015948862af62a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a3e16cfeea9618d6f00015948862af62a">get_output_buffers</a> (output_shapes, device, is_float16=False)</td></tr>
<tr class="separator:a3e16cfeea9618d6f00015948862af62a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a03680dc6cc867f388c79f8781eabccfb"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a03680dc6cc867f388c79f8781eabccfb">diff_outputs</a> (torch_outputs, ort_outputs, relative=False)</td></tr>
<tr class="separator:a03680dc6cc867f388c79f8781eabccfb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64155a123341cdd2eb7482a13921d6d1"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a64155a123341cdd2eb7482a13921d6d1">compare_outputs</a> (torch_outputs, ort_outputs, rtol=1e-03, atol=1e-03, **kwargs)</td></tr>
<tr class="separator:a64155a123341cdd2eb7482a13921d6d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4f679570c9e0dc6d688362160e899bc"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#ae4f679570c9e0dc6d688362160e899bc">compare_outputs_v2</a> (torch_outputs, ort_outputs, atol=1e-06)</td></tr>
<tr class="separator:ae4f679570c9e0dc6d688362160e899bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c2274b1205a9d61a09908d46507a004"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a9c2274b1205a9d61a09908d46507a004">export_onnx</a> (model, device, str onnx_model_path, bool verbose=False, bool use_external_data_format=False, bool has_position_ids=True, bool has_attention_mask=True, torch.dtype input_ids_dtype=torch.int32, torch.dtype position_ids_dtype=torch.int32, torch.dtype attention_mask_dtype=torch.int32)</td></tr>
<tr class="separator:a9c2274b1205a9d61a09908d46507a004"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cf9247468ab12ea15129bc0b26fa883"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a6cf9247468ab12ea15129bc0b26fa883">optimize_onnx</a> (onnx_model_path, optimized_model_path, is_float16, num_attention_heads, hidden_size, use_external_data_format=False, <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a5af264c33515195b79acb995314fb682">auto_mixed_precision</a>=False, stage=0, **kwargs)</td></tr>
<tr class="separator:a6cf9247468ab12ea15129bc0b26fa883"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5af264c33515195b79acb995314fb682"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a5af264c33515195b79acb995314fb682">auto_mixed_precision</a> (OnnxModel onnx_model, list[str] op_block_list=[# noqa:B006 &quot;Add&quot;, &quot;LayerNormalization&quot;, &quot;SkipLayerNormalization&quot;, &quot;FastGelu&quot;, &quot;EmbedLayerNormalization&quot;,])</td></tr>
<tr class="separator:a5af264c33515195b79acb995314fb682"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af64512ae0fcb757e27cc2cb10a855f77"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#af64512ae0fcb757e27cc2cb10a855f77">pytorch_inference</a> (model, <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a> inputs, int total_runs=0)</td></tr>
<tr class="separator:af64512ae0fcb757e27cc2cb10a855f77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5ad28464860ff0d926f71c5b6a1ebe1"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#aa5ad28464860ff0d926f71c5b6a1ebe1">onnxruntime_inference</a> (ort_session, <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a> inputs, int total_runs=0)</td></tr>
<tr class="separator:aa5ad28464860ff0d926f71c5b6a1ebe1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a79464ad545285ccfcd5681a4dcfc9b72"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a79464ad545285ccfcd5681a4dcfc9b72">prepare_io_binding</a> (ort_session, input_ids, position_ids, attention_mask, past, output_buffers, output_shapes)</td></tr>
<tr class="separator:a79464ad545285ccfcd5681a4dcfc9b72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9c9cec46430b390cddbe0e90b80572b8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a9c9cec46430b390cddbe0e90b80572b8">get_outputs_from_io_binding_buffer</a> (ort_session, output_buffers, output_shapes, return_numpy=True)</td></tr>
<tr class="separator:a9c9cec46430b390cddbe0e90b80572b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaee6fa3bc141f892959ca46779734529"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#aaee6fa3bc141f892959ca46779734529">onnxruntime_inference_with_binded_io</a> (ort_session, <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a> inputs, dict[str, torch.Tensor] output_buffers, dict[str, list[int]] output_shapes, int total_runs=0, bool return_numpy=True, bool include_copy_output_latency=False)</td></tr>
<tr class="separator:aaee6fa3bc141f892959ca46779734529"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff4fef15a9a834210c4f08349f8b26a4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#aff4fef15a9a834210c4f08349f8b26a4">save_outputs</a> (i, ort_outputs, torch_outputs)</td></tr>
<tr class="separator:aff4fef15a9a834210c4f08349f8b26a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0385c861419a62dd154bf49989c1ded3"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a0385c861419a62dd154bf49989c1ded3">save_inputs</a> (i, dummy_inputs, ort_outputs, torch_outputs)</td></tr>
<tr class="separator:a0385c861419a62dd154bf49989c1ded3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abca7263a2addd80a7f674b16a7144964"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#abca7263a2addd80a7f674b16a7144964">test_parity</a> (ort_session, model, device, is_float16=False, rtol=5e-4, atol=5e-4, test_cases_per_run=10000, total_runs=1, use_io_binding=True, model_class=&quot;GPT2LMHeadModel&quot;, has_position_ids=True, has_attention_mask=True, input_ids_dtype=torch.int32, position_ids_dtype=torch.int32, attention_mask_dtype=torch.int32, stage=0, verbose=False, enable_pickle_output=False)</td></tr>
<tr class="separator:abca7263a2addd80a7f674b16a7144964"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a640d5447e300b36c9f0b0a4a9294aa9e"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a640d5447e300b36c9f0b0a4a9294aa9e">test_performance</a> (ort_session, model, device, is_float16=False, total_runs=100, use_io_binding=True, model_class=&quot;GPT2LMHeadModel&quot;, has_position_ids=True, has_attention_mask=True, input_ids_dtype=torch.int32, position_ids_dtype=torch.int32, attention_mask_dtype=torch.int32, batch_size=8, sequence_length=1, past_sequence_length=32)</td></tr>
<tr class="separator:a640d5447e300b36c9f0b0a4a9294aa9e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4774e0364f42d2f480f13e20af6ac8ee"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#a4774e0364f42d2f480f13e20af6ac8ee">torchscript</a> (model, config, device, has_position_ids=True, has_attention_mask=True)</td></tr>
<tr class="separator:a4774e0364f42d2f480f13e20af6ac8ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0841a5445e7719cedf909b59ae8e1ef"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Helper.html#aa0841a5445e7719cedf909b59ae8e1ef">get_onnx_paths</a> (output_dir, model_name_or_path, str model_class=&quot;GPT2LMHeadModel&quot;, has_past=True, new_folder=False, remove_existing=[&quot;raw&quot;, &quot;fp32&quot;, &quot;fp16&quot;, &quot;int8&quot;])</td></tr>
<tr class="separator:aa0841a5445e7719cedf909b59ae8e1ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">A helper class for Gpt2 model conversion, inference and verification.</pre> </div><h2 class="groupheader">Member Function Documentation</h2>
<a id="af387e3526f829df8c587ab168aac7647"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af387e3526f829df8c587ab168aac7647">&#9670;&nbsp;</a></span>auto_increase_buffer_size() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.auto_increase_buffer_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_buffers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_shapes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="af387e3526f829df8c587ab168aac7647"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af387e3526f829df8c587ab168aac7647">&#9670;&nbsp;</a></span>auto_increase_buffer_size() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.auto_increase_buffer_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_buffers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_shapes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a5af264c33515195b79acb995314fb682"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5af264c33515195b79acb995314fb682">&#9670;&nbsp;</a></span>auto_mixed_precision() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.auto_mixed_precision </td>
          <td>(</td>
          <td class="paramtype">OnnxModel&#160;</td>
          <td class="paramname"><em>onnx_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[str] &#160;</td>
          <td class="paramname"><em>op_block_list</em> = <code>[&#160;&#160;#&#160;noqa:&#160;B006
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Add&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;LayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SkipLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;FastGelu&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;EmbedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;]</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Convert GPT-2 model to mixed precision.
   It detects whether original model has fp16 weights, and set parameters for float16 conversion automatically.
Args:
    onnx_model (OnnxModel): optimized ONNX model
    op_block_list (List[str], optional): operators to compute in fp32. Defaults to ["Add", "LayerNormalization",
                                         "SkipLayerNormalization", "FastGelu", "EmbedLayerNormalization"]
Returns:
    parameters(dict): a dictionary of parameters used in float16 conversion
</pre> 
</div>
</div>
<a id="a5af264c33515195b79acb995314fb682"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5af264c33515195b79acb995314fb682">&#9670;&nbsp;</a></span>auto_mixed_precision() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.auto_mixed_precision </td>
          <td>(</td>
          <td class="paramtype">OnnxModel&#160;</td>
          <td class="paramname"><em>onnx_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[str] &#160;</td>
          <td class="paramname"><em>op_block_list</em> = <code>[&#160;&#160;#&#160;noqa:&#160;B006
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;Add&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;LayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;SkipLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;FastGelu&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&quot;EmbedLayerNormalization&quot;,
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;]</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Convert GPT-2 model to mixed precision.
   It detects whether original model has fp16 weights, and set parameters for float16 conversion automatically.
Args:
    onnx_model (OnnxModel): optimized ONNX model
    op_block_list (List[str], optional): operators to compute in fp32. Defaults to ["Add", "LayerNormalization",
                                         "SkipLayerNormalization", "FastGelu", "EmbedLayerNormalization"]
Returns:
    parameters(dict): a dictionary of parameters used in float16 conversion
</pre> 
</div>
</div>
<a id="a64155a123341cdd2eb7482a13921d6d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a64155a123341cdd2eb7482a13921d6d1">&#9670;&nbsp;</a></span>compare_outputs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.compare_outputs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rtol</em> = <code>1e-03</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>atol</em> = <code>1e-03</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns True if torch and ORT outputs are close for given thresholds, and False otherwise.
Note: need kwargs since Gpt2BeamSearchHelper.compare_outputs has an extra parameter model_class
</pre> 
</div>
</div>
<a id="a64155a123341cdd2eb7482a13921d6d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a64155a123341cdd2eb7482a13921d6d1">&#9670;&nbsp;</a></span>compare_outputs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.compare_outputs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rtol</em> = <code>1e-03</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>atol</em> = <code>1e-03</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns True if torch and ORT outputs are close for given thresholds, and False otherwise.
Note: need kwargs since Gpt2BeamSearchHelper.compare_outputs has an extra parameter model_class
</pre> 
</div>
</div>
<a id="ae4f679570c9e0dc6d688362160e899bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4f679570c9e0dc6d688362160e899bc">&#9670;&nbsp;</a></span>compare_outputs_v2() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.compare_outputs_v2 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>atol</em> = <code>1e-06</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compare outputs from PyTorch and OnnxRuntime

Args:
    torch_outputs (Tuple[Torch.Tensor]): PyTorch model output
    ort_outputs (List[numpy.ndarray]): OnnxRuntime output
    atol (float, optional): Absolute tollerance. Defaults to 1e-06.

Returns:
    is_all_close(bool): whether all elements are close.
    max_abs_diff(float): maximum absolute difference.
    messages(str): a list of debug message for each output
</pre> 
</div>
</div>
<a id="ae4f679570c9e0dc6d688362160e899bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4f679570c9e0dc6d688362160e899bc">&#9670;&nbsp;</a></span>compare_outputs_v2() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.compare_outputs_v2 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>atol</em> = <code>1e-06</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compare outputs from PyTorch and OnnxRuntime

Args:
    torch_outputs (Tuple[Torch.Tensor]): PyTorch model output
    ort_outputs (List[numpy.ndarray]): OnnxRuntime output
    atol (float, optional): Absolute tollerance. Defaults to 1e-06.

Returns:
    is_all_close(bool): whether all elements are close.
    max_abs_diff(float): maximum absolute difference.
    messages(str): a list of debug message for each output
</pre> 
</div>
</div>
<a id="a03680dc6cc867f388c79f8781eabccfb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03680dc6cc867f388c79f8781eabccfb">&#9670;&nbsp;</a></span>diff_outputs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.diff_outputs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>relative</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns the maximum difference between PyTorch and OnnxRuntime outputs.</pre> 
</div>
</div>
<a id="a03680dc6cc867f388c79f8781eabccfb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a03680dc6cc867f388c79f8781eabccfb">&#9670;&nbsp;</a></span>diff_outputs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.diff_outputs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>relative</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns the maximum difference between PyTorch and OnnxRuntime outputs.</pre> 
</div>
</div>
<a id="a9c2274b1205a9d61a09908d46507a004"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c2274b1205a9d61a09908d46507a004">&#9670;&nbsp;</a></span>export_onnx() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.export_onnx </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>input_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>position_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>attention_mask_dtype</em> = <code>torch.int32</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Export GPT-2 model with past state to ONNX model.</pre> 
</div>
</div>
<a id="a9c2274b1205a9d61a09908d46507a004"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c2274b1205a9d61a09908d46507a004">&#9670;&nbsp;</a></span>export_onnx() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.export_onnx </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>input_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>position_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>attention_mask_dtype</em> = <code>torch.int32</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Export GPT-2 model with past state to ONNX model.</pre> 
</div>
</div>
<a id="a346eb791dab571f1f11b1c9676767f3a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a346eb791dab571f1f11b1c9676767f3a">&#9670;&nbsp;</a></span>get_dummy_inputs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a> gpt2.gpt2_helper.Gpt2Helper.get_dummy_inputs </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>past_sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_attention_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>vocab_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>float16</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>input_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>position_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>attention_mask_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>left_side_padding</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Create random inputs for GPT2 model.
Returns torch tensors of input_ids, position_ids, attention_mask and a list of past state tensors.
</pre> 
</div>
</div>
<a id="a346eb791dab571f1f11b1c9676767f3a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a346eb791dab571f1f11b1c9676767f3a">&#9670;&nbsp;</a></span>get_dummy_inputs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> <a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a> gpt2.gpt2_helper.Gpt2Helper.get_dummy_inputs </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>past_sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_attention_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>vocab_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>float16</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>input_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>position_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.dtype &#160;</td>
          <td class="paramname"><em>attention_mask_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>left_side_padding</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Create random inputs for GPT2 model.
Returns torch tensors of input_ids, position_ids, attention_mask and a list of past state tensors.
</pre> 
</div>
</div>
<a id="aa0841a5445e7719cedf909b59ae8e1ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0841a5445e7719cedf909b59ae8e1ef">&#9670;&nbsp;</a></span>get_onnx_paths() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.get_onnx_paths </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>model_class</em> = <code>&quot;GPT2LMHeadModel&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_past</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>new_folder</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>remove_existing</em> = <code>[&quot;raw&quot;,&#160;&quot;fp32&quot;,&#160;&quot;fp16&quot;,&#160;&quot;int8&quot;]</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Build a  path name for given model based on given attributes.</pre> 
</div>
</div>
<a id="aa0841a5445e7719cedf909b59ae8e1ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0841a5445e7719cedf909b59ae8e1ef">&#9670;&nbsp;</a></span>get_onnx_paths() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.get_onnx_paths </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_name_or_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>model_class</em> = <code>&quot;GPT2LMHeadModel&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_past</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>new_folder</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>remove_existing</em> = <code>[&quot;raw&quot;,&#160;&quot;fp32&quot;,&#160;&quot;fp16&quot;,&#160;&quot;int8&quot;]</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Build a  path name for given model based on given attributes.</pre> 
</div>
</div>
<a id="a3e16cfeea9618d6f00015948862af62a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3e16cfeea9618d6f00015948862af62a">&#9670;&nbsp;</a></span>get_output_buffers() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.get_output_buffers </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_shapes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_float16</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns a dictionary of output name as key, and 1D tensor as value. The tensor has enough space for given shape.</pre> 
</div>
</div>
<a id="a3e16cfeea9618d6f00015948862af62a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3e16cfeea9618d6f00015948862af62a">&#9670;&nbsp;</a></span>get_output_buffers() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.get_output_buffers </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_shapes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_float16</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns a dictionary of output name as key, and 1D tensor as value. The tensor has enough space for given shape.</pre> 
</div>
</div>
<a id="a27f40b2bcd85189e4ae2b91436db4863"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a27f40b2bcd85189e4ae2b91436db4863">&#9670;&nbsp;</a></span>get_output_shapes() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> dict[str, list[int]] gpt2.gpt2_helper.Gpt2Helper.get_output_shapes </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>past_sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">GPT2Config&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>model_class</em> = <code>&quot;GPT2LMHeadModel&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns a dictionary with output name as key, and shape as value.</pre> 
</div>
</div>
<a id="a27f40b2bcd85189e4ae2b91436db4863"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a27f40b2bcd85189e4ae2b91436db4863">&#9670;&nbsp;</a></span>get_output_shapes() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"> dict[str, list[int]] gpt2.gpt2_helper.Gpt2Helper.get_output_shapes </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>past_sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>sequence_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">GPT2Config&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>model_class</em> = <code>&quot;GPT2LMHeadModel&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns a dictionary with output name as key, and shape as value.</pre> 
</div>
</div>
<a id="a9c9cec46430b390cddbe0e90b80572b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c9cec46430b390cddbe0e90b80572b8">&#9670;&nbsp;</a></span>get_outputs_from_io_binding_buffer() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.get_outputs_from_io_binding_buffer </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_buffers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_shapes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_numpy</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Copy results to cpu. Returns a list of numpy array.</pre> 
</div>
</div>
<a id="a9c9cec46430b390cddbe0e90b80572b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c9cec46430b390cddbe0e90b80572b8">&#9670;&nbsp;</a></span>get_outputs_from_io_binding_buffer() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.get_outputs_from_io_binding_buffer </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_buffers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_shapes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>return_numpy</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Copy results to cpu. Returns a list of numpy array.</pre> 
</div>
</div>
<a id="aa5ad28464860ff0d926f71c5b6a1ebe1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5ad28464860ff0d926f71c5b6a1ebe1">&#9670;&nbsp;</a></span>onnxruntime_inference() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.onnxruntime_inference </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a>&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Run inference of ONNX model, and returns average latency in ms when total_runs &gt; 0 besides outputs.</pre> 
</div>
</div>
<a id="aa5ad28464860ff0d926f71c5b6a1ebe1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5ad28464860ff0d926f71c5b6a1ebe1">&#9670;&nbsp;</a></span>onnxruntime_inference() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.onnxruntime_inference </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a>&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Run inference of ONNX model, and returns average latency in ms when total_runs &gt; 0 besides outputs.</pre> 
</div>
</div>
<a id="aaee6fa3bc141f892959ca46779734529"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaee6fa3bc141f892959ca46779734529">&#9670;&nbsp;</a></span>onnxruntime_inference_with_binded_io() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.onnxruntime_inference_with_binded_io </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a>&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict[str, torch.Tensor]&#160;</td>
          <td class="paramname"><em>output_buffers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict[str, list[int]]&#160;</td>
          <td class="paramname"><em>output_shapes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>return_numpy</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>include_copy_output_latency</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Inference with IO binding. Returns outputs, and optional latency when total_runs &gt; 0.</pre> 
</div>
</div>
<a id="aaee6fa3bc141f892959ca46779734529"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaee6fa3bc141f892959ca46779734529">&#9670;&nbsp;</a></span>onnxruntime_inference_with_binded_io() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.onnxruntime_inference_with_binded_io </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a>&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict[str, torch.Tensor]&#160;</td>
          <td class="paramname"><em>output_buffers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict[str, list[int]]&#160;</td>
          <td class="paramname"><em>output_shapes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>return_numpy</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>include_copy_output_latency</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Inference with IO binding. Returns outputs, and optional latency when total_runs &gt; 0.</pre> 
</div>
</div>
<a id="a6cf9247468ab12ea15129bc0b26fa883"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6cf9247468ab12ea15129bc0b26fa883">&#9670;&nbsp;</a></span>optimize_onnx() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.optimize_onnx </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>optimized_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_float16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_attention_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>auto_mixed_precision</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>stage</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Optimize ONNX model with an option to convert it to use mixed precision.</pre> 
</div>
</div>
<a id="a6cf9247468ab12ea15129bc0b26fa883"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6cf9247468ab12ea15129bc0b26fa883">&#9670;&nbsp;</a></span>optimize_onnx() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.optimize_onnx </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>onnx_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>optimized_model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_float16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_attention_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>auto_mixed_precision</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>stage</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Optimize ONNX model with an option to convert it to use mixed precision.</pre> 
</div>
</div>
<a id="a79464ad545285ccfcd5681a4dcfc9b72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79464ad545285ccfcd5681a4dcfc9b72">&#9670;&nbsp;</a></span>prepare_io_binding() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.prepare_io_binding </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_ids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>position_ids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>attention_mask</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>past</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_buffers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_shapes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returnas IO binding object for a session.</pre> 
</div>
</div>
<a id="a79464ad545285ccfcd5681a4dcfc9b72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a79464ad545285ccfcd5681a4dcfc9b72">&#9670;&nbsp;</a></span>prepare_io_binding() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.prepare_io_binding </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_ids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>position_ids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>attention_mask</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>past</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_buffers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_shapes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returnas IO binding object for a session.</pre> 
</div>
</div>
<a id="af64512ae0fcb757e27cc2cb10a855f77"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af64512ae0fcb757e27cc2cb10a855f77">&#9670;&nbsp;</a></span>pytorch_inference() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.pytorch_inference </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a>&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Run inference of PyTorch model, and returns average latency in ms when total_runs &gt; 0 besides outputs.</pre> 
</div>
</div>
<a id="af64512ae0fcb757e27cc2cb10a855f77"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af64512ae0fcb757e27cc2cb10a855f77">&#9670;&nbsp;</a></span>pytorch_inference() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.pytorch_inference </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classgpt2_1_1gpt2__helper_1_1Gpt2Inputs.html">Gpt2Inputs</a>&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Run inference of PyTorch model, and returns average latency in ms when total_runs &gt; 0 besides outputs.</pre> 
</div>
</div>
<a id="a0385c861419a62dd154bf49989c1ded3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0385c861419a62dd154bf49989c1ded3">&#9670;&nbsp;</a></span>save_inputs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.save_inputs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>i</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dummy_inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a0385c861419a62dd154bf49989c1ded3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0385c861419a62dd154bf49989c1ded3">&#9670;&nbsp;</a></span>save_inputs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.save_inputs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>i</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dummy_inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aff4fef15a9a834210c4f08349f8b26a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff4fef15a9a834210c4f08349f8b26a4">&#9670;&nbsp;</a></span>save_outputs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.save_outputs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>i</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aff4fef15a9a834210c4f08349f8b26a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff4fef15a9a834210c4f08349f8b26a4">&#9670;&nbsp;</a></span>save_outputs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.save_outputs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>i</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>torch_outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="abca7263a2addd80a7f674b16a7144964"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abca7263a2addd80a7f674b16a7144964">&#9670;&nbsp;</a></span>test_parity() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.test_parity </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_float16</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rtol</em> = <code>5e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>atol</em> = <code>5e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>test_cases_per_run</em> = <code>10000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>use_io_binding</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_class</em> = <code>&quot;GPT2LMHeadModel&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>position_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>attention_mask_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>stage</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>enable_pickle_output</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate random inputs and compare the results of PyTorch and Onnx Runtime.</pre> 
</div>
</div>
<a id="abca7263a2addd80a7f674b16a7144964"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abca7263a2addd80a7f674b16a7144964">&#9670;&nbsp;</a></span>test_parity() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.test_parity </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_float16</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rtol</em> = <code>5e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>atol</em> = <code>5e-4</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>test_cases_per_run</em> = <code>10000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>use_io_binding</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_class</em> = <code>&quot;GPT2LMHeadModel&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>position_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>attention_mask_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>stage</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>enable_pickle_output</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate random inputs and compare the results of PyTorch and Onnx Runtime.</pre> 
</div>
</div>
<a id="a640d5447e300b36c9f0b0a4a9294aa9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a640d5447e300b36c9f0b0a4a9294aa9e">&#9670;&nbsp;</a></span>test_performance() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.test_performance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_float16</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>use_io_binding</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_class</em> = <code>&quot;GPT2LMHeadModel&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>position_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>attention_mask_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_size</em> = <code>8</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sequence_length</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>past_sequence_length</em> = <code>32</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate random inputs and measure average latency of Onnx Runtime.</pre> 
</div>
</div>
<a id="a640d5447e300b36c9f0b0a4a9294aa9e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a640d5447e300b36c9f0b0a4a9294aa9e">&#9670;&nbsp;</a></span>test_performance() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.test_performance </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ort_session</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_float16</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>total_runs</em> = <code>100</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>use_io_binding</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model_class</em> = <code>&quot;GPT2LMHeadModel&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>position_ids_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>attention_mask_dtype</em> = <code>torch.int32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_size</em> = <code>8</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sequence_length</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>past_sequence_length</em> = <code>32</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Generate random inputs and measure average latency of Onnx Runtime.</pre> 
</div>
</div>
<a id="a4774e0364f42d2f480f13e20af6ac8ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4774e0364f42d2f480f13e20af6ac8ee">&#9670;&nbsp;</a></span>torchscript() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.torchscript </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">JIT trace for TorchScript.</pre> 
</div>
</div>
<a id="a4774e0364f42d2f480f13e20af6ac8ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4774e0364f42d2f480f13e20af6ac8ee">&#9670;&nbsp;</a></span>torchscript() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def gpt2.gpt2_helper.Gpt2Helper.torchscript </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_position_ids</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>has_attention_mask</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">JIT trace for TorchScript.</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>chromadb_rest_wrapper/venv/lib/python3.10/site-packages/onnxruntime/transformers/models/gpt2/<a class="el" href="chromadb__rest__wrapper_2venv_2lib_2python3_810_2site-packages_2onnxruntime_2transformers_2models_2gpt2_2gpt2__helper_8py.html">gpt2_helper.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
