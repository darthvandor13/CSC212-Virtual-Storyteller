<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2 Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceonnxruntime.html">onnxruntime</a></li><li class="navelem"><a class="el" href="namespaceonnxruntime_1_1transformers.html">transformers</a></li><li class="navelem"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1fusion__attention__sam2.html">fusion_attention_sam2</a></li><li class="navelem"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html">FusionMultiHeadAttentionSam2</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2 Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2:</div>
<div class="dyncontent">
<div class="center"><img src="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2__inherit__graph.png" border="0" usemap="#aonnxruntime_8transformers_8fusion__attention__sam2_8FusionMultiHeadAttentionSam2_inherit__map" alt="Inheritance graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2:</div>
<div class="dyncontent">
<div class="center"><img src="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2__coll__graph.png" border="0" usemap="#aonnxruntime_8transformers_8fusion__attention__sam2_8FusionMultiHeadAttentionSam2_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 1 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a5b415998b76b7042081174ec8f27ca61"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a5b415998b76b7042081174ec8f27ca61">__init__</a> (self, <a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a> model, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#aed39513235c987282be09e4cfe595ac3">hidden_size</a>, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a2f558d8f90fbd07ec2c108f8a1a48990">num_heads</a>)</td></tr>
<tr class="separator:a5b415998b76b7042081174ec8f27ca61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab96b48e05ba8550d46a65b209c44c857"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#ab96b48e05ba8550d46a65b209c44c857">get_decoder_num_heads</a> (self, NodeProto reshape_q)</td></tr>
<tr class="separator:ab96b48e05ba8550d46a65b209c44c857"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acfc9e92c6403e3c25dd739f996597907"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#acfc9e92c6403e3c25dd739f996597907">get_encoder_num_heads</a> (self, NodeProto reshape_in)</td></tr>
<tr class="separator:acfc9e92c6403e3c25dd739f996597907"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:addf42575868e6b377e410ee7fd89cea2"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#addf42575868e6b377e410ee7fd89cea2">get_hidden_size</a> (self, layernorm_node)</td></tr>
<tr class="separator:addf42575868e6b377e410ee7fd89cea2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a861fd960b550f9012e701ba3985a9039"><td class="memItemLeft" align="right" valign="top">tuple[int, int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a861fd960b550f9012e701ba3985a9039">get_num_heads_and_hidden_size</a> (self, NodeProto reshape_q, NodeProto layernorm_node, bool is_encoder=False)</td></tr>
<tr class="separator:a861fd960b550f9012e701ba3985a9039"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af02e69f3c91a79db4e6ebee7c61d3670"><td class="memItemLeft" align="right" valign="top">NodeProto|None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#af02e69f3c91a79db4e6ebee7c61d3670">create_attention_node</a> (self, NodeProto q_matmul, NodeProto q_add, NodeProto k_matmul, NodeProto k_add, NodeProto v_matmul, NodeProto v_add, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a2f558d8f90fbd07ec2c108f8a1a48990">num_heads</a>, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#aed39513235c987282be09e4cfe595ac3">hidden_size</a>, str output)</td></tr>
<tr class="separator:af02e69f3c91a79db4e6ebee7c61d3670"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5945991530ae94783133416152ed2ecb"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a5945991530ae94783133416152ed2ecb">fuse</a> (self, normalize_node, input_name_to_nodes, output_name_to_node)</td></tr>
<tr class="separator:a5945991530ae94783133416152ed2ecb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac902a131c2467c7ce5d714ab3da433e4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#ac902a131c2467c7ce5d714ab3da433e4">match_attention_subgraph</a> (self, node_after_output_projection)</td></tr>
<tr class="separator:ac902a131c2467c7ce5d714ab3da433e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9482a2abadeb4d885ab5d1cbecd8b732"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a9482a2abadeb4d885ab5d1cbecd8b732">fuse_sam_encoder_pattern</a> (self, normalize_node, input_name_to_nodes, output_name_to_node)</td></tr>
<tr class="separator:a9482a2abadeb4d885ab5d1cbecd8b732"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6889da80f5b9b2282538fdce4d9a20b7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a6889da80f5b9b2282538fdce4d9a20b7">match_sam_encoder_attention_subgraph</a> (self, node_after_output_projection, input_index=None)</td></tr>
<tr class="separator:a6889da80f5b9b2282538fdce4d9a20b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac9d914fad9f6dc902e8487686a3c49c"><td class="memItemLeft" align="right" valign="top">NodeProto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#aac9d914fad9f6dc902e8487686a3c49c">create_mha_node</a> (self, NodeProto reshape_q, NodeProto transpose_k, NodeProto transpose_v, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a2f558d8f90fbd07ec2c108f8a1a48990">num_heads</a>)</td></tr>
<tr class="separator:aac9d914fad9f6dc902e8487686a3c49c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5b415998b76b7042081174ec8f27ca61"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a5b415998b76b7042081174ec8f27ca61">__init__</a> (self, <a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a> model, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#aed39513235c987282be09e4cfe595ac3">hidden_size</a>, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a2f558d8f90fbd07ec2c108f8a1a48990">num_heads</a>)</td></tr>
<tr class="separator:a5b415998b76b7042081174ec8f27ca61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab96b48e05ba8550d46a65b209c44c857"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#ab96b48e05ba8550d46a65b209c44c857">get_decoder_num_heads</a> (self, NodeProto reshape_q)</td></tr>
<tr class="separator:ab96b48e05ba8550d46a65b209c44c857"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acfc9e92c6403e3c25dd739f996597907"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#acfc9e92c6403e3c25dd739f996597907">get_encoder_num_heads</a> (self, NodeProto reshape_in)</td></tr>
<tr class="separator:acfc9e92c6403e3c25dd739f996597907"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:addf42575868e6b377e410ee7fd89cea2"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#addf42575868e6b377e410ee7fd89cea2">get_hidden_size</a> (self, layernorm_node)</td></tr>
<tr class="separator:addf42575868e6b377e410ee7fd89cea2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a861fd960b550f9012e701ba3985a9039"><td class="memItemLeft" align="right" valign="top">tuple[int, int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a861fd960b550f9012e701ba3985a9039">get_num_heads_and_hidden_size</a> (self, NodeProto reshape_q, NodeProto layernorm_node, bool is_encoder=False)</td></tr>
<tr class="separator:a861fd960b550f9012e701ba3985a9039"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af02e69f3c91a79db4e6ebee7c61d3670"><td class="memItemLeft" align="right" valign="top">NodeProto|None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#af02e69f3c91a79db4e6ebee7c61d3670">create_attention_node</a> (self, NodeProto q_matmul, NodeProto q_add, NodeProto k_matmul, NodeProto k_add, NodeProto v_matmul, NodeProto v_add, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a2f558d8f90fbd07ec2c108f8a1a48990">num_heads</a>, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#aed39513235c987282be09e4cfe595ac3">hidden_size</a>, str output)</td></tr>
<tr class="separator:af02e69f3c91a79db4e6ebee7c61d3670"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5945991530ae94783133416152ed2ecb"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a5945991530ae94783133416152ed2ecb">fuse</a> (self, normalize_node, input_name_to_nodes, output_name_to_node)</td></tr>
<tr class="separator:a5945991530ae94783133416152ed2ecb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac902a131c2467c7ce5d714ab3da433e4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#ac902a131c2467c7ce5d714ab3da433e4">match_attention_subgraph</a> (self, node_after_output_projection)</td></tr>
<tr class="separator:ac902a131c2467c7ce5d714ab3da433e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9482a2abadeb4d885ab5d1cbecd8b732"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a9482a2abadeb4d885ab5d1cbecd8b732">fuse_sam_encoder_pattern</a> (self, normalize_node, input_name_to_nodes, output_name_to_node)</td></tr>
<tr class="separator:a9482a2abadeb4d885ab5d1cbecd8b732"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6889da80f5b9b2282538fdce4d9a20b7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a6889da80f5b9b2282538fdce4d9a20b7">match_sam_encoder_attention_subgraph</a> (self, node_after_output_projection, input_index=None)</td></tr>
<tr class="separator:a6889da80f5b9b2282538fdce4d9a20b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aac9d914fad9f6dc902e8487686a3c49c"><td class="memItemLeft" align="right" valign="top">NodeProto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#aac9d914fad9f6dc902e8487686a3c49c">create_mha_node</a> (self, NodeProto reshape_q, NodeProto transpose_k, NodeProto transpose_v, int <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a2f558d8f90fbd07ec2c108f8a1a48990">num_heads</a>)</td></tr>
<tr class="separator:aac9d914fad9f6dc902e8487686a3c49c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html">onnxruntime.transformers.fusion_base.Fusion</a></td></tr>
<tr class="memitem:a7d0d94dbf15fc205f4735e3d1e8828c5 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a7d0d94dbf15fc205f4735e3d1e8828c5">__init__</a> (self, <a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a> model, str fused_op_type, str|list[str] search_op_types, str description=&quot;&quot;)</td></tr>
<tr class="separator:a7d0d94dbf15fc205f4735e3d1e8828c5 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4ffc1eac3afcdfc42e471c9f2d41330 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#ab4ffc1eac3afcdfc42e471c9f2d41330">increase_counter</a> (self, str fused_op_name)</td></tr>
<tr class="separator:ab4ffc1eac3afcdfc42e471c9f2d41330 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1bf9b45d1d3c486821b8f56fc9c3626 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#ab1bf9b45d1d3c486821b8f56fc9c3626">fuse</a> (self, NodeProto node, dict[str, list[NodeProto]] input_name_to_nodes, dict[str, NodeProto] output_name_to_node)</td></tr>
<tr class="separator:ab1bf9b45d1d3c486821b8f56fc9c3626 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67b4a3359ea81d9c96c4fff4edec9fa8 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a67b4a3359ea81d9c96c4fff4edec9fa8">apply</a> (self)</td></tr>
<tr class="separator:a67b4a3359ea81d9c96c4fff4edec9fa8 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f370334fa35b77d7667baf24ac346a1 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a4f370334fa35b77d7667baf24ac346a1">add_initializer</a> (self, str name, int data_type, Sequence[int] dims, Any vals, bool raw=True)</td></tr>
<tr class="separator:a4f370334fa35b77d7667baf24ac346a1 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4f74752db0beb76467a18f527234065 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#aa4f74752db0beb76467a18f527234065">remove_initializer</a> (self, TensorProto tensor)</td></tr>
<tr class="separator:aa4f74752db0beb76467a18f527234065 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89db5ab3fec70db716d6ab2a8a30a650 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a89db5ab3fec70db716d6ab2a8a30a650">add_nodes_to_remove</a> (self, list[NodeProto] nodes)</td></tr>
<tr class="separator:a89db5ab3fec70db716d6ab2a8a30a650 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36a3534fd354c644d2b540b5e1e52e0e inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a36a3534fd354c644d2b540b5e1e52e0e">add_nodes_to_remove_with_nodes_to_keep</a> (self, list[NodeProto] nodes, list[NodeProto] nodes_to_keep)</td></tr>
<tr class="separator:a36a3534fd354c644d2b540b5e1e52e0e inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d0d94dbf15fc205f4735e3d1e8828c5 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a7d0d94dbf15fc205f4735e3d1e8828c5">__init__</a> (self, <a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a> model, str fused_op_type, str|list[str] search_op_types, str description=&quot;&quot;)</td></tr>
<tr class="separator:a7d0d94dbf15fc205f4735e3d1e8828c5 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4ffc1eac3afcdfc42e471c9f2d41330 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#ab4ffc1eac3afcdfc42e471c9f2d41330">increase_counter</a> (self, str fused_op_name)</td></tr>
<tr class="separator:ab4ffc1eac3afcdfc42e471c9f2d41330 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1bf9b45d1d3c486821b8f56fc9c3626 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#ab1bf9b45d1d3c486821b8f56fc9c3626">fuse</a> (self, NodeProto node, dict[str, list[NodeProto]] input_name_to_nodes, dict[str, NodeProto] output_name_to_node)</td></tr>
<tr class="separator:ab1bf9b45d1d3c486821b8f56fc9c3626 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a67b4a3359ea81d9c96c4fff4edec9fa8 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a67b4a3359ea81d9c96c4fff4edec9fa8">apply</a> (self)</td></tr>
<tr class="separator:a67b4a3359ea81d9c96c4fff4edec9fa8 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f370334fa35b77d7667baf24ac346a1 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a4f370334fa35b77d7667baf24ac346a1">add_initializer</a> (self, str name, int data_type, Sequence[int] dims, Any vals, bool raw=True)</td></tr>
<tr class="separator:a4f370334fa35b77d7667baf24ac346a1 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4f74752db0beb76467a18f527234065 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#aa4f74752db0beb76467a18f527234065">remove_initializer</a> (self, TensorProto tensor)</td></tr>
<tr class="separator:aa4f74752db0beb76467a18f527234065 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a89db5ab3fec70db716d6ab2a8a30a650 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a89db5ab3fec70db716d6ab2a8a30a650">add_nodes_to_remove</a> (self, list[NodeProto] nodes)</td></tr>
<tr class="separator:a89db5ab3fec70db716d6ab2a8a30a650 inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36a3534fd354c644d2b540b5e1e52e0e inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a36a3534fd354c644d2b540b5e1e52e0e">add_nodes_to_remove_with_nodes_to_keep</a> (self, list[NodeProto] nodes, list[NodeProto] nodes_to_keep)</td></tr>
<tr class="separator:a36a3534fd354c644d2b540b5e1e52e0e inherit pub_methods_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:aed39513235c987282be09e4cfe595ac3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#aed39513235c987282be09e4cfe595ac3">hidden_size</a></td></tr>
<tr class="separator:aed39513235c987282be09e4cfe595ac3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f558d8f90fbd07ec2c108f8a1a48990"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a2f558d8f90fbd07ec2c108f8a1a48990">num_heads</a></td></tr>
<tr class="separator:a2f558d8f90fbd07ec2c108f8a1a48990"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86e7e03420488c9f6d3b1703e35dac3a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#a86e7e03420488c9f6d3b1703e35dac3a">num_heads_warning</a></td></tr>
<tr class="separator:a86e7e03420488c9f6d3b1703e35dac3a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abfa05054d95fb4fd0820dbf5c97f9917"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#abfa05054d95fb4fd0820dbf5c97f9917">hidden_size_warning</a></td></tr>
<tr class="separator:abfa05054d95fb4fd0820dbf5c97f9917"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad44d4bf8f59a424c03a5746260af693a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__attention__sam2_1_1FusionMultiHeadAttentionSam2.html#ad44d4bf8f59a424c03a5746260af693a">prune_graph</a></td></tr>
<tr class="separator:ad44d4bf8f59a424c03a5746260af693a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_attribs_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td colspan="2" onclick="javascript:toggleInherit('pub_attribs_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion')"><img src="closed.png" alt="-"/>&#160;Public Attributes inherited from <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html">onnxruntime.transformers.fusion_base.Fusion</a></td></tr>
<tr class="memitem:a98ba45b80c0c61b8422469cedf9eee5e inherit pub_attribs_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion.html#a98ba45b80c0c61b8422469cedf9eee5e">this_graph_name</a></td></tr>
<tr class="separator:a98ba45b80c0c61b8422469cedf9eee5e inherit pub_attribs_classonnxruntime_1_1transformers_1_1fusion__base_1_1Fusion"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Fuse MultiHeadAttention subgraph of Segment Anything v2 (SAM2).
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a5b415998b76b7042081174ec8f27ca61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5b415998b76b7042081174ec8f27ca61">&#9670;&nbsp;</a></span>__init__() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a>&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_heads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5b415998b76b7042081174ec8f27ca61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5b415998b76b7042081174ec8f27ca61">&#9670;&nbsp;</a></span>__init__() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a>&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_heads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="af02e69f3c91a79db4e6ebee7c61d3670"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af02e69f3c91a79db4e6ebee7c61d3670">&#9670;&nbsp;</a></span>create_attention_node() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> NodeProto | None onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.create_attention_node </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>q_matmul</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>q_add</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>k_matmul</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>k_add</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>v_matmul</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>v_add</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Create an Attention node.

Args:
    q_matmul (NodeProto): MatMul node in fully connection for Q
    q_add (NodeProto): Add bias node in fully connection for Q
    k_matmul (NodeProto): MatMul node in fully connection for K
    k_add (NodeProto): Add bias node in fully connection for K
    v_matmul (NodeProto): MatMul node in fully connection for V
    v_add (NodeProto): Add bias node in fully connection for V
    num_heads (int): number of attention heads. If a model is pruned, it is the number of heads after pruning.
    hidden_size (int): hidden dimension. If a model is pruned, it is the hidden dimension after pruning.
    output (str): output name

Returns:
    Union[NodeProto, None]: the node created or None if failed.
</pre> 
</div>
</div>
<a id="af02e69f3c91a79db4e6ebee7c61d3670"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af02e69f3c91a79db4e6ebee7c61d3670">&#9670;&nbsp;</a></span>create_attention_node() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> NodeProto | None onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.create_attention_node </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>q_matmul</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>q_add</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>k_matmul</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>k_add</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>v_matmul</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>v_add</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_heads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Create an Attention node.

Args:
    q_matmul (NodeProto): MatMul node in fully connection for Q
    q_add (NodeProto): Add bias node in fully connection for Q
    k_matmul (NodeProto): MatMul node in fully connection for K
    k_add (NodeProto): Add bias node in fully connection for K
    v_matmul (NodeProto): MatMul node in fully connection for V
    v_add (NodeProto): Add bias node in fully connection for V
    num_heads (int): number of attention heads. If a model is pruned, it is the number of heads after pruning.
    hidden_size (int): hidden dimension. If a model is pruned, it is the hidden dimension after pruning.
    output (str): output name

Returns:
    Union[NodeProto, None]: the node created or None if failed.
</pre> 
</div>
</div>
<a id="aac9d914fad9f6dc902e8487686a3c49c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac9d914fad9f6dc902e8487686a3c49c">&#9670;&nbsp;</a></span>create_mha_node() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> NodeProto onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.create_mha_node </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>reshape_q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>transpose_k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>transpose_v</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_heads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Create a MultiHeadAttention node for SAM2 encoder.

Args:
    reshape_q (NodeProto): Reshape node for Q, output is 3D BxSxNH format
    transpose_k (NodeProto): Transpose node for K, output is BNSH format
    transpose_v (NodeProto): Transpose node for V, output is BNSH format
    num_heads (int): number of attention heads. If a model is pruned, it is the number of heads after pruning.

Returns:
    NodeProto: the MultiHeadAttention node created.
</pre> 
</div>
</div>
<a id="aac9d914fad9f6dc902e8487686a3c49c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aac9d914fad9f6dc902e8487686a3c49c">&#9670;&nbsp;</a></span>create_mha_node() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> NodeProto onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.create_mha_node </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>reshape_q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>transpose_k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>transpose_v</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_heads</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Create a MultiHeadAttention node for SAM2 encoder.

Args:
    reshape_q (NodeProto): Reshape node for Q, output is 3D BxSxNH format
    transpose_k (NodeProto): Transpose node for K, output is BNSH format
    transpose_v (NodeProto): Transpose node for V, output is BNSH format
    num_heads (int): number of attention heads. If a model is pruned, it is the number of heads after pruning.

Returns:
    NodeProto: the MultiHeadAttention node created.
</pre> 
</div>
</div>
<a id="a5945991530ae94783133416152ed2ecb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5945991530ae94783133416152ed2ecb">&#9670;&nbsp;</a></span>fuse() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.fuse </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_name_to_nodes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_name_to_node</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5945991530ae94783133416152ed2ecb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5945991530ae94783133416152ed2ecb">&#9670;&nbsp;</a></span>fuse() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.fuse </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_name_to_nodes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_name_to_node</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9482a2abadeb4d885ab5d1cbecd8b732"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9482a2abadeb4d885ab5d1cbecd8b732">&#9670;&nbsp;</a></span>fuse_sam_encoder_pattern() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> bool onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.fuse_sam_encoder_pattern </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_name_to_nodes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_name_to_node</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9482a2abadeb4d885ab5d1cbecd8b732"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9482a2abadeb4d885ab5d1cbecd8b732">&#9670;&nbsp;</a></span>fuse_sam_encoder_pattern() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> bool onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.fuse_sam_encoder_pattern </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalize_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_name_to_nodes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_name_to_node</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab96b48e05ba8550d46a65b209c44c857"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab96b48e05ba8550d46a65b209c44c857">&#9670;&nbsp;</a></span>get_decoder_num_heads() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.get_decoder_num_heads </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>reshape_q</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Detect num_heads from a reshape node.

Args:
    reshape_q (NodeProto): reshape node for Q
Returns:
    int: num_heads, or 0 if not found
</pre> 
</div>
</div>
<a id="ab96b48e05ba8550d46a65b209c44c857"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab96b48e05ba8550d46a65b209c44c857">&#9670;&nbsp;</a></span>get_decoder_num_heads() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.get_decoder_num_heads </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>reshape_q</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Detect num_heads from a reshape node.

Args:
    reshape_q (NodeProto): reshape node for Q
Returns:
    int: num_heads, or 0 if not found
</pre> 
</div>
</div>
<a id="acfc9e92c6403e3c25dd739f996597907"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acfc9e92c6403e3c25dd739f996597907">&#9670;&nbsp;</a></span>get_encoder_num_heads() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.get_encoder_num_heads </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>reshape_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Detect num_heads from a reshape node.

Args:
    reshape_q (NodeProto): reshape node for Q
Returns:
    int: num_heads, or 0 if not found
</pre> 
</div>
</div>
<a id="acfc9e92c6403e3c25dd739f996597907"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acfc9e92c6403e3c25dd739f996597907">&#9670;&nbsp;</a></span>get_encoder_num_heads() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.get_encoder_num_heads </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>reshape_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Detect num_heads from a reshape node.

Args:
    reshape_q (NodeProto): reshape node for Q
Returns:
    int: num_heads, or 0 if not found
</pre> 
</div>
</div>
<a id="addf42575868e6b377e410ee7fd89cea2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#addf42575868e6b377e410ee7fd89cea2">&#9670;&nbsp;</a></span>get_hidden_size() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.get_hidden_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layernorm_node</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Detect hidden_size from LayerNormalization node.
Args:
    layernorm_node (NodeProto): LayerNormalization node before Q, K and V
Returns:
    int: hidden_size, or 0 if not found
</pre> 
</div>
</div>
<a id="addf42575868e6b377e410ee7fd89cea2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#addf42575868e6b377e410ee7fd89cea2">&#9670;&nbsp;</a></span>get_hidden_size() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.get_hidden_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>layernorm_node</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Detect hidden_size from LayerNormalization node.
Args:
    layernorm_node (NodeProto): LayerNormalization node before Q, K and V
Returns:
    int: hidden_size, or 0 if not found
</pre> 
</div>
</div>
<a id="a861fd960b550f9012e701ba3985a9039"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a861fd960b550f9012e701ba3985a9039">&#9670;&nbsp;</a></span>get_num_heads_and_hidden_size() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> tuple[int, int] onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.get_num_heads_and_hidden_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>reshape_q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>layernorm_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>is_encoder</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Detect num_heads and hidden_size.

Args:
    reshape_q (NodeProto): reshape node for Q
    layernorm_node (NodeProto): LayerNormalization node before Q, K, V
Returns:
    Tuple[int, int]: num_heads and hidden_size
</pre> 
</div>
</div>
<a id="a861fd960b550f9012e701ba3985a9039"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a861fd960b550f9012e701ba3985a9039">&#9670;&nbsp;</a></span>get_num_heads_and_hidden_size() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> tuple[int, int] onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.get_num_heads_and_hidden_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>reshape_q</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NodeProto&#160;</td>
          <td class="paramname"><em>layernorm_node</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>is_encoder</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Detect num_heads and hidden_size.

Args:
    reshape_q (NodeProto): reshape node for Q
    layernorm_node (NodeProto): LayerNormalization node before Q, K, V
Returns:
    Tuple[int, int]: num_heads and hidden_size
</pre> 
</div>
</div>
<a id="ac902a131c2467c7ce5d714ab3da433e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac902a131c2467c7ce5d714ab3da433e4">&#9670;&nbsp;</a></span>match_attention_subgraph() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.match_attention_subgraph </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>node_after_output_projection</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Match Q, K and V paths exported by PyTorch 2.*</pre> 
</div>
</div>
<a id="ac902a131c2467c7ce5d714ab3da433e4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac902a131c2467c7ce5d714ab3da433e4">&#9670;&nbsp;</a></span>match_attention_subgraph() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.match_attention_subgraph </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>node_after_output_projection</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Match Q, K and V paths exported by PyTorch 2.*</pre> 
</div>
</div>
<a id="a6889da80f5b9b2282538fdce4d9a20b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6889da80f5b9b2282538fdce4d9a20b7">&#9670;&nbsp;</a></span>match_sam_encoder_attention_subgraph() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.match_sam_encoder_attention_subgraph </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>node_after_output_projection</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_index</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Match SDPA pattern in SAM2 enconder.*</pre> 
</div>
</div>
<a id="a6889da80f5b9b2282538fdce4d9a20b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6889da80f5b9b2282538fdce4d9a20b7">&#9670;&nbsp;</a></span>match_sam_encoder_attention_subgraph() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.match_sam_encoder_attention_subgraph </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>node_after_output_projection</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_index</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Match SDPA pattern in SAM2 enconder.*</pre> 
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="aed39513235c987282be09e4cfe595ac3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aed39513235c987282be09e4cfe595ac3">&#9670;&nbsp;</a></span>hidden_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.hidden_size</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abfa05054d95fb4fd0820dbf5c97f9917"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abfa05054d95fb4fd0820dbf5c97f9917">&#9670;&nbsp;</a></span>hidden_size_warning</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.hidden_size_warning</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2f558d8f90fbd07ec2c108f8a1a48990"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f558d8f90fbd07ec2c108f8a1a48990">&#9670;&nbsp;</a></span>num_heads</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.num_heads</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a86e7e03420488c9f6d3b1703e35dac3a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a86e7e03420488c9f6d3b1703e35dac3a">&#9670;&nbsp;</a></span>num_heads_warning</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.num_heads_warning</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad44d4bf8f59a424c03a5746260af693a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad44d4bf8f59a424c03a5746260af693a">&#9670;&nbsp;</a></span>prune_graph</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnxruntime.transformers.fusion_attention_sam2.FusionMultiHeadAttentionSam2.prune_graph</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>chromadb_rest_wrapper/venv/lib/python3.10/site-packages/onnxruntime/transformers/<a class="el" href="chromadb__rest__wrapper_2venv_2lib_2python3_810_2site-packages_2onnxruntime_2transformers_2fusion__attention__sam2_8py.html">fusion_attention_sam2.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
