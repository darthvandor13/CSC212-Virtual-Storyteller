<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: onnxruntime.transformers.convert_generation Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceonnxruntime.html">onnxruntime</a></li><li class="navelem"><a class="el" href="namespaceonnxruntime_1_1transformers.html">transformers</a></li><li class="navelem"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html">convert_generation</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">onnxruntime.transformers.convert_generation Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1transformers_1_1convert__generation_1_1GenerationType.html">GenerationType</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a52501cbc8202a6aeb905c1f099bb17d8"><td class="memItemLeft" align="right" valign="top">argparse.Namespace&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a52501cbc8202a6aeb905c1f099bb17d8">parse_arguments</a> (list[str]|None argv=None)</td></tr>
<tr class="separator:a52501cbc8202a6aeb905c1f099bb17d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad589fec17f92714aecf43169cc6a9ca4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#ad589fec17f92714aecf43169cc6a9ca4">gpt2_to_onnx</a> (argparse.Namespace args)</td></tr>
<tr class="separator:ad589fec17f92714aecf43169cc6a9ca4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fceb651d8941fd9c76fbb5ee1f62cf4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a7fceb651d8941fd9c76fbb5ee1f62cf4">t5_to_onnx</a> (argparse.Namespace args)</td></tr>
<tr class="separator:a7fceb651d8941fd9c76fbb5ee1f62cf4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ea6baadfae322c7517be2ac2bf4924c"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a5ea6baadfae322c7517be2ac2bf4924c">shape_inference</a> (str onnx_path, bool use_external_data_format=True)</td></tr>
<tr class="separator:a5ea6baadfae322c7517be2ac2bf4924c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4e30dbd65e865059e7813079747fffaa"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a4e30dbd65e865059e7813079747fffaa">pad_weights_of_logits_matmul</a> (str onnx_path, bool use_external_data_format=True)</td></tr>
<tr class="separator:a4e30dbd65e865059e7813079747fffaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a5e8005c95d17336e89bbdf98ce7821"><td class="memItemLeft" align="right" valign="top">InferenceSession&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a9a5e8005c95d17336e89bbdf98ce7821">create_ort_session</a> (str model_path, bool use_gpu, bool use_sln_strict_mode)</td></tr>
<tr class="separator:a9a5e8005c95d17336e89bbdf98ce7821"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a4f066ceeebcee90ad792bfa322836d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a2a4f066ceeebcee90ad792bfa322836d">verify_gpt2_subgraph</a> (onnx.GraphProto graph, <a class="el" href="classonnxruntime_1_1transformers_1_1benchmark__helper_1_1Precision.html">Precision</a> precision)</td></tr>
<tr class="separator:a2a4f066ceeebcee90ad792bfa322836d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40461afb0523406dc6f74dc768c83187"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a40461afb0523406dc6f74dc768c83187">verify_t5_decoder_subgraph</a> (onnx.GraphProto graph, <a class="el" href="classonnxruntime_1_1transformers_1_1benchmark__helper_1_1Precision.html">Precision</a> precision)</td></tr>
<tr class="separator:a40461afb0523406dc6f74dc768c83187"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fb78fb2c4a6a143433de62d8abd67e2"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a7fb78fb2c4a6a143433de62d8abd67e2">verify_t5_encoder_decoder_init_subgraph</a> (onnx.GraphProto graph, <a class="el" href="classonnxruntime_1_1transformers_1_1benchmark__helper_1_1Precision.html">Precision</a> precision)</td></tr>
<tr class="separator:a7fb78fb2c4a6a143433de62d8abd67e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a70ef23edc233a0918604d86e8edd243f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a70ef23edc233a0918604d86e8edd243f">remove_shared_initializers</a> (GraphProto graph1, GraphProto graph2, str shared_prefix=&quot;shared_&quot;, int min_elements=1024, dict|None signature_cache1=None, dict|None signature_cache2=None)</td></tr>
<tr class="separator:a70ef23edc233a0918604d86e8edd243f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a048fa44813cbaadc6591286e9d68e170"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a048fa44813cbaadc6591286e9d68e170">get_shared_initializers</a> (ModelProto encoder_model, ModelProto decoder_model)</td></tr>
<tr class="separator:a048fa44813cbaadc6591286e9d68e170"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8743ace7a762509ee7532e0864bd5fae"><td class="memItemLeft" align="right" valign="top">list[TensorProto]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a8743ace7a762509ee7532e0864bd5fae">move_initializers</a> (GraphProto graph, int min_elements=1024)</td></tr>
<tr class="separator:a8743ace7a762509ee7532e0864bd5fae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57fbdee01fb6651d9fa6e7586d399408"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a57fbdee01fb6651d9fa6e7586d399408">kwargs_of</a> (node)</td></tr>
<tr class="separator:a57fbdee01fb6651d9fa6e7586d399408"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e180a98cc07ad8087ab1b4a2990bcce"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a0e180a98cc07ad8087ab1b4a2990bcce">shape_of</a> (vi)</td></tr>
<tr class="separator:a0e180a98cc07ad8087ab1b4a2990bcce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a38f523a1344d80c0521659b7c85b1880"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a38f523a1344d80c0521659b7c85b1880">update_decoder_subgraph_past_present_share_buffer</a> (GraphProto subg)</td></tr>
<tr class="separator:a38f523a1344d80c0521659b7c85b1880"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c93dd20072a3579ba47915ea02de26c"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a0c93dd20072a3579ba47915ea02de26c">update_decoder_subgraph_use_decoder_masked_attention</a> (GraphProto subg, bool is_beam_search, bool switch_attention)</td></tr>
<tr class="separator:a0c93dd20072a3579ba47915ea02de26c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a97cb4d3d41a0a0faba3e2c3b4e52e4e7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a97cb4d3d41a0a0faba3e2c3b4e52e4e7">find_past_seq_len_usage</a> (GraphProto subg)</td></tr>
<tr class="separator:a97cb4d3d41a0a0faba3e2c3b4e52e4e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8ed568fe64c300fe95c098cdc288e89"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#ac8ed568fe64c300fe95c098cdc288e89">replace_mha_with_gqa</a> (<a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a> model, str attn_mask, int kv_num_heads=0, int world_size=1, int window_size=-1)</td></tr>
<tr class="separator:ac8ed568fe64c300fe95c098cdc288e89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c4d493f3425ac9fb54a3e7b98226993"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a1c4d493f3425ac9fb54a3e7b98226993">update_decoder_subgraph_output_cross_attention</a> (GraphProto subg)</td></tr>
<tr class="separator:a1c4d493f3425ac9fb54a3e7b98226993"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a174f55fd7ef4abeb382abf1fbd1109"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a8a174f55fd7ef4abeb382abf1fbd1109">update_decoder_subgraph_share_buffer_and_use_decoder_masked_mha</a> (ModelProto subg)</td></tr>
<tr class="separator:a8a174f55fd7ef4abeb382abf1fbd1109"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa081b97345149a70b24e237e26a2fb2f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#aa081b97345149a70b24e237e26a2fb2f">pack_qkv_for_decoder_masked_mha</a> (ModelProto model_proto)</td></tr>
<tr class="separator:aa081b97345149a70b24e237e26a2fb2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a35bf3ad31b7cda2a85477a6e92bcabef"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a35bf3ad31b7cda2a85477a6e92bcabef">update_input_shapes_for_gpt2_decoder_model</a> (str decoder_onnx_path, bool use_external_data_format=True)</td></tr>
<tr class="separator:a35bf3ad31b7cda2a85477a6e92bcabef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c43fd36f844f248bce4fa174ccb01d1"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a7c43fd36f844f248bce4fa174ccb01d1">generate_gpt2_init_decoder</a> (str decoder_onnx_path, str init_decoder_onnx_path, bool use_external_data_format=True)</td></tr>
<tr class="separator:a7c43fd36f844f248bce4fa174ccb01d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8b6a82ba00c13c7ed356f056d24b66d7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a8b6a82ba00c13c7ed356f056d24b66d7">make_dim_proto_numeric_t5</a> (model, config)</td></tr>
<tr class="separator:a8b6a82ba00c13c7ed356f056d24b66d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9943b700a6a859f269b3002f3582262d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a9943b700a6a859f269b3002f3582262d">convert_generation_model</a> (argparse.Namespace args, <a class="el" href="classonnxruntime_1_1transformers_1_1convert__generation_1_1GenerationType.html">GenerationType</a> generation_type=<a class="el" href="classonnxruntime_1_1transformers_1_1convert__generation_1_1GenerationType.html#a09e9220e4719da28940bbe19c89d62ca">GenerationType.BEAMSEARCH</a>)</td></tr>
<tr class="separator:a9943b700a6a859f269b3002f3582262d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5f6ee9a43a9c965b2581e48a4b36b7b8"><td class="memItemLeft" align="right" valign="top">dict[str, Any]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a5f6ee9a43a9c965b2581e48a4b36b7b8">test_torch_performance</a> (argparse.Namespace args, GPT2LMHeadModel|T5ForConditionalGeneration model, torch.Tensor input_ids, torch.Tensor attention_mask, int eos_token_id, int pad_token_id, list[list[int]] bad_words_ids)</td></tr>
<tr class="separator:a5f6ee9a43a9c965b2581e48a4b36b7b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a030af6efb76df850f6c8c3f8daf77c97"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a030af6efb76df850f6c8c3f8daf77c97">create_attention_mask</a> (input_ids, pad_token_id)</td></tr>
<tr class="separator:a030af6efb76df850f6c8c3f8daf77c97"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68adff2888f94264a038aaae3b45fa99"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a68adff2888f94264a038aaae3b45fa99">test_gpt_model</a> (argparse.Namespace args, list[str]|None sentences=None, bool is_greedy=False)</td></tr>
<tr class="separator:a68adff2888f94264a038aaae3b45fa99"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a47c0eed667ac45a2fcbd6aa6e3771e14"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a47c0eed667ac45a2fcbd6aa6e3771e14">test_t5_model</a> (argparse.Namespace args, list[str]|None sentences=None)</td></tr>
<tr class="separator:a47c0eed667ac45a2fcbd6aa6e3771e14"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d4866899804858d7ff90acaae490925"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#a2d4866899804858d7ff90acaae490925">main</a> (list[str]|None argv=None, list[str]|None sentences=None)</td></tr>
<tr class="separator:a2d4866899804858d7ff90acaae490925"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:ae613da3f21dc1636ff839db614ec84ae"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1convert__generation.html#ae613da3f21dc1636ff839db614ec84ae">logger</a> = logging.getLogger(&quot;&quot;)</td></tr>
<tr class="separator:ae613da3f21dc1636ff839db614ec84ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a9943b700a6a859f269b3002f3582262d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9943b700a6a859f269b3002f3582262d">&#9670;&nbsp;</a></span>convert_generation_model()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.convert_generation_model </td>
          <td>(</td>
          <td class="paramtype">argparse.Namespace&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1transformers_1_1convert__generation_1_1GenerationType.html">GenerationType</a> &#160;</td>
          <td class="paramname"><em>generation_type</em> = <code><a class="el" href="classonnxruntime_1_1transformers_1_1convert__generation_1_1GenerationType.html#a09e9220e4719da28940bbe19c89d62ca">GenerationType.BEAMSEARCH</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert model according to command line arguments.

Args:
    args (argparse.Namespace): arguments parsed from command line
</pre> 
</div>
</div>
<a id="a030af6efb76df850f6c8c3f8daf77c97"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a030af6efb76df850f6c8c3f8daf77c97">&#9670;&nbsp;</a></span>create_attention_mask()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.create_attention_mask </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_ids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>pad_token_id</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9a5e8005c95d17336e89bbdf98ce7821"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a5e8005c95d17336e89bbdf98ce7821">&#9670;&nbsp;</a></span>create_ort_session()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">InferenceSession onnxruntime.transformers.convert_generation.create_ort_session </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>model_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_gpu</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_sln_strict_mode</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Create OnnxRuntime session.

Args:
    model_path (str): onnx model path
    use_gpu (bool): use GPU or not
    use_sln_strict_mode (bool): use strict mode for skip layer normalization or not

Raises:
    RuntimeError: CUDAExecutionProvider is not available when --use_gpu is specified.

Returns:
    onnxruntime.InferenceSession: The created session.
</pre> 
</div>
</div>
<a id="a97cb4d3d41a0a0faba3e2c3b4e52e4e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a97cb4d3d41a0a0faba3e2c3b4e52e4e7">&#9670;&nbsp;</a></span>find_past_seq_len_usage()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.find_past_seq_len_usage </td>
          <td>(</td>
          <td class="paramtype">GraphProto&#160;</td>
          <td class="paramname"><em>subg</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Correct graph which originally use dim of past_seq_len from input_ids's shape which is fixed to max_seq_len after
   shared past/present buffer

Args:
    subg (GraphProto): GraphProto of the decoder subgraph
return:
    tensor_names_to_rename : set of tensor names which is equal to past_sequence_length
    nodes_to_remove : list of node to remove
</pre> 
</div>
</div>
<a id="a7c43fd36f844f248bce4fa174ccb01d1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7c43fd36f844f248bce4fa174ccb01d1">&#9670;&nbsp;</a></span>generate_gpt2_init_decoder()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool onnxruntime.transformers.convert_generation.generate_gpt2_init_decoder </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>decoder_onnx_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>init_decoder_onnx_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Generates the initial decoder GPT2 subgraph and saves it for downstream use.
   The initial decoder model will be saved to init_decoder_onnx_path.

Args:
    decoder_onnx_path (str): Path of GPT-2 decoder onnx model
    init_decoder_onnx_path (str): Path of GPT-2 init decoder onnx model
    use_external_data_format(bool): output tensors to external data or not.
</pre> 
</div>
</div>
<a id="a048fa44813cbaadc6591286e9d68e170"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a048fa44813cbaadc6591286e9d68e170">&#9670;&nbsp;</a></span>get_shared_initializers()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.get_shared_initializers </td>
          <td>(</td>
          <td class="paramtype">ModelProto&#160;</td>
          <td class="paramname"><em>encoder_model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ModelProto&#160;</td>
          <td class="paramname"><em>decoder_model</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad589fec17f92714aecf43169cc6a9ca4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad589fec17f92714aecf43169cc6a9ca4">&#9670;&nbsp;</a></span>gpt2_to_onnx()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.gpt2_to_onnx </td>
          <td>(</td>
          <td class="paramtype">argparse.Namespace&#160;</td>
          <td class="paramname"><em>args</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert GPT-2 model to onnx

Args:
    args (argparse.Namespace): arguments parsed from command line
</pre> 
</div>
</div>
<a id="a57fbdee01fb6651d9fa6e7586d399408"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a57fbdee01fb6651d9fa6e7586d399408">&#9670;&nbsp;</a></span>kwargs_of()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.kwargs_of </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>node</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a2d4866899804858d7ff90acaae490925"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d4866899804858d7ff90acaae490925">&#9670;&nbsp;</a></span>main()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.main </td>
          <td>(</td>
          <td class="paramtype">list[str] | None &#160;</td>
          <td class="paramname"><em>argv</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[str] | None &#160;</td>
          <td class="paramname"><em>sentences</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Main entry function

Args:
    argv (Optional[List[str]], optional): _description_. Defaults to None.
    sentences (Optional[List[str]], optional): input text. Defaults to None.

Raises:
    ValueError: Path does not exist: --encoder_decoder_init_onnx
    ValueError: Path does not exist: --decoder_onnx
    ValueError: --decoder_onnx and --encoder_decoder_init_onnx are not used together for T5

Returns:
    Union[Dict[str, Any], None]: A dictionary with string with metric name, and value can be integer or string.
</pre> 
</div>
</div>
<a id="a8b6a82ba00c13c7ed356f056d24b66d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8b6a82ba00c13c7ed356f056d24b66d7">&#9670;&nbsp;</a></span>make_dim_proto_numeric_t5()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.make_dim_proto_numeric_t5 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>config</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Make dim_proto numeric.

Args:
    model: T5 encoder and decoder model.
    config: T5 config.
</pre> 
</div>
</div>
<a id="a8743ace7a762509ee7532e0864bd5fae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8743ace7a762509ee7532e0864bd5fae">&#9670;&nbsp;</a></span>move_initializers()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> list[TensorProto] onnxruntime.transformers.convert_generation.move_initializers </td>
          <td>(</td>
          <td class="paramtype">GraphProto&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>min_elements</em> = <code>1024</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Remove initializers of a graph, when they have number of elements larger than a threshold.

Args:
    graph (GraphProto): the graph.
    min_elements (int, optional): minimal number of elements for initializers to be considered. Defaults to 1024.

Returns:
    List[TensorProto]: initializers that are removed from the graph.
</pre> 
</div>
</div>
<a id="aa081b97345149a70b24e237e26a2fb2f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa081b97345149a70b24e237e26a2fb2f">&#9670;&nbsp;</a></span>pack_qkv_for_decoder_masked_mha()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.pack_qkv_for_decoder_masked_mha </td>
          <td>(</td>
          <td class="paramtype">ModelProto&#160;</td>
          <td class="paramname"><em>model_proto</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a4e30dbd65e865059e7813079747fffaa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4e30dbd65e865059e7813079747fffaa">&#9670;&nbsp;</a></span>pad_weights_of_logits_matmul()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool onnxruntime.transformers.convert_generation.pad_weights_of_logits_matmul </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pad the logits MatMul weight in the provided decoder model, which will be overwritten.

Args:
    onnx_path (str): Path of onnx model
    use_external_data_format(bool): output tensors to external data or not.
</pre> 
</div>
</div>
<a id="a52501cbc8202a6aeb905c1f099bb17d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a52501cbc8202a6aeb905c1f099bb17d8">&#9670;&nbsp;</a></span>parse_arguments()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">argparse Namespace onnxruntime.transformers.convert_generation.parse_arguments </td>
          <td>(</td>
          <td class="paramtype">list[str] | None &#160;</td>
          <td class="paramname"><em>argv</em> = <code>None</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Parse arguments

Args:
    argv (Optional[List[str]], optional): _description_. Defaults to None.

Returns:
    argparse.Namespace: Parsed arguments.
</pre> 
</div>
</div>
<a id="a70ef23edc233a0918604d86e8edd243f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a70ef23edc233a0918604d86e8edd243f">&#9670;&nbsp;</a></span>remove_shared_initializers()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.remove_shared_initializers </td>
          <td>(</td>
          <td class="paramtype">GraphProto&#160;</td>
          <td class="paramname"><em>graph1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">GraphProto&#160;</td>
          <td class="paramname"><em>graph2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>shared_prefix</em> = <code>&quot;shared_&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>min_elements</em> = <code>1024</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict | None &#160;</td>
          <td class="paramname"><em>signature_cache1</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict | None &#160;</td>
          <td class="paramname"><em>signature_cache2</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Remove initializers with same value from two graphs.

Args:
    graph1 (GraphProto): the first graph to process
    graph2 (GraphProto): the second graph to process
    shared_prefix (str): add prefix to the shared initializers among two graphs
    min_elements (int, optional): minimal number of elements for initializers to be considered. Defaults to 1024.
    signature_cache1 (dict): Optional dictionary to store data signatures of tensors in graph1 in order to speed up comparison
    signature_cache2 (dict): Optional dictionary to store data signatures of tensors in graph2 in order to speed up comparison
</pre> 
</div>
</div>
<a id="ac8ed568fe64c300fe95c098cdc288e89"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac8ed568fe64c300fe95c098cdc288e89">&#9670;&nbsp;</a></span>replace_mha_with_gqa()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.replace_mha_with_gqa </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a>&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>attn_mask</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>kv_num_heads</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>world_size</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>window_size</em> = <code>-1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a5ea6baadfae322c7517be2ac2bf4924c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ea6baadfae322c7517be2ac2bf4924c">&#9670;&nbsp;</a></span>shape_inference()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.shape_inference </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>onnx_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Shape inference on an onnx file, which will be overwritten.

Args:
    onnx_path (str): Path of onnx model
    use_external_data_format(bool): output tensors to external data or not.
</pre> 
</div>
</div>
<a id="a0e180a98cc07ad8087ab1b4a2990bcce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e180a98cc07ad8087ab1b4a2990bcce">&#9670;&nbsp;</a></span>shape_of()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.shape_of </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>vi</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7fceb651d8941fd9c76fbb5ee1f62cf4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fceb651d8941fd9c76fbb5ee1f62cf4">&#9670;&nbsp;</a></span>t5_to_onnx()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.t5_to_onnx </td>
          <td>(</td>
          <td class="paramtype">argparse.Namespace&#160;</td>
          <td class="paramname"><em>args</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert T5 model to onnx

Args:
    args (argparse.Namespace): arguments parsed from command line
</pre> 
</div>
</div>
<a id="a68adff2888f94264a038aaae3b45fa99"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68adff2888f94264a038aaae3b45fa99">&#9670;&nbsp;</a></span>test_gpt_model()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.test_gpt_model </td>
          <td>(</td>
          <td class="paramtype">argparse.Namespace&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[str] | None &#160;</td>
          <td class="paramname"><em>sentences</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>is_greedy</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test GPT-2 model

Args:
    args (argparse.Namespace): arguments parsed from command line
    sentences (Optional[List[str]], optional): input text. Defaults to None.

Returns:
    Union[Dict[str, Any], None]: A dictionary with string with metric name, and value can be integer or string.
</pre> 
</div>
</div>
<a id="a47c0eed667ac45a2fcbd6aa6e3771e14"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47c0eed667ac45a2fcbd6aa6e3771e14">&#9670;&nbsp;</a></span>test_t5_model()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.test_t5_model </td>
          <td>(</td>
          <td class="paramtype">argparse.Namespace&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[str] | None &#160;</td>
          <td class="paramname"><em>sentences</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test T5 or MT5 model

Args:
    args (argparse.Namespace): arguments parsed from command line
    sentences (Optional[List[str]], optional): input text. Defaults to None.

Returns:
    Union[Dict[str, Any], None]: A dictionary with string with metric name, and value can be integer or string.
</pre> 
</div>
</div>
<a id="a5f6ee9a43a9c965b2581e48a4b36b7b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f6ee9a43a9c965b2581e48a4b36b7b8">&#9670;&nbsp;</a></span>test_torch_performance()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> dict[str, Any] onnxruntime.transformers.convert_generation.test_torch_performance </td>
          <td>(</td>
          <td class="paramtype">argparse.Namespace&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">GPT2LMHeadModel | T5ForConditionalGeneration&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.Tensor&#160;</td>
          <td class="paramname"><em>input_ids</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.Tensor&#160;</td>
          <td class="paramname"><em>attention_mask</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>eos_token_id</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>pad_token_id</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[list[int]]&#160;</td>
          <td class="paramname"><em>bad_words_ids</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Test PyTorch performance of text generation.

Args:
    args (argparse.Namespace): arguments parsed from command line
    model (Union[GPT2LMHeadModel, T5ForConditionalGeneration]): PyTorch model
    input_ids (torch.Tensor): input_ids
    attention_mask (torch.Tensor): Attention mask
    eos_token_id (int): EOS token ID
    pad_token_id (int): Padding token ID
    bad_words_ids (List[List[int]]): Words shall not be generated.

Raises:
    RuntimeError: PyTorch with CUDA is not available for --use_gpu

Returns:
    Dict[str, Any]: A dictionary with string with metric name, and value can be integer or string.
</pre> 
</div>
</div>
<a id="a1c4d493f3425ac9fb54a3e7b98226993"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c4d493f3425ac9fb54a3e7b98226993">&#9670;&nbsp;</a></span>update_decoder_subgraph_output_cross_attention()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.update_decoder_subgraph_output_cross_attention </td>
          <td>(</td>
          <td class="paramtype">GraphProto&#160;</td>
          <td class="paramname"><em>subg</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a38f523a1344d80c0521659b7c85b1880"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a38f523a1344d80c0521659b7c85b1880">&#9670;&nbsp;</a></span>update_decoder_subgraph_past_present_share_buffer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.update_decoder_subgraph_past_present_share_buffer </td>
          <td>(</td>
          <td class="paramtype">GraphProto&#160;</td>
          <td class="paramname"><em>subg</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a8a174f55fd7ef4abeb382abf1fbd1109"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a174f55fd7ef4abeb382abf1fbd1109">&#9670;&nbsp;</a></span>update_decoder_subgraph_share_buffer_and_use_decoder_masked_mha()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.update_decoder_subgraph_share_buffer_and_use_decoder_masked_mha </td>
          <td>(</td>
          <td class="paramtype">ModelProto&#160;</td>
          <td class="paramname"><em>subg</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0c93dd20072a3579ba47915ea02de26c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c93dd20072a3579ba47915ea02de26c">&#9670;&nbsp;</a></span>update_decoder_subgraph_use_decoder_masked_attention()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool onnxruntime.transformers.convert_generation.update_decoder_subgraph_use_decoder_masked_attention </td>
          <td>(</td>
          <td class="paramtype">GraphProto&#160;</td>
          <td class="paramname"><em>subg</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>is_beam_search</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool
&#160;</td>
          <td class="paramname"><em>switch_attention</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update the Attention nodes to DecoderMaskedSelfAttention.

Args:
    subg (GraphProto): GraphProto of the decoder subgraph
    is_beam_search (bool): Boolean specifying if the sampling algo is BeamSearch
    switch_attention (bool): Boolean specifying if `Attention` is to be switched with `DecoderMaskedSelfAttention`
</pre> 
</div>
</div>
<a id="a35bf3ad31b7cda2a85477a6e92bcabef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a35bf3ad31b7cda2a85477a6e92bcabef">&#9670;&nbsp;</a></span>update_input_shapes_for_gpt2_decoder_model()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.update_input_shapes_for_gpt2_decoder_model </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>decoder_onnx_path</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_external_data_format</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update the input shapes for the inputs "input_ids" and "position_ids" and make the sequence length dim value 1 for each of them.
   The decoder model will be over-written.

Args:
    decoder_onnx_path (str): Path of GPT-2 decoder onnx model
    use_external_data_format(bool): output tensors to external data or not.
</pre> 
</div>
</div>
<a id="a2a4f066ceeebcee90ad792bfa322836d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2a4f066ceeebcee90ad792bfa322836d">&#9670;&nbsp;</a></span>verify_gpt2_subgraph()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.verify_gpt2_subgraph </td>
          <td>(</td>
          <td class="paramtype">onnx.GraphProto&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1transformers_1_1benchmark__helper_1_1Precision.html">Precision</a>&#160;</td>
          <td class="paramname"><em>precision</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Verify GPT-2 subgraph

Args:
    graph (onnx.GraphProto): onnx graph of GPT-2
    precision (Precision): Precision (FLOAT16 or FLOAT32) of the model.

Raises:
    ValueError: Number of inputs not expected.
    ValueError: Input name is not expected.
    ValueError: Input data type is not expected.
    ValueError: Number of outputs not expected.
    ValueError: Output name is not expected.
    ValueError: Output data type is not expected.
</pre> 
</div>
</div>
<a id="a40461afb0523406dc6f74dc768c83187"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40461afb0523406dc6f74dc768c83187">&#9670;&nbsp;</a></span>verify_t5_decoder_subgraph()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.verify_t5_decoder_subgraph </td>
          <td>(</td>
          <td class="paramtype">onnx.GraphProto&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1transformers_1_1benchmark__helper_1_1Precision.html">Precision</a>&#160;</td>
          <td class="paramname"><em>precision</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Verify T5 decoder subgraph

Args:
    graph (onnx.GraphProto): onnx graph of T5 decoder
    precision (Precision): Precision (FLOAT16 or FLOAT32) of the model.

Raises:
    ValueError: Number of inputs not expected.
    ValueError: Input name is not expected.
    ValueError: Input data type is not expected.
    ValueError: Number of outputs not expected.
    ValueError: Output name is not expected.
    ValueError: Output data type is not expected.
</pre> 
</div>
</div>
<a id="a7fb78fb2c4a6a143433de62d8abd67e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fb78fb2c4a6a143433de62d8abd67e2">&#9670;&nbsp;</a></span>verify_t5_encoder_decoder_init_subgraph()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.convert_generation.verify_t5_encoder_decoder_init_subgraph </td>
          <td>(</td>
          <td class="paramtype">onnx.GraphProto&#160;</td>
          <td class="paramname"><em>graph</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1transformers_1_1benchmark__helper_1_1Precision.html">Precision</a>&#160;</td>
          <td class="paramname"><em>precision</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Verify T5 decoder subgraph

Args:
    graph (onnx.GraphProto): onnx graph of T5 decoder
    precision (Precision): Precision (FLOAT16 or FLOAT32) of the model.

Raises:
    ValueError: Number of inputs not expected.
    ValueError: Input name is not expected.
    ValueError: Input data type is not expected.
    ValueError: Number of outputs not expected.
    ValueError: Output name is not expected.
    ValueError: Output data type is not expected.
</pre> 
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="ae613da3f21dc1636ff839db614ec84ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae613da3f21dc1636ff839db614ec84ae">&#9670;&nbsp;</a></span>logger</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnxruntime.transformers.convert_generation.logger = logging.getLogger(&quot;&quot;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
