<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: langchain_core.language_models.base.BaseLanguageModel Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacelangchain__core.html">langchain_core</a></li><li class="navelem"><a class="el" href="namespacelangchain__core_1_1language__models.html">language_models</a></li><li class="navelem"><a class="el" href="namespacelangchain__core_1_1language__models_1_1base.html">base</a></li><li class="navelem"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html">BaseLanguageModel</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-attribs">Static Public Attributes</a> &#124;
<a href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">langchain_core.language_models.base.BaseLanguageModel Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for langchain_core.language_models.base.BaseLanguageModel:</div>
<div class="dyncontent">
<div class="center"><img src="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel__inherit__graph.png" border="0" usemap="#alangchain__core_8language__models_8base_8BaseLanguageModel_inherit__map" alt="Inheritance graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for langchain_core.language_models.base.BaseLanguageModel:</div>
<div class="dyncontent">
<div class="center"><img src="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel__coll__graph.png" border="0" usemap="#alangchain__core_8language__models_8base_8BaseLanguageModel_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 1 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a7372e2d3dd1fe0bb947ba445704f62c0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7372e2d3dd1fe0bb947ba445704f62c0">set_verbose</a> (cls, Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a>] verbose)</td></tr>
<tr class="separator:a7372e2d3dd1fe0bb947ba445704f62c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb2e0d0544101ed7216a60648ff8ccec"><td class="memItemLeft" align="right" valign="top">TypeAlias&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#afb2e0d0544101ed7216a60648ff8ccec">InputType</a> (self)</td></tr>
<tr class="separator:afb2e0d0544101ed7216a60648ff8ccec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af549c328d66f2c758c743676b936da22"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#af549c328d66f2c758c743676b936da22">generate_prompt</a> (self, list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] prompts, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>, **Any kwargs)</td></tr>
<tr class="separator:af549c328d66f2c758c743676b936da22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98581b8dcc726a0f9f95603c0a60e6a4"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a98581b8dcc726a0f9f95603c0a60e6a4">agenerate_prompt</a> (self, list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] prompts, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a98581b8dcc726a0f9f95603c0a60e6a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a705f1e99b82dd3e0d19335ac47d85af8"><td class="memItemLeft" align="right" valign="top">Runnable[<a class="el" href="namespacelangchain__core_1_1language__models_1_1base.html#a00fb344778dc86fc8afd9cfc29b3b494">LanguageModelInput</a>, Union[dict, <a class="el" href="classpydantic_1_1main_1_1BaseModel.html">BaseModel</a>]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a705f1e99b82dd3e0d19335ac47d85af8">with_structured_output</a> (self, Union[dict, type] schema, **Any kwargs)</td></tr>
<tr class="separator:a705f1e99b82dd3e0d19335ac47d85af8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f7a5d85acda5e504d8f126d7951a8c2"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a8f7a5d85acda5e504d8f126d7951a8c2">predict</a> (self, str text, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a8f7a5d85acda5e504d8f126d7951a8c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2bb4737ed5b54fdc309a0308ff5e3b3"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#af2bb4737ed5b54fdc309a0308ff5e3b3">predict_messages</a> (self, list[BaseMessage] messages, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>, **Any kwargs)</td></tr>
<tr class="separator:af2bb4737ed5b54fdc309a0308ff5e3b3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3be2144da26f0253471e6137da6422a8"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a3be2144da26f0253471e6137da6422a8">apredict</a> (self, str text, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a3be2144da26f0253471e6137da6422a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad78ae674fd4fb11d8d4d1bc36162d50c"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ad78ae674fd4fb11d8d4d1bc36162d50c">apredict_messages</a> (self, list[BaseMessage] messages, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>, **Any kwargs)</td></tr>
<tr class="separator:ad78ae674fd4fb11d8d4d1bc36162d50c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2f592685022c930119b46a54cc642dd"><td class="memItemLeft" align="right" valign="top">list[int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ac2f592685022c930119b46a54cc642dd">get_token_ids</a> (self, str text)</td></tr>
<tr class="separator:ac2f592685022c930119b46a54cc642dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af464ecf7fc013bbaa4573b83aecdf626"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#af464ecf7fc013bbaa4573b83aecdf626">get_num_tokens</a> (self, str text)</td></tr>
<tr class="separator:af464ecf7fc013bbaa4573b83aecdf626"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3fa68289b24c36ba84881c769fca8f4"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ab3fa68289b24c36ba84881c769fca8f4">get_num_tokens_from_messages</a> (self, list[BaseMessage] messages, Optional[Sequence] tools=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>)</td></tr>
<tr class="separator:ab3fa68289b24c36ba84881c769fca8f4"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-attribs"></a>
Static Public Attributes</h2></td></tr>
<tr class="memitem:a15a531155fcd2fb285a070e9a31f1492"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a15a531155fcd2fb285a070e9a31f1492">default</a></td></tr>
<tr class="separator:a15a531155fcd2fb285a070e9a31f1492"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7df8406beb8687aa660ecd162c68bc2a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></td></tr>
<tr class="separator:a7df8406beb8687aa660ecd162c68bc2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf4fc9722efcd58dff847b0015165792"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#aaf4fc9722efcd58dff847b0015165792">exclude</a></td></tr>
<tr class="separator:aaf4fc9722efcd58dff847b0015165792"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44631b9ca0352cbd634ebe50a9dca3c9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a></td></tr>
<tr class="separator:a44631b9ca0352cbd634ebe50a9dca3c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad35476617e8f5e4e725b2b75f95f78ce"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ad35476617e8f5e4e725b2b75f95f78ce">default_factory</a></td></tr>
<tr class="separator:ad35476617e8f5e4e725b2b75f95f78ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a338ed3c32514080a24e93a9dbb70def1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a338ed3c32514080a24e93a9dbb70def1">True</a></td></tr>
<tr class="separator:a338ed3c32514080a24e93a9dbb70def1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2142f5d0cbb2717105aeb5b53d7b48f8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a2142f5d0cbb2717105aeb5b53d7b48f8">repr</a></td></tr>
<tr class="separator:a2142f5d0cbb2717105aeb5b53d7b48f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf486a987306c1af846c57557c76d31b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a></td></tr>
<tr class="separator:abf486a987306c1af846c57557c76d31b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13c293f947462f9c167f970c457d0b76"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a13c293f947462f9c167f970c457d0b76">model_config</a></td></tr>
<tr class="separator:a13c293f947462f9c167f970c457d0b76"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Abstract base class for interfacing with language models.

All language model wrappers inherited from BaseLanguageModel.
</pre> </div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a98581b8dcc726a0f9f95603c0a60e6a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a98581b8dcc726a0f9f95603c0a60e6a4">&#9670;&nbsp;</a></span>agenerate_prompt()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> LLMResult langchain_core.language_models.base.BaseLanguageModel.agenerate_prompt </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>]&#160;</td>
          <td class="paramname"><em>prompts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> &#160;</td>
          <td class="paramname"><em>callbacks</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asynchronously pass a sequence of prompts and return model generations.

This method should make use of batched calls for models that expose a batched
API.

Use this method when you want to:
    1. take advantage of batched calls,
    2. need more output from the model than just the top generated value,
    3. are building chains that are agnostic to the underlying language model
        type (e.g., pure text completion models vs chat models).

Args:
    prompts: List of PromptValues. A PromptValue is an object that can be
        converted to match the format of any language model (string for pure
        text generation models and BaseMessages for chat models).
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    callbacks: Callbacks to pass through. Used for executing additional
        functionality, such as logging or streaming, throughout generation.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    An LLMResult, which contains a list of candidate Generations for each input
        prompt and additional model provider-specific output.
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a65f501d0cbaffa30706877d01d89cae1">langchain_core.language_models.chat_models.BaseChatModel</a>.</p>

</div>
</div>
<a id="a3be2144da26f0253471e6137da6422a8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3be2144da26f0253471e6137da6422a8">&#9670;&nbsp;</a></span>apredict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> str langchain_core.language_models.base.BaseLanguageModel.apredict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>text</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any
    &#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asynchronously pass a string to the model and return a string.

Use this method when calling pure text generation models and only the top
    candidate generation is needed.

Args:
    text: String input to pass to the model.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    Top model prediction as a string.
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1language__models_1_1llms_1_1BaseLLM.html#acd8f5e454fa337809be5fcd4834a5cb6">langchain_core.language_models.llms.BaseLLM</a>, and <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a6388c19ec3a5171e4764c38a651ba220">langchain_core.language_models.chat_models.BaseChatModel</a>.</p>

</div>
</div>
<a id="ad78ae674fd4fb11d8d4d1bc36162d50c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad78ae674fd4fb11d8d4d1bc36162d50c">&#9670;&nbsp;</a></span>apredict_messages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> BaseMessage langchain_core.language_models.base.BaseLanguageModel.apredict_messages </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[BaseMessage]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asynchronously pass messages to the model and return a message.

Use this method when calling chat models and only the top
    candidate generation is needed.

Args:
    messages: A sequence of chat messages corresponding to a single model input.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    Top model prediction as a message.
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1language__models_1_1llms_1_1BaseLLM.html#a0fbc637ac90aa684f7279b212b7450f6">langchain_core.language_models.llms.BaseLLM</a>, and <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a3ce9cf41619799218c5cd08b82ac7e57">langchain_core.language_models.chat_models.BaseChatModel</a>.</p>

</div>
</div>
<a id="af549c328d66f2c758c743676b936da22"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af549c328d66f2c758c743676b936da22">&#9670;&nbsp;</a></span>generate_prompt()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> LLMResult langchain_core.language_models.base.BaseLanguageModel.generate_prompt </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>]&#160;</td>
          <td class="paramname"><em>prompts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> &#160;</td>
          <td class="paramname"><em>callbacks</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pass a sequence of prompts to the model and return model generations.

This method should make use of batched calls for models that expose a batched
API.

Use this method when you want to:
    1. take advantage of batched calls,
    2. need more output from the model than just the top generated value,
    3. are building chains that are agnostic to the underlying language model
        type (e.g., pure text completion models vs chat models).

Args:
    prompts: List of PromptValues. A PromptValue is an object that can be
        converted to match the format of any language model (string for pure
        text generation models and BaseMessages for chat models).
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    callbacks: Callbacks to pass through. Used for executing additional
        functionality, such as logging or streaming, throughout generation.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    An LLMResult, which contains a list of candidate Generations for each input
        prompt and additional model provider-specific output.
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ac244ce3ac312e236ad58bf30b2766948">langchain_core.language_models.chat_models.BaseChatModel</a>.</p>

</div>
</div>
<a id="af464ecf7fc013bbaa4573b83aecdf626"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af464ecf7fc013bbaa4573b83aecdf626">&#9670;&nbsp;</a></span>get_num_tokens()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int langchain_core.language_models.base.BaseLanguageModel.get_num_tokens </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>text</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get the number of tokens present in the text.

Useful for checking if an input fits in a model's context window.

Args:
    text: The string input to tokenize.

Returns:
    The integer number of tokens in the text.
</pre> 
</div>
</div>
<a id="ab3fa68289b24c36ba84881c769fca8f4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3fa68289b24c36ba84881c769fca8f4">&#9670;&nbsp;</a></span>get_num_tokens_from_messages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> int langchain_core.language_models.base.BaseLanguageModel.get_num_tokens_from_messages </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[BaseMessage]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence] &#160;</td>
          <td class="paramname"><em>tools</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get the number of tokens in the messages.

Useful for checking if an input fits in a model's context window.

**Note**: the base implementation of get_num_tokens_from_messages ignores
tool schemas.

Args:
    messages: The message inputs to tokenize.
    tools: If provided, sequence of dict, BaseModel, function, or BaseTools
        to be converted to tool schemas.

Returns:
    The sum of the number of tokens across the messages.
</pre> 
</div>
</div>
<a id="ac2f592685022c930119b46a54cc642dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac2f592685022c930119b46a54cc642dd">&#9670;&nbsp;</a></span>get_token_ids()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> list[int] langchain_core.language_models.base.BaseLanguageModel.get_token_ids </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>text</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return the ordered ids of the tokens in a text.

Args:
    text: The string input to tokenize.

Returns:
    A list of ids corresponding to the tokens in the text, in order they occur
        in the text.
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__openai_1_1llms_1_1base_1_1BaseOpenAI.html#a1a9d528dfd7bed04c26b57b6f4d61bc2">langchain_openai.llms.base.BaseOpenAI</a>, and <a class="el" href="classlangchain__openai_1_1chat__models_1_1base_1_1BaseChatOpenAI.html#aca416859079bcc19b874039ed4fa0116">langchain_openai.chat_models.base.BaseChatOpenAI</a>.</p>

</div>
</div>
<a id="afb2e0d0544101ed7216a60648ff8ccec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afb2e0d0544101ed7216a60648ff8ccec">&#9670;&nbsp;</a></span>InputType()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> TypeAlias langchain_core.language_models.base.BaseLanguageModel.InputType </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get the input type for this runnable.</pre> 
</div>
</div>
<a id="a8f7a5d85acda5e504d8f126d7951a8c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8f7a5d85acda5e504d8f126d7951a8c2">&#9670;&nbsp;</a></span>predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> str langchain_core.language_models.base.BaseLanguageModel.predict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>text</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any
    &#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pass a single string input to the model and return a string.

 Use this method when passing in raw text. If you want to pass in specific
    types of chat messages, use predict_messages.

Args:
    text: String input to pass to the model.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    Top model prediction as a string.
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1language__models_1_1llms_1_1BaseLLM.html#a835f58682deffa02a4ae95a7ff80dc3e">langchain_core.language_models.llms.BaseLLM</a>, and <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a416fa5eb36946a9fd05d45cbfaa71880">langchain_core.language_models.chat_models.BaseChatModel</a>.</p>

</div>
</div>
<a id="af2bb4737ed5b54fdc309a0308ff5e3b3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af2bb4737ed5b54fdc309a0308ff5e3b3">&#9670;&nbsp;</a></span>predict_messages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> BaseMessage langchain_core.language_models.base.BaseLanguageModel.predict_messages </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[BaseMessage]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pass a message sequence to the model and return a message.

Use this method when passing in chat messages. If you want to pass in raw text,
    use predict.

Args:
    messages: A sequence of chat messages corresponding to a single model input.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    Top model prediction as a message.
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1language__models_1_1llms_1_1BaseLLM.html#aa970ddef323b0d8b223670a7a3d71471">langchain_core.language_models.llms.BaseLLM</a>, and <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a2f77789b282f5a4762d0edd61a8eacd8">langchain_core.language_models.chat_models.BaseChatModel</a>.</p>

</div>
</div>
<a id="a7372e2d3dd1fe0bb947ba445704f62c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7372e2d3dd1fe0bb947ba445704f62c0">&#9670;&nbsp;</a></span>set_verbose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a> langchain_core.language_models.base.BaseLanguageModel.set_verbose </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a>]&#160;</td>
          <td class="paramname"><em>verbose</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">If verbose is None, set it.

This allows users to pass in None as verbose to access the global setting.

Args:
    verbose: The verbosity setting to use.

Returns:
    The verbosity setting to use.
</pre> 
</div>
</div>
<a id="a705f1e99b82dd3e0d19335ac47d85af8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a705f1e99b82dd3e0d19335ac47d85af8">&#9670;&nbsp;</a></span>with_structured_output()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Runnable[<a class="el" href="namespacelangchain__core_1_1language__models_1_1base.html#a00fb344778dc86fc8afd9cfc29b3b494">LanguageModelInput</a>, Union[dict, <a class="el" href="classpydantic_1_1main_1_1BaseModel.html">BaseModel</a>]] langchain_core.language_models.base.BaseLanguageModel.with_structured_output </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[dict, type]&#160;</td>
          <td class="paramname"><em>schema</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any
    &#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Not implemented on this class.</pre> 
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a44631b9ca0352cbd634ebe50a9dca3c9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a44631b9ca0352cbd634ebe50a9dca3c9">&#9670;&nbsp;</a></span>bool</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.base.BaseLanguageModel.bool</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="abf486a987306c1af846c57557c76d31b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf486a987306c1af846c57557c76d31b">&#9670;&nbsp;</a></span>Callbacks</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.base.BaseLanguageModel.Callbacks</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a15a531155fcd2fb285a070e9a31f1492"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a15a531155fcd2fb285a070e9a31f1492">&#9670;&nbsp;</a></span>default</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.base.BaseLanguageModel.default</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ad35476617e8f5e4e725b2b75f95f78ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad35476617e8f5e4e725b2b75f95f78ce">&#9670;&nbsp;</a></span>default_factory</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.base.BaseLanguageModel.default_factory</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aaf4fc9722efcd58dff847b0015165792"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaf4fc9722efcd58dff847b0015165792">&#9670;&nbsp;</a></span>exclude</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.base.BaseLanguageModel.exclude</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a13c293f947462f9c167f970c457d0b76"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a13c293f947462f9c167f970c457d0b76">&#9670;&nbsp;</a></span>model_config</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.base.BaseLanguageModel.model_config</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=  <a class="code" href="namespacepydantic_1_1v1_1_1config.html#acfc2d247c305b959d6aa3e9d99ab3df4">ConfigDict</a>(</div>
<div class="line">        arbitrary_types_allowed=<span class="keyword">True</span>,</div>
<div class="line">    )</div>
<div class="ttc" id="anamespacepydantic_1_1v1_1_1config_html_acfc2d247c305b959d6aa3e9d99ab3df4"><div class="ttname"><a href="namespacepydantic_1_1v1_1_1config.html#acfc2d247c305b959d6aa3e9d99ab3df4">pydantic.v1.config.ConfigDict</a></div><div class="ttdeci">ConfigDict</div><div class="ttdef"><b>Definition:</b> config.py:77</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a7df8406beb8687aa660ecd162c68bc2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7df8406beb8687aa660ecd162c68bc2a">&#9670;&nbsp;</a></span>None</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.base.BaseLanguageModel.None</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a2142f5d0cbb2717105aeb5b53d7b48f8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2142f5d0cbb2717105aeb5b53d7b48f8">&#9670;&nbsp;</a></span>repr</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.base.BaseLanguageModel.repr</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a338ed3c32514080a24e93a9dbb70def1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a338ed3c32514080a24e93a9dbb70def1">&#9670;&nbsp;</a></span>True</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.base.BaseLanguageModel.True</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>py3_env/lib/python3.10/site-packages/langchain_core/language_models/<a class="el" href="py3__env_2lib_2python3_810_2site-packages_2langchain__core_2language__models_2base_8py.html">base.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
