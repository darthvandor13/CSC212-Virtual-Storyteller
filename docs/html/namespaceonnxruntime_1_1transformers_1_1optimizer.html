<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: onnxruntime.transformers.optimizer Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceonnxruntime.html">onnxruntime</a></li><li class="navelem"><a class="el" href="namespaceonnxruntime_1_1transformers.html">transformers</a></li><li class="navelem"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1optimizer.html">optimizer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">onnxruntime.transformers.optimizer Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ab404cb074c5131f24c38192cb9e72159"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1optimizer.html#ab404cb074c5131f24c38192cb9e72159">optimize_by_onnxruntime</a> (str|ModelProto|None onnx_model=None, bool use_gpu=False, str|None optimized_model_path=None, int|None opt_level=99, list[str] disabled_optimizers=[], bool verbose=False, bool save_as_external_data=False, str external_data_filename=&quot;&quot;, int external_data_file_threshold=1024, *str|None provider=None, **deprecated_kwargs)</td></tr>
<tr class="separator:ab404cb074c5131f24c38192cb9e72159"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abc26ba9926ec11ccb52818bac0a4f7b0"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1optimizer.html#abc26ba9926ec11ccb52818bac0a4f7b0">optimize_by_fusion</a> (ModelProto model, str model_type=&quot;bert&quot;, int num_heads=0, int hidden_size=0, <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__options_1_1FusionOptions.html">FusionOptions</a>|None optimization_options=None)</td></tr>
<tr class="separator:abc26ba9926ec11ccb52818bac0a4f7b0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0855b2250d62fe132e48ee7aaaf70a62"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1optimizer.html#a0855b2250d62fe132e48ee7aaaf70a62">optimize_model</a> (str|ModelProto input, str model_type=&quot;bert&quot;, int num_heads=0, int hidden_size=0, <a class="el" href="classonnxruntime_1_1transformers_1_1fusion__options_1_1FusionOptions.html">FusionOptions</a>|None optimization_options=None, int|None opt_level=None, bool use_gpu=False, bool only_onnxruntime=False, bool verbose=False, *str|None provider=None)</td></tr>
<tr class="separator:a0855b2250d62fe132e48ee7aaaf70a62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0a6f34e207d3288455fd4b436d724ab3"><td class="memItemLeft" align="right" valign="top">dict[str, int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1optimizer.html#a0a6f34e207d3288455fd4b436d724ab3">get_fusion_statistics</a> (str optimized_model_path)</td></tr>
<tr class="separator:a0a6f34e207d3288455fd4b436d724ab3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa20fa841ab69cf2a2abc8e619b06a40b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1optimizer.html#aa20fa841ab69cf2a2abc8e619b06a40b">main</a> ()</td></tr>
<tr class="separator:aa20fa841ab69cf2a2abc8e619b06a40b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:acfe84c64a29b78bd2ae8987104576e4f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1optimizer.html#acfe84c64a29b78bd2ae8987104576e4f">logger</a> = logging.getLogger(__name__)</td></tr>
<tr class="separator:acfe84c64a29b78bd2ae8987104576e4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca7c237c734bf317c623210fd4ea4127"><td class="memItemLeft" align="right" valign="top">dictionary&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceonnxruntime_1_1transformers_1_1optimizer.html#aca7c237c734bf317c623210fd4ea4127">MODEL_TYPES</a></td></tr>
<tr class="separator:aca7c237c734bf317c623210fd4ea4127"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="a0a6f34e207d3288455fd4b436d724ab3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0a6f34e207d3288455fd4b436d724ab3">&#9670;&nbsp;</a></span>get_fusion_statistics()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> dict[str, int] onnxruntime.transformers.optimizer.get_fusion_statistics </td>
          <td>(</td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>optimized_model_path</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get counter of fused operators in optimized model.

Args:
    optimized_model_path (str): the path of onnx model.

Returns:
    A dictionary with operator type as key, and count as value
</pre> 
</div>
</div>
<a id="aa20fa841ab69cf2a2abc8e619b06a40b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa20fa841ab69cf2a2abc8e619b06a40b">&#9670;&nbsp;</a></span>main()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.transformers.optimizer.main </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="abc26ba9926ec11ccb52818bac0a4f7b0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abc26ba9926ec11ccb52818bac0a4f7b0">&#9670;&nbsp;</a></span>optimize_by_fusion()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a> onnxruntime.transformers.optimizer.optimize_by_fusion </td>
          <td>(</td>
          <td class="paramtype">ModelProto&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>model_type</em> = <code>&quot;bert&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>num_heads</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>hidden_size</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__options_1_1FusionOptions.html">FusionOptions</a> | None &#160;</td>
          <td class="paramname"><em>optimization_options</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Optimize Model by graph fusion logic.

Note that ONNXRuntime graph optimizations (like constant folding) will not be applied. So it is better to enable
constant folding during exporting ONNX model, or run optimize_by_onnxruntime on the model first like optimize_model.

For BERT model, num_heads and hidden_size are optional. For other model types, you need to specify these parameters.

Args:
    model (ModelProto): model object
    model_type (str, optional): model type - like bert, bert_tf, bert_keras or gpt2. Defaults to 'bert'.
    num_heads (int, optional): number of attention heads. Defaults to 0.
                               0 allows detect the parameter from graph automatically.
    hidden_size (int, optional): hidden size. Defaults to 0.
                                 0 allows detect the parameter from graph automatically.
    optimization_options (FusionOptions, optional): optimization options that turn on/off some fusions.
                                                    Defaults to None.

 Returns:
    object of an optimizer class.
</pre> 
</div>
</div>
<a id="ab404cb074c5131f24c38192cb9e72159"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab404cb074c5131f24c38192cb9e72159">&#9670;&nbsp;</a></span>optimize_by_onnxruntime()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">str onnxruntime.transformers.optimizer.optimize_by_onnxruntime </td>
          <td>(</td>
          <td class="paramtype">str | ModelProto | None &#160;</td>
          <td class="paramname"><em>onnx_model</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_gpu</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str | None &#160;</td>
          <td class="paramname"><em>optimized_model_path</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int | None &#160;</td>
          <td class="paramname"><em>opt_level</em> = <code>99</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[str] &#160;</td>
          <td class="paramname"><em>disabled_optimizers</em> = <code>[]</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>save_as_external_data</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>external_data_filename</em> = <code>&quot;&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>external_data_file_threshold</em> = <code>1024</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*str | None &#160;</td>
          <td class="paramname"><em>provider</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>deprecated_kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Use onnxruntime to optimize model.

Args:
    onnx_model (str | ModelProto): the path of input onnx model or ModelProto.
    use_gpu (bool): whether the optimized model is targeted to run in GPU.
    optimized_model_path (str or None): the path of optimized model.
    opt_level (int): graph optimization level.
    disabled_optimizers (List[str]): a list of names of disabled optimizers
    save_as_external_data (bool): whether to save external data outside of ONNX model
    external_data_filename (str): name of external data file. If not provided, name is automatically created from ONNX model.
    external_data_file_threshold (int): threshold to decide whether to save tensor in ONNX model or in external data file
    provider (str or None): execution provider to use if use_gpu
Returns:
    optimized_model_path (str): the path of optimized model
</pre> 
</div>
</div>
<a id="a0855b2250d62fe132e48ee7aaaf70a62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0855b2250d62fe132e48ee7aaaf70a62">&#9670;&nbsp;</a></span>optimize_model()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classonnxruntime_1_1transformers_1_1onnx__model_1_1OnnxModel.html">OnnxModel</a> onnxruntime.transformers.optimizer.optimize_model </td>
          <td>(</td>
          <td class="paramtype">str | ModelProto&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>model_type</em> = <code>&quot;bert&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>num_heads</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>hidden_size</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1transformers_1_1fusion__options_1_1FusionOptions.html">FusionOptions</a> | None &#160;</td>
          <td class="paramname"><em>optimization_options</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int | None &#160;</td>
          <td class="paramname"><em>opt_level</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_gpu</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>only_onnxruntime</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>verbose</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*str | None &#160;</td>
          <td class="paramname"><em>provider</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Optimize Model by OnnxRuntime and/or python fusion logic.

ONNX Runtime has graph optimizations (https://onnxruntime.ai/docs/performance/model-optimizations/graph-optimizations.html).
However, the coverage is limited. We also have graph fusions that implemented in Python to improve the coverage.
They can combined: ONNX Runtime will run first when opt_level &gt; 0, then graph fusions in Python will be applied.

To use ONNX Runtime only and no Python fusion logic, use only_onnxruntime flag and a positive opt_level like
    optimize_model(input, opt_level=1, use_gpu=False, only_onnxruntime=True)

When opt_level is None, we will choose default optimization level according to model type.

When opt_level is 0 and only_onnxruntime is False, only python fusion logic is used and onnxruntime is disabled.

When opt_level &gt; 1, use_gpu shall set properly
since the optimized graph might contain operators for GPU or CPU only.

If your model is intended for GPU inference only (especially float16 or mixed precision model), it is recommended to
set use_gpu to be True, otherwise the model is not optimized for GPU inference.

For BERT model, num_heads and hidden_size are optional. For other model types, you need specify these parameters.

Args:
    input (str | ModelProto): input model path or ModelProto.
    model_type (str, optional): model type - like bert, bert_tf, bert_keras or gpt2. Defaults to 'bert'.
    num_heads (int, optional): number of attention heads. Defaults to 0.
        0 allows detect the parameter from graph automatically.
    hidden_size (int, optional): hidden size. Defaults to 0.
        0 allows detect the parameter from graph automatically.
    optimization_options (FusionOptions, optional): optimization options that turn on/off some fusions.
        Defaults to None.
    opt_level (int, optional): onnxruntime graph optimization level (0, 1, 2 or 99) or None. Defaults to None.
        When the value is None, default value (1 for bert and gpt2, 0 for other model types) will be used.
        When the level &gt; 0, onnxruntime will be used to optimize model first.
    use_gpu (bool, optional): use gpu or not for onnxruntime. Defaults to False.
    only_onnxruntime (bool, optional): only use onnxruntime to optimize model, and no python fusion.
        Defaults to False.
    provider (str, optional): execution provider to use if use_gpu. Defaults to None.

 Returns:
    object of an optimizer class.
</pre> 
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="acfe84c64a29b78bd2ae8987104576e4f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acfe84c64a29b78bd2ae8987104576e4f">&#9670;&nbsp;</a></span>logger</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">onnxruntime.transformers.optimizer.logger = logging.getLogger(__name__)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aca7c237c734bf317c623210fd4ea4127"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca7c237c734bf317c623210fd4ea4127">&#9670;&nbsp;</a></span>MODEL_TYPES</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">dictionary onnxruntime.transformers.optimizer.MODEL_TYPES</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;=  {</div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;    <span class="stringliteral">&quot;bart&quot;</span>: (BartOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),</div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;    <span class="stringliteral">&quot;bert&quot;</span>: (BertOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;    <span class="stringliteral">&quot;bert_tf&quot;</span>: (BertOnnxModelTF, <span class="stringliteral">&quot;tf2onnx&quot;</span>, 0),</div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;    <span class="stringliteral">&quot;bert_keras&quot;</span>: (BertOnnxModelKeras, <span class="stringliteral">&quot;keras2onnx&quot;</span>, 0),</div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;    <span class="stringliteral">&quot;clip&quot;</span>: (ClipOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),  <span class="comment"># Clip in Stable Diffusion</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;    <span class="stringliteral">&quot;conformer&quot;</span>: (ConformerOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;    <span class="stringliteral">&quot;gpt2&quot;</span>: (Gpt2OnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),</div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;    <span class="stringliteral">&quot;gpt2_tf&quot;</span>: (Gpt2OnnxModel, <span class="stringliteral">&quot;tf2onnx&quot;</span>, 0),  <span class="comment"># might add a class for GPT2OnnxModel for TF later.</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;    <span class="stringliteral">&quot;gpt_neox&quot;</span>: (BertOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 0),  <span class="comment"># GPT-NeoX</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;    <span class="stringliteral">&quot;phi&quot;</span>: (PhiOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 0),</div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;    <span class="stringliteral">&quot;sam2&quot;</span>: (Sam2OnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),</div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;    <span class="stringliteral">&quot;swin&quot;</span>: (BertOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),</div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;    <span class="stringliteral">&quot;tnlr&quot;</span>: (TnlrOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),</div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;    <span class="stringliteral">&quot;t5&quot;</span>: (T5OnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 2),</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;    <span class="stringliteral">&quot;unet&quot;</span>: (UnetOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),  <span class="comment"># UNet in Stable Diffusion</span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;    <span class="stringliteral">&quot;vae&quot;</span>: (VaeOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),  <span class="comment"># UAE in Stable Diffusion</span></div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;    <span class="stringliteral">&quot;vit&quot;</span>: (BertOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),</div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;    <span class="stringliteral">&quot;mmdit&quot;</span>: (MmditOnnxModel, <span class="stringliteral">&quot;pytorch&quot;</span>, 1),</div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;}</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
