<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: langchain_core.language_models.chat_models.BaseChatModel Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacelangchain__core.html">langchain_core</a></li><li class="navelem"><a class="el" href="namespacelangchain__core_1_1language__models.html">language_models</a></li><li class="navelem"><a class="el" href="namespacelangchain__core_1_1language__models_1_1chat__models.html">chat_models</a></li><li class="navelem"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html">BaseChatModel</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pub-static-attribs">Static Public Attributes</a> &#124;
<a href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">langchain_core.language_models.chat_models.BaseChatModel Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for langchain_core.language_models.chat_models.BaseChatModel:</div>
<div class="dyncontent">
<div class="center"><img src="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel__inherit__graph.png" border="0" usemap="#alangchain__core_8language__models_8chat__models_8BaseChatModel_inherit__map" alt="Inheritance graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for langchain_core.language_models.chat_models.BaseChatModel:</div>
<div class="dyncontent">
<div class="center"><img src="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel__coll__graph.png" border="0" usemap="#alangchain__core_8language__models_8chat__models_8BaseChatModel_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 1 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ac849438ef69279f268fde8707305bb2a"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ac849438ef69279f268fde8707305bb2a">raise_deprecation</a> (cls, <a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a> values)</td></tr>
<tr class="separator:ac849438ef69279f268fde8707305bb2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66a9bdd0c57082986754bda600dae8ab"><td class="memItemLeft" align="right" valign="top">Any&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a66a9bdd0c57082986754bda600dae8ab">OutputType</a> (self)</td></tr>
<tr class="separator:a66a9bdd0c57082986754bda600dae8ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7f8c2cc4a26e9976707d2c61fb19e89"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ac7f8c2cc4a26e9976707d2c61fb19e89">invoke</a> (self, LanguageModelInput input, Optional[RunnableConfig] config=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:ac7f8c2cc4a26e9976707d2c61fb19e89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b25f07dd72cc1494428db258df52141"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a2b25f07dd72cc1494428db258df52141">ainvoke</a> (self, LanguageModelInput input, Optional[RunnableConfig] config=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a2b25f07dd72cc1494428db258df52141"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ada1f2f92a2fcd8774b60f04393256fb7"><td class="memItemLeft" align="right" valign="top">Iterator[BaseMessageChunk]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ada1f2f92a2fcd8774b60f04393256fb7">stream</a> (self, LanguageModelInput input, Optional[RunnableConfig] config=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:ada1f2f92a2fcd8774b60f04393256fb7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6e21a4ff68c4b90a8a4f41746963f916"><td class="memItemLeft" align="right" valign="top">AsyncIterator[BaseMessageChunk]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a6e21a4ff68c4b90a8a4f41746963f916">astream</a> (self, LanguageModelInput input, Optional[RunnableConfig] config=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a6e21a4ff68c4b90a8a4f41746963f916"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8f989a0d51f1a9577e5d05f41404c0ba"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8f989a0d51f1a9577e5d05f41404c0ba">generate</a> (self, list[list[BaseMessage]] messages, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] tags=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a>[str, Any]] metadata=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[str] run_name=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[uuid.UUID] run_id=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a8f989a0d51f1a9577e5d05f41404c0ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af2713f693278f2dd8cf536bc595f1425"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#af2713f693278f2dd8cf536bc595f1425">agenerate</a> (self, list[list[BaseMessage]] messages, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, *Optional[list[str]] tags=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a>[str, Any]] metadata=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[str] run_name=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, Optional[uuid.UUID] run_id=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:af2713f693278f2dd8cf536bc595f1425"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac244ce3ac312e236ad58bf30b2766948"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ac244ce3ac312e236ad58bf30b2766948">generate_prompt</a> (self, list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] prompts, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:ac244ce3ac312e236ad58bf30b2766948"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a65f501d0cbaffa30706877d01d89cae1"><td class="memItemLeft" align="right" valign="top">LLMResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a65f501d0cbaffa30706877d01d89cae1">agenerate_prompt</a> (self, list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] prompts, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a65f501d0cbaffa30706877d01d89cae1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a881bb6a83ba9c962d2cf142e0e2d5112"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a881bb6a83ba9c962d2cf142e0e2d5112">__call__</a> (self, list[BaseMessage] messages, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> callbacks=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a881bb6a83ba9c962d2cf142e0e2d5112"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d014c11202e208de1d52429ce22cc41"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a9d014c11202e208de1d52429ce22cc41">call_as_llm</a> (self, str message, Optional[list[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a9d014c11202e208de1d52429ce22cc41"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a416fa5eb36946a9fd05d45cbfaa71880"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a416fa5eb36946a9fd05d45cbfaa71880">predict</a> (self, str text, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a416fa5eb36946a9fd05d45cbfaa71880"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f77789b282f5a4762d0edd61a8eacd8"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a2f77789b282f5a4762d0edd61a8eacd8">predict_messages</a> (self, list[BaseMessage] messages, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a2f77789b282f5a4762d0edd61a8eacd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6388c19ec3a5171e4764c38a651ba220"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a6388c19ec3a5171e4764c38a651ba220">apredict</a> (self, str text, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a6388c19ec3a5171e4764c38a651ba220"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3ce9cf41619799218c5cd08b82ac7e57"><td class="memItemLeft" align="right" valign="top">BaseMessage&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a3ce9cf41619799218c5cd08b82ac7e57">apredict_messages</a> (self, list[BaseMessage] messages, *Optional[Sequence[str]] stop=<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a>, **Any kwargs)</td></tr>
<tr class="separator:a3ce9cf41619799218c5cd08b82ac7e57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75830e7f62ab3b08307792385cf68454"><td class="memItemLeft" align="right" valign="top">dict&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a> (self, **Any kwargs)</td></tr>
<tr class="separator:a75830e7f62ab3b08307792385cf68454"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0584ebeaf94fe4f5ede42df5c4635d2d"><td class="memItemLeft" align="right" valign="top">Runnable[LanguageModelInput, BaseMessage]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a0584ebeaf94fe4f5ede42df5c4635d2d">bind_tools</a> (self, Sequence[Union[typing.Dict[str, Any], type, Callable, BaseTool] # noqa:UP006] tools, **Any kwargs)</td></tr>
<tr class="separator:a0584ebeaf94fe4f5ede42df5c4635d2d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a69c4cb0e6768a99204536ccde028b824"><td class="memItemLeft" align="right" valign="top">Runnable[LanguageModelInput, Union[typing.Dict, <a class="el" href="classpydantic_1_1main_1_1BaseModel.html">BaseModel</a>]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a69c4cb0e6768a99204536ccde028b824">with_structured_output</a> (self, Union[typing.Dict, type] schema, *<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a> include_raw=False, **Any kwargs)</td></tr>
<tr class="separator:a69c4cb0e6768a99204536ccde028b824"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html">langchain_core.language_models.base.BaseLanguageModel</a></td></tr>
<tr class="memitem:a7372e2d3dd1fe0bb947ba445704f62c0 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7372e2d3dd1fe0bb947ba445704f62c0">set_verbose</a> (cls, Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a>] verbose)</td></tr>
<tr class="separator:a7372e2d3dd1fe0bb947ba445704f62c0 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb2e0d0544101ed7216a60648ff8ccec inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">TypeAlias&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#afb2e0d0544101ed7216a60648ff8ccec">InputType</a> (self)</td></tr>
<tr class="separator:afb2e0d0544101ed7216a60648ff8ccec inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a705f1e99b82dd3e0d19335ac47d85af8 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">Runnable[<a class="el" href="namespacelangchain__core_1_1language__models_1_1base.html#a00fb344778dc86fc8afd9cfc29b3b494">LanguageModelInput</a>, Union[dict, <a class="el" href="classpydantic_1_1main_1_1BaseModel.html">BaseModel</a>]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a705f1e99b82dd3e0d19335ac47d85af8">with_structured_output</a> (self, Union[dict, type] schema, **Any kwargs)</td></tr>
<tr class="separator:a705f1e99b82dd3e0d19335ac47d85af8 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2f592685022c930119b46a54cc642dd inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">list[int]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ac2f592685022c930119b46a54cc642dd">get_token_ids</a> (self, str text)</td></tr>
<tr class="separator:ac2f592685022c930119b46a54cc642dd inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af464ecf7fc013bbaa4573b83aecdf626 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#af464ecf7fc013bbaa4573b83aecdf626">get_num_tokens</a> (self, str text)</td></tr>
<tr class="separator:af464ecf7fc013bbaa4573b83aecdf626 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3fa68289b24c36ba84881c769fca8f4 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ab3fa68289b24c36ba84881c769fca8f4">get_num_tokens_from_messages</a> (self, list[BaseMessage] messages, Optional[Sequence] tools=<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a>)</td></tr>
<tr class="separator:ab3fa68289b24c36ba84881c769fca8f4 inherit pub_methods_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a2ba23caed0e36512d90f1c30b3fdaa21"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a2ba23caed0e36512d90f1c30b3fdaa21">disable_streaming</a></td></tr>
<tr class="separator:a2ba23caed0e36512d90f1c30b3fdaa21"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-attribs"></a>
Static Public Attributes</h2></td></tr>
<tr class="memitem:ae86a49547d47ee5d37e5de4511d6dcc8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#ae86a49547d47ee5d37e5de4511d6dcc8">name</a></td></tr>
<tr class="separator:ae86a49547d47ee5d37e5de4511d6dcc8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afd62802c6d8b05f19b8377934270e445"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#afd62802c6d8b05f19b8377934270e445">since</a></td></tr>
<tr class="separator:afd62802c6d8b05f19b8377934270e445"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c727a2c91c467be5ec9880198831cd7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a5c727a2c91c467be5ec9880198831cd7">removal</a></td></tr>
<tr class="separator:a5c727a2c91c467be5ec9880198831cd7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37740e205816c167eea0aaf33efade2f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a37740e205816c167eea0aaf33efade2f">alternative</a></td></tr>
<tr class="separator:a37740e205816c167eea0aaf33efade2f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5286b5305fcbcbf7c93a97bdf43ad8b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#aa5286b5305fcbcbf7c93a97bdf43ad8b">default</a></td></tr>
<tr class="separator:aa5286b5305fcbcbf7c93a97bdf43ad8b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cc2bc655191b554549a0c76122b786b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></td></tr>
<tr class="separator:a8cc2bc655191b554549a0c76122b786b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61d7382fe5885461f3f666459c4f9614"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a61d7382fe5885461f3f666459c4f9614">exclude</a></td></tr>
<tr class="separator:a61d7382fe5885461f3f666459c4f9614"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af7f8d0efe19d1f2e7e8d639e03688fa9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#af7f8d0efe19d1f2e7e8d639e03688fa9">model_config</a></td></tr>
<tr class="separator:af7f8d0efe19d1f2e7e8d639e03688fa9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td colspan="2" onclick="javascript:toggleInherit('pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel')"><img src="closed.png" alt="-"/>&#160;Static Public Attributes inherited from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html">langchain_core.language_models.base.BaseLanguageModel</a></td></tr>
<tr class="memitem:a15a531155fcd2fb285a070e9a31f1492 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a15a531155fcd2fb285a070e9a31f1492">default</a></td></tr>
<tr class="separator:a15a531155fcd2fb285a070e9a31f1492 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7df8406beb8687aa660ecd162c68bc2a inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a7df8406beb8687aa660ecd162c68bc2a">None</a></td></tr>
<tr class="separator:a7df8406beb8687aa660ecd162c68bc2a inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf4fc9722efcd58dff847b0015165792 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#aaf4fc9722efcd58dff847b0015165792">exclude</a></td></tr>
<tr class="separator:aaf4fc9722efcd58dff847b0015165792 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a44631b9ca0352cbd634ebe50a9dca3c9 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a></td></tr>
<tr class="separator:a44631b9ca0352cbd634ebe50a9dca3c9 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad35476617e8f5e4e725b2b75f95f78ce inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ad35476617e8f5e4e725b2b75f95f78ce">default_factory</a></td></tr>
<tr class="separator:ad35476617e8f5e4e725b2b75f95f78ce inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a338ed3c32514080a24e93a9dbb70def1 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a338ed3c32514080a24e93a9dbb70def1">True</a></td></tr>
<tr class="separator:a338ed3c32514080a24e93a9dbb70def1 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2142f5d0cbb2717105aeb5b53d7b48f8 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a2142f5d0cbb2717105aeb5b53d7b48f8">repr</a></td></tr>
<tr class="separator:a2142f5d0cbb2717105aeb5b53d7b48f8 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf486a987306c1af846c57557c76d31b inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a></td></tr>
<tr class="separator:abf486a987306c1af846c57557c76d31b inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a13c293f947462f9c167f970c457d0b76 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a13c293f947462f9c167f970c457d0b76">model_config</a></td></tr>
<tr class="separator:a13c293f947462f9c167f970c457d0b76 inherit pub_static_attribs_classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Base class for chat models.

Key imperative methods:
    Methods that actually call the underlying model.

    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
    | Method                    | Input                                                          | Output                                                              | Description                                                                                      |
    +===========================+================================================================+=====================================================================+==================================================================================================+
    | `invoke`                  | str | List[dict | tuple | BaseMessage] | PromptValue           | BaseMessage                                                         | A single chat model call.                                                                        |
    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
    | `ainvoke`                 | '''                                                            | BaseMessage                                                         | Defaults to running invoke in an async executor.                                                 |
    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
    | `stream`                  | '''                                                            | Iterator[BaseMessageChunk]                                          | Defaults to yielding output of invoke.                                                           |
    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
    | `astream`                 | '''                                                            | AsyncIterator[BaseMessageChunk]                                     | Defaults to yielding output of ainvoke.                                                          |
    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
    | `astream_events`          | '''                                                            | AsyncIterator[StreamEvent]                                          | Event types: 'on_chat_model_start', 'on_chat_model_stream', 'on_chat_model_end'.                 |
    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
    | `batch`                   | List[''']                                                      | List[BaseMessage]                                                   | Defaults to running invoke in concurrent threads.                                                |
    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
    | `abatch`                  | List[''']                                                      | List[BaseMessage]                                                   | Defaults to running ainvoke in concurrent threads.                                               |
    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
    | `batch_as_completed`      | List[''']                                                      | Iterator[Tuple[int, Union[BaseMessage, Exception]]]                 | Defaults to running invoke in concurrent threads.                                                |
    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+
    | `abatch_as_completed`     | List[''']                                                      | AsyncIterator[Tuple[int, Union[BaseMessage, Exception]]]            | Defaults to running ainvoke in concurrent threads.                                               |
    +---------------------------+----------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+

    This table provides a brief overview of the main imperative methods. Please see the base Runnable reference for full documentation.

Key declarative methods:
    Methods for creating another Runnable using the ChatModel.

    +----------------------------------+-----------------------------------------------------------------------------------------------------------+
    | Method                           | Description                                                                                               |
    +==================================+===========================================================================================================+
    | `bind_tools`                     | Create ChatModel that can call tools.                                                                     |
    +----------------------------------+-----------------------------------------------------------------------------------------------------------+
    | `with_structured_output`         | Create wrapper that structures model output using schema.                                                 |
    +----------------------------------+-----------------------------------------------------------------------------------------------------------+
    | `with_retry`                     | Create wrapper that retries model calls on failure.                                                       |
    +----------------------------------+-----------------------------------------------------------------------------------------------------------+
    | `with_fallbacks`                 | Create wrapper that falls back to other models on failure.                                                |
    +----------------------------------+-----------------------------------------------------------------------------------------------------------+
    | `configurable_fields`            | Specify init args of the model that can be configured at runtime via the RunnableConfig.                  |
    +----------------------------------+-----------------------------------------------------------------------------------------------------------+
    | `configurable_alternatives`      | Specify alternative models which can be swapped in at runtime via the RunnableConfig.                     |
    +----------------------------------+-----------------------------------------------------------------------------------------------------------+

    This table provides a brief overview of the main declarative methods. Please see the reference for each method for full documentation.

Creating custom chat model:
    Custom chat model implementations should inherit from this class.
    Please reference the table below for information about which
    methods and properties are required or optional for implementations.

    +----------------------------------+--------------------------------------------------------------------+-------------------+
    | Method/Property                  | Description                                                        | Required/Optional |
    +==================================+====================================================================+===================+
    | `_generate`                      | Use to generate a chat result from a prompt                        | Required          |
    +----------------------------------+--------------------------------------------------------------------+-------------------+
    | `_llm_type` (property)           | Used to uniquely identify the type of the model. Used for logging. | Required          |
    +----------------------------------+--------------------------------------------------------------------+-------------------+
    | `_identifying_params` (property) | Represent model parameterization for tracing purposes.             | Optional          |
    +----------------------------------+--------------------------------------------------------------------+-------------------+
    | `_stream`                        | Use to implement streaming                                         | Optional          |
    +----------------------------------+--------------------------------------------------------------------+-------------------+
    | `_agenerate`                     | Use to implement a native async method                             | Optional          |
    +----------------------------------+--------------------------------------------------------------------+-------------------+
    | `_astream`                       | Use to implement async version of `_stream`                        | Optional          |
    +----------------------------------+--------------------------------------------------------------------+-------------------+

    Follow the guide for more information on how to implement a custom Chat Model:
    [Guide](https://python.langchain.com/docs/how_to/custom_chat_model/).</pre> </div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a881bb6a83ba9c962d2cf142e0e2d5112"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a881bb6a83ba9c962d2cf142e0e2d5112">&#9670;&nbsp;</a></span>__call__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> BaseMessage langchain_core.language_models.chat_models.BaseChatModel.__call__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[BaseMessage]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> &#160;</td>
          <td class="paramname"><em>callbacks</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="af2713f693278f2dd8cf536bc595f1425"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af2713f693278f2dd8cf536bc595f1425">&#9670;&nbsp;</a></span>agenerate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> LLMResult langchain_core.language_models.chat_models.BaseChatModel.agenerate </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[list[BaseMessage]]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> &#160;</td>
          <td class="paramname"><em>callbacks</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[list[str]] &#160;</td>
          <td class="paramname"><em>tags</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a>[str, Any]] &#160;</td>
          <td class="paramname"><em>metadata</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>run_name</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[uuid.UUID] &#160;</td>
          <td class="paramname"><em>run_id</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asynchronously pass a sequence of prompts to a model and return generations.

This method should make use of batched calls for models that expose a batched
API.

Use this method when you want to:
    1. take advantage of batched calls,
    2. need more output from the model than just the top generated value,
    3. are building chains that are agnostic to the underlying language model
        type (e.g., pure text completion models vs chat models).

Args:
    messages: List of list of messages.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    callbacks: Callbacks to pass through. Used for executing additional
        functionality, such as logging or streaming, throughout generation.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    An LLMResult, which contains a list of candidate Generations for each input
        prompt and additional model provider-specific output.
</pre> 
</div>
</div>
<a id="a65f501d0cbaffa30706877d01d89cae1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a65f501d0cbaffa30706877d01d89cae1">&#9670;&nbsp;</a></span>agenerate_prompt()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> LLMResult langchain_core.language_models.chat_models.BaseChatModel.agenerate_prompt </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>]&#160;</td>
          <td class="paramname"><em>prompts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> &#160;</td>
          <td class="paramname"><em>callbacks</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asynchronously pass a sequence of prompts and return model generations.

This method should make use of batched calls for models that expose a batched
API.

Use this method when you want to:
    1. take advantage of batched calls,
    2. need more output from the model than just the top generated value,
    3. are building chains that are agnostic to the underlying language model
        type (e.g., pure text completion models vs chat models).

Args:
    prompts: List of PromptValues. A PromptValue is an object that can be
        converted to match the format of any language model (string for pure
        text generation models and BaseMessages for chat models).
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    callbacks: Callbacks to pass through. Used for executing additional
        functionality, such as logging or streaming, throughout generation.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    An LLMResult, which contains a list of candidate Generations for each input
        prompt and additional model provider-specific output.
</pre> 
<p>Reimplemented from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a98581b8dcc726a0f9f95603c0a60e6a4">langchain_core.language_models.base.BaseLanguageModel</a>.</p>

</div>
</div>
<a id="a2b25f07dd72cc1494428db258df52141"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b25f07dd72cc1494428db258df52141">&#9670;&nbsp;</a></span>ainvoke()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> BaseMessage langchain_core.language_models.chat_models.BaseChatModel.ainvoke </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">LanguageModelInput&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[RunnableConfig] &#160;</td>
          <td class="paramname"><em>config</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6388c19ec3a5171e4764c38a651ba220"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6388c19ec3a5171e4764c38a651ba220">&#9670;&nbsp;</a></span>apredict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> str langchain_core.language_models.chat_models.BaseChatModel.apredict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>text</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any
    &#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asynchronously pass a string to the model and return a string.

Use this method when calling pure text generation models and only the top
    candidate generation is needed.

Args:
    text: String input to pass to the model.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    Top model prediction as a string.
</pre> 
<p>Reimplemented from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a3be2144da26f0253471e6137da6422a8">langchain_core.language_models.base.BaseLanguageModel</a>.</p>

</div>
</div>
<a id="a3ce9cf41619799218c5cd08b82ac7e57"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3ce9cf41619799218c5cd08b82ac7e57">&#9670;&nbsp;</a></span>apredict_messages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> BaseMessage langchain_core.language_models.chat_models.BaseChatModel.apredict_messages </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[BaseMessage]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asynchronously pass messages to the model and return a message.

Use this method when calling chat models and only the top
    candidate generation is needed.

Args:
    messages: A sequence of chat messages corresponding to a single model input.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    Top model prediction as a message.
</pre> 
<p>Reimplemented from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#ad78ae674fd4fb11d8d4d1bc36162d50c">langchain_core.language_models.base.BaseLanguageModel</a>.</p>

</div>
</div>
<a id="a6e21a4ff68c4b90a8a4f41746963f916"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6e21a4ff68c4b90a8a4f41746963f916">&#9670;&nbsp;</a></span>astream()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> AsyncIterator[BaseMessageChunk] langchain_core.language_models.chat_models.BaseChatModel.astream </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">LanguageModelInput&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[RunnableConfig] &#160;</td>
          <td class="paramname"><em>config</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a0584ebeaf94fe4f5ede42df5c4635d2d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0584ebeaf94fe4f5ede42df5c4635d2d">&#9670;&nbsp;</a></span>bind_tools()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Runnable[LanguageModelInput, BaseMessage] langchain_core.language_models.chat_models.BaseChatModel.bind_tools </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Sequence[
            Union[typing.Dict[str, Any], type, Callable, BaseTool]  # noqa: UP006
        ]&#160;</td>
          <td class="paramname"><em>tools</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a9d014c11202e208de1d52429ce22cc41"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9d014c11202e208de1d52429ce22cc41">&#9670;&nbsp;</a></span>call_as_llm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> str langchain_core.language_models.chat_models.BaseChatModel.call_as_llm </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>message</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any
    &#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a75830e7f62ab3b08307792385cf68454"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a75830e7f62ab3b08307792385cf68454">&#9670;&nbsp;</a></span>dict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> dict langchain_core.language_models.chat_models.BaseChatModel.dict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return a dictionary of the LLM.</pre> 
</div>
</div>
<a id="a8f989a0d51f1a9577e5d05f41404c0ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8f989a0d51f1a9577e5d05f41404c0ba">&#9670;&nbsp;</a></span>generate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> LLMResult langchain_core.language_models.chat_models.BaseChatModel.generate </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[list[BaseMessage]]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> &#160;</td>
          <td class="paramname"><em>callbacks</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[list[str]] &#160;</td>
          <td class="paramname"><em>tags</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[<a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a>[str, Any]] &#160;</td>
          <td class="paramname"><em>metadata</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>run_name</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[uuid.UUID] &#160;</td>
          <td class="paramname"><em>run_id</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pass a sequence of prompts to the model and return model generations.

This method should make use of batched calls for models that expose a batched
API.

Use this method when you want to:
    1. take advantage of batched calls,
    2. need more output from the model than just the top generated value,
    3. are building chains that are agnostic to the underlying language model
        type (e.g., pure text completion models vs chat models).

Args:
    messages: List of list of messages.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    callbacks: Callbacks to pass through. Used for executing additional
        functionality, such as logging or streaming, throughout generation.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    An LLMResult, which contains a list of candidate Generations for each input
        prompt and additional model provider-specific output.
</pre> 
</div>
</div>
<a id="ac244ce3ac312e236ad58bf30b2766948"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac244ce3ac312e236ad58bf30b2766948">&#9670;&nbsp;</a></span>generate_prompt()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> LLMResult langchain_core.language_models.chat_models.BaseChatModel.generate_prompt </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[<a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>]&#160;</td>
          <td class="paramname"><em>prompts</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#abf486a987306c1af846c57557c76d31b">Callbacks</a> &#160;</td>
          <td class="paramname"><em>callbacks</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pass a sequence of prompts to the model and return model generations.

This method should make use of batched calls for models that expose a batched
API.

Use this method when you want to:
    1. take advantage of batched calls,
    2. need more output from the model than just the top generated value,
    3. are building chains that are agnostic to the underlying language model
        type (e.g., pure text completion models vs chat models).

Args:
    prompts: List of PromptValues. A PromptValue is an object that can be
        converted to match the format of any language model (string for pure
        text generation models and BaseMessages for chat models).
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    callbacks: Callbacks to pass through. Used for executing additional
        functionality, such as logging or streaming, throughout generation.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    An LLMResult, which contains a list of candidate Generations for each input
        prompt and additional model provider-specific output.
</pre> 
<p>Reimplemented from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#af549c328d66f2c758c743676b936da22">langchain_core.language_models.base.BaseLanguageModel</a>.</p>

</div>
</div>
<a id="ac7f8c2cc4a26e9976707d2c61fb19e89"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac7f8c2cc4a26e9976707d2c61fb19e89">&#9670;&nbsp;</a></span>invoke()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> BaseMessage langchain_core.language_models.chat_models.BaseChatModel.invoke </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">LanguageModelInput&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[RunnableConfig] &#160;</td>
          <td class="paramname"><em>config</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a66a9bdd0c57082986754bda600dae8ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66a9bdd0c57082986754bda600dae8ab">&#9670;&nbsp;</a></span>OutputType()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Any langchain_core.language_models.chat_models.BaseChatModel.OutputType </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Get the output type for this runnable.</pre> 
</div>
</div>
<a id="a416fa5eb36946a9fd05d45cbfaa71880"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a416fa5eb36946a9fd05d45cbfaa71880">&#9670;&nbsp;</a></span>predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> str langchain_core.language_models.chat_models.BaseChatModel.predict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>text</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any
    &#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pass a single string input to the model and return a string.

 Use this method when passing in raw text. If you want to pass in specific
    types of chat messages, use predict_messages.

Args:
    text: String input to pass to the model.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    Top model prediction as a string.
</pre> 
<p>Reimplemented from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a8f7a5d85acda5e504d8f126d7951a8c2">langchain_core.language_models.base.BaseLanguageModel</a>.</p>

</div>
</div>
<a id="a2f77789b282f5a4762d0edd61a8eacd8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f77789b282f5a4762d0edd61a8eacd8">&#9670;&nbsp;</a></span>predict_messages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> BaseMessage langchain_core.language_models.chat_models.BaseChatModel.predict_messages </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[BaseMessage]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pass a message sequence to the model and return a message.

Use this method when passing in chat messages. If you want to pass in raw text,
    use predict.

Args:
    messages: A sequence of chat messages corresponding to a single model input.
    stop: Stop words to use when generating. Model output is cut off at the
        first occurrence of any of these substrings.
    **kwargs: Arbitrary additional keyword arguments. These are usually passed
        to the model provider API call.

Returns:
    Top model prediction as a message.
</pre> 
<p>Reimplemented from <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#af2bb4737ed5b54fdc309a0308ff5e3b3">langchain_core.language_models.base.BaseLanguageModel</a>.</p>

</div>
</div>
<a id="ac849438ef69279f268fde8707305bb2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac849438ef69279f268fde8707305bb2a">&#9670;&nbsp;</a></span>raise_deprecation()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Any langchain_core.language_models.chat_models.BaseChatModel.raise_deprecation </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>cls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a75830e7f62ab3b08307792385cf68454">dict</a>&#160;</td>
          <td class="paramname"><em>values</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Raise deprecation warning if callback_manager is used.

Args:
    values (Dict): Values to validate.

Returns:
    Dict: Validated values.

Raises:
    DeprecationWarning: If callback_manager is used.
</pre> 
</div>
</div>
<a id="ada1f2f92a2fcd8774b60f04393256fb7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ada1f2f92a2fcd8774b60f04393256fb7">&#9670;&nbsp;</a></span>stream()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Iterator[BaseMessageChunk] langchain_core.language_models.chat_models.BaseChatModel.stream </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">LanguageModelInput&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[RunnableConfig] &#160;</td>
          <td class="paramname"><em>config</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[list[str]] &#160;</td>
          <td class="paramname"><em>stop</em> = <code><a class="el" href="classlangchain__core_1_1language__models_1_1chat__models_1_1BaseChatModel.html#a8cc2bc655191b554549a0c76122b786b">None</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a69c4cb0e6768a99204536ccde028b824"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a69c4cb0e6768a99204536ccde028b824">&#9670;&nbsp;</a></span>with_structured_output()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Runnable[LanguageModelInput, Union[typing.Dict, <a class="el" href="classpydantic_1_1main_1_1BaseModel.html">BaseModel</a>]] langchain_core.language_models.chat_models.BaseChatModel.with_structured_output </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[typing.Dict, type]&#160;</td>
          <td class="paramname"><em>schema</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*<a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html#a44631b9ca0352cbd634ebe50a9dca3c9">bool</a> &#160;</td>
          <td class="paramname"><em>include_raw</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Model wrapper that returns outputs formatted to match the given schema.

Args:
    schema:
        The output schema. Can be passed in as:
            - an OpenAI function/tool schema,
            - a JSON Schema,
            - a TypedDict class,
            - or a Pydantic class.
        If ``schema`` is a Pydantic class then the model output will be a
        Pydantic instance of that class, and the model-generated fields will be
        validated by the Pydantic class. Otherwise the model output will be a
        dict and will not be validated. See :meth:`langchain_core.utils.function_calling.convert_to_openai_tool`
        for more on how to properly specify types and descriptions of
        schema fields when specifying a Pydantic or TypedDict class.

    include_raw:
        If False then only the parsed structured output is returned. If
        an error occurs during model output parsing it will be raised. If True
        then both the raw model response (a BaseMessage) and the parsed model
        response will be returned. If an error occurs during output parsing it
        will be caught and returned as well. The final output is always a dict
        with keys "raw", "parsed", and "parsing_error".

Returns:
    A Runnable that takes same inputs as a :class:`langchain_core.language_models.chat.BaseChatModel`.

    If ``include_raw`` is False and ``schema`` is a Pydantic class, Runnable outputs
    an instance of ``schema`` (i.e., a Pydantic object).

    Otherwise, if ``include_raw`` is False then Runnable outputs a dict.

    If ``include_raw`` is True, then Runnable outputs a dict with keys:
        - ``"raw"``: BaseMessage
        - ``"parsed"``: None if there was a parsing error, otherwise the type depends on the ``schema`` as described above.
        - ``"parsing_error"``: Optional[BaseException]

Example: Pydantic schema (include_raw=False):
    .. code-block:: python

        from pydantic import BaseModel

        class AnswerWithJustification(BaseModel):
            '''An answer to the user question along with justification for the answer.'''
            answer: str
            justification: str

        llm = ChatModel(model="model-name", temperature=0)
        structured_llm = llm.with_structured_output(AnswerWithJustification)

        structured_llm.invoke("What weighs more a pound of bricks or a pound of feathers")

        # -&gt; AnswerWithJustification(
        #     answer='They weigh the same',
        #     justification='Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.'
        # )

Example: Pydantic schema (include_raw=True):
    .. code-block:: python

        from pydantic import BaseModel

        class AnswerWithJustification(BaseModel):
            '''An answer to the user question along with justification for the answer.'''
            answer: str
            justification: str

        llm = ChatModel(model="model-name", temperature=0)
        structured_llm = llm.with_structured_output(AnswerWithJustification, include_raw=True)

        structured_llm.invoke("What weighs more a pound of bricks or a pound of feathers")
        # -&gt; {
        #     'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Ao02pnFYXD6GN1yzc0uXPsvF', 'function': {'arguments': '{"answer":"They weigh the same.","justification":"Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ."}', 'name': 'AnswerWithJustification'}, 'type': 'function'}]}),
        #     'parsed': AnswerWithJustification(answer='They weigh the same.', justification='Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume or density of the objects may differ.'),
        #     'parsing_error': None
        # }

Example: Dict schema (include_raw=False):
    .. code-block:: python

        from pydantic import BaseModel
        from langchain_core.utils.function_calling import convert_to_openai_tool

        class AnswerWithJustification(BaseModel):
            '''An answer to the user question along with justification for the answer.'''
            answer: str
            justification: str

        dict_schema = convert_to_openai_tool(AnswerWithJustification)
        llm = ChatModel(model="model-name", temperature=0)
        structured_llm = llm.with_structured_output(dict_schema)

        structured_llm.invoke("What weighs more a pound of bricks or a pound of feathers")
        # -&gt; {
        #     'answer': 'They weigh the same',
        #     'justification': 'Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume and density of the two substances differ.'
        # }

.. versionchanged:: 0.2.26

        Added support for TypedDict class.
</pre> 
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a37740e205816c167eea0aaf33efade2f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a37740e205816c167eea0aaf33efade2f">&#9670;&nbsp;</a></span>alternative</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.chat_models.BaseChatModel.alternative</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aa5286b5305fcbcbf7c93a97bdf43ad8b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5286b5305fcbcbf7c93a97bdf43ad8b">&#9670;&nbsp;</a></span>default</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.chat_models.BaseChatModel.default</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a2ba23caed0e36512d90f1c30b3fdaa21"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2ba23caed0e36512d90f1c30b3fdaa21">&#9670;&nbsp;</a></span>disable_streaming</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.chat_models.BaseChatModel.disable_streaming</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a61d7382fe5885461f3f666459c4f9614"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a61d7382fe5885461f3f666459c4f9614">&#9670;&nbsp;</a></span>exclude</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.chat_models.BaseChatModel.exclude</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="af7f8d0efe19d1f2e7e8d639e03688fa9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af7f8d0efe19d1f2e7e8d639e03688fa9">&#9670;&nbsp;</a></span>model_config</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.chat_models.BaseChatModel.model_config</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line">=  <a class="code" href="namespacepydantic_1_1v1_1_1config.html#acfc2d247c305b959d6aa3e9d99ab3df4">ConfigDict</a>(</div>
<div class="line">        arbitrary_types_allowed=<span class="keyword">True</span>,</div>
<div class="line">    )</div>
<div class="ttc" id="anamespacepydantic_1_1v1_1_1config_html_acfc2d247c305b959d6aa3e9d99ab3df4"><div class="ttname"><a href="namespacepydantic_1_1v1_1_1config.html#acfc2d247c305b959d6aa3e9d99ab3df4">pydantic.v1.config.ConfigDict</a></div><div class="ttdeci">ConfigDict</div><div class="ttdef"><b>Definition:</b> config.py:77</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="ae86a49547d47ee5d37e5de4511d6dcc8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae86a49547d47ee5d37e5de4511d6dcc8">&#9670;&nbsp;</a></span>name</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.chat_models.BaseChatModel.name</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a8cc2bc655191b554549a0c76122b786b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8cc2bc655191b554549a0c76122b786b">&#9670;&nbsp;</a></span>None</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.chat_models.BaseChatModel.None</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a5c727a2c91c467be5ec9880198831cd7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5c727a2c91c467be5ec9880198831cd7">&#9670;&nbsp;</a></span>removal</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.chat_models.BaseChatModel.removal</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="afd62802c6d8b05f19b8377934270e445"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afd62802c6d8b05f19b8377934270e445">&#9670;&nbsp;</a></span>since</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.language_models.chat_models.BaseChatModel.since</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>py3_env/lib/python3.10/site-packages/langchain_core/language_models/<a class="el" href="chat__models_8py.html">chat_models.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
