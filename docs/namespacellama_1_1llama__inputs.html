<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: llama.llama_inputs Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacellama.html">llama</a></li><li class="navelem"><a class="el" href="namespacellama_1_1llama__inputs.html">llama_inputs</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">llama.llama_inputs Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:adbcdc043740d88ecb8dff8159d68661d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#adbcdc043740d88ecb8dff8159d68661d">get_position_ids</a> (torch.Tensor attention_mask, bool use_past_kv)</td></tr>
<tr class="separator:adbcdc043740d88ecb8dff8159d68661d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9aed5a45f330bd51975faab2bd53941"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#ad9aed5a45f330bd51975faab2bd53941">get_sample_inputs</a> (AutoConfig config, torch.device device, int batch_size, int seq_len, str engine=&quot;pt&quot;, bool return_dict=False)</td></tr>
<tr class="separator:ad9aed5a45f330bd51975faab2bd53941"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a155a5b8f985f18bda2192cf81fa258d8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#a155a5b8f985f18bda2192cf81fa258d8">get_sample_with_past_kv_inputs</a> (AutoConfig config, torch.device device, int batch_size, int past_seq_len, bool use_fp16=False, str engine=&quot;pt&quot;, bool return_dict=False, int world_size=1)</td></tr>
<tr class="separator:a155a5b8f985f18bda2192cf81fa258d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a289d425cc879ad8962e1ccd16580895d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#a289d425cc879ad8962e1ccd16580895d">get_merged_sample_with_past_kv_inputs</a> (AutoConfig config, torch.device device, int batch_size, int seq_len, int past_seq_len, int max_seq_len, bool use_fp16=False, bool use_buffer_share=False, str engine=&quot;pt&quot;, bool return_dict=False, int world_size=1)</td></tr>
<tr class="separator:a289d425cc879ad8962e1ccd16580895d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aff426eac71fba9286e2058a1456e5785"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#aff426eac71fba9286e2058a1456e5785">get_msft_sample_inputs</a> (AutoConfig config, int batch_size, int past_seq_len, int seq_len, int max_seq_len, bool use_fp16, bool use_buffer_share, bool split_kv)</td></tr>
<tr class="separator:aff426eac71fba9286e2058a1456e5785"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae71fb81b7c8e1ba46ad9ea4f5d30d2fc"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#ae71fb81b7c8e1ba46ad9ea4f5d30d2fc">get_past_kv_inputs</a> (AutoConfig config, int batch_size, int past_seq_len, bool use_fp16, int world_size=1)</td></tr>
<tr class="separator:ae71fb81b7c8e1ba46ad9ea4f5d30d2fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acd036db5a63a64246df5998c3b2a5629"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#acd036db5a63a64246df5998c3b2a5629">flatten_past_kv_inputs</a> (list[tuple[torch.Tensor, torch.Tensor]] past_key_values)</td></tr>
<tr class="separator:acd036db5a63a64246df5998c3b2a5629"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7656ac72a0e3e3cf885e4be02302c0ad"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#a7656ac72a0e3e3cf885e4be02302c0ad">convert_inputs_for_ort</a> (dict pt_inputs, bool use_buffer_share=False, int past_seq_len=0, int max_seq_len=2048)</td></tr>
<tr class="separator:a7656ac72a0e3e3cf885e4be02302c0ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37310a277e55f63ed0790689cb561573"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#a37310a277e55f63ed0790689cb561573">enable_past_present_share_buffer</a> (dict ort_inputs, int past_seq_len, int max_seq_len)</td></tr>
<tr class="separator:a37310a277e55f63ed0790689cb561573"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09a48c205aef3843cddead8adf6eba44"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#a09a48c205aef3843cddead8adf6eba44">verify_ort_inputs</a> (InferenceSession model, dict ort_inputs)</td></tr>
<tr class="separator:a09a48c205aef3843cddead8adf6eba44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe686f47369552967ba8242b2f0c56d4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#afe686f47369552967ba8242b2f0c56d4">add_io_bindings_as_ortvalues</a> (InferenceSession model, dict ort_inputs, str device, int device_id, bool use_buffer_share, dict kv_cache_ortvalues)</td></tr>
<tr class="separator:afe686f47369552967ba8242b2f0c56d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a816655d4dc867ed2c5e2abed5914f90f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#a816655d4dc867ed2c5e2abed5914f90f">add_io_bindings_as_tensors</a> (InferenceSession model, dict inputs, dict outputs, bool use_fp16, bool use_buffer_share)</td></tr>
<tr class="separator:a816655d4dc867ed2c5e2abed5914f90f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a211b951f687e6bd68882e23948c8125c"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacellama_1_1llama__inputs.html#a211b951f687e6bd68882e23948c8125c">get_initial_inputs_and_outputs</a> (AutoConfig config, AutoTokenizer tokenizer, int requested_length, list[str] prompt, torch.device device, bool use_fp16, bool use_buffer_share, str engine)</td></tr>
<tr class="separator:a211b951f687e6bd68882e23948c8125c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Function Documentation</h2>
<a id="afe686f47369552967ba8242b2f0c56d4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe686f47369552967ba8242b2f0c56d4">&#9670;&nbsp;</a></span>add_io_bindings_as_ortvalues()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.add_io_bindings_as_ortvalues </td>
          <td>(</td>
          <td class="paramtype">InferenceSession&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict&#160;</td>
          <td class="paramname"><em>ort_inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>device_id</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_buffer_share</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict&#160;</td>
          <td class="paramname"><em>kv_cache_ortvalues</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a816655d4dc867ed2c5e2abed5914f90f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a816655d4dc867ed2c5e2abed5914f90f">&#9670;&nbsp;</a></span>add_io_bindings_as_tensors()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.add_io_bindings_as_tensors </td>
          <td>(</td>
          <td class="paramtype">InferenceSession&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict&#160;</td>
          <td class="paramname"><em>outputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_fp16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool
&#160;</td>
          <td class="paramname"><em>use_buffer_share</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a7656ac72a0e3e3cf885e4be02302c0ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7656ac72a0e3e3cf885e4be02302c0ad">&#9670;&nbsp;</a></span>convert_inputs_for_ort()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.convert_inputs_for_ort </td>
          <td>(</td>
          <td class="paramtype">dict&#160;</td>
          <td class="paramname"><em>pt_inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_buffer_share</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>past_seq_len</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>max_seq_len</em> = <code>2048</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a37310a277e55f63ed0790689cb561573"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a37310a277e55f63ed0790689cb561573">&#9670;&nbsp;</a></span>enable_past_present_share_buffer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.enable_past_present_share_buffer </td>
          <td>(</td>
          <td class="paramtype">dict&#160;</td>
          <td class="paramname"><em>ort_inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>past_seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>max_seq_len</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="acd036db5a63a64246df5998c3b2a5629"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acd036db5a63a64246df5998c3b2a5629">&#9670;&nbsp;</a></span>flatten_past_kv_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.flatten_past_kv_inputs </td>
          <td>(</td>
          <td class="paramtype">list[tuple[torch.Tensor, torch.Tensor]]&#160;</td>
          <td class="paramname"><em>past_key_values</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a211b951f687e6bd68882e23948c8125c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a211b951f687e6bd68882e23948c8125c">&#9670;&nbsp;</a></span>get_initial_inputs_and_outputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.get_initial_inputs_and_outputs </td>
          <td>(</td>
          <td class="paramtype">AutoConfig&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">AutoTokenizer&#160;</td>
          <td class="paramname"><em>tokenizer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>requested_length</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">list[str]&#160;</td>
          <td class="paramname"><em>prompt</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_fp16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_buffer_share</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>engine</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a289d425cc879ad8962e1ccd16580895d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a289d425cc879ad8962e1ccd16580895d">&#9670;&nbsp;</a></span>get_merged_sample_with_past_kv_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.get_merged_sample_with_past_kv_inputs </td>
          <td>(</td>
          <td class="paramtype">AutoConfig&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>past_seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>max_seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_fp16</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_buffer_share</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>engine</em> = <code>&quot;pt&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>return_dict</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>world_size</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="aff426eac71fba9286e2058a1456e5785"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aff426eac71fba9286e2058a1456e5785">&#9670;&nbsp;</a></span>get_msft_sample_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.get_msft_sample_inputs </td>
          <td>(</td>
          <td class="paramtype">AutoConfig&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>past_seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>max_seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_fp16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_buffer_share</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>split_kv</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae71fb81b7c8e1ba46ad9ea4f5d30d2fc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae71fb81b7c8e1ba46ad9ea4f5d30d2fc">&#9670;&nbsp;</a></span>get_past_kv_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.get_past_kv_inputs </td>
          <td>(</td>
          <td class="paramtype">AutoConfig&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>past_seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_fp16</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>world_size</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="adbcdc043740d88ecb8dff8159d68661d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adbcdc043740d88ecb8dff8159d68661d">&#9670;&nbsp;</a></span>get_position_ids()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.get_position_ids </td>
          <td>(</td>
          <td class="paramtype">torch.Tensor&#160;</td>
          <td class="paramname"><em>attention_mask</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>use_past_kv</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ad9aed5a45f330bd51975faab2bd53941"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad9aed5a45f330bd51975faab2bd53941">&#9670;&nbsp;</a></span>get_sample_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.get_sample_inputs </td>
          <td>(</td>
          <td class="paramtype">AutoConfig&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>engine</em> = <code>&quot;pt&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>return_dict</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a155a5b8f985f18bda2192cf81fa258d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a155a5b8f985f18bda2192cf81fa258d8">&#9670;&nbsp;</a></span>get_sample_with_past_kv_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.get_sample_with_past_kv_inputs </td>
          <td>(</td>
          <td class="paramtype">AutoConfig&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">torch.device&#160;</td>
          <td class="paramname"><em>device</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>past_seq_len</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>use_fp16</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>engine</em> = <code>&quot;pt&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>return_dict</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>world_size</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a09a48c205aef3843cddead8adf6eba44"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a09a48c205aef3843cddead8adf6eba44">&#9670;&nbsp;</a></span>verify_ort_inputs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def llama.llama_inputs.verify_ort_inputs </td>
          <td>(</td>
          <td class="paramtype">InferenceSession&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">dict&#160;</td>
          <td class="paramname"><em>ort_inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
