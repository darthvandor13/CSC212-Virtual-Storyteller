<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: langsmith.evaluation._arunner Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacelangsmith.html">langsmith</a></li><li class="navelem"><a class="el" href="namespacelangsmith_1_1evaluation.html">evaluation</a></li><li class="navelem"><a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html">_arunner</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">langsmith.evaluation._arunner Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangsmith_1_1evaluation_1_1__arunner_1_1__AsyncExperimentManager.html">_AsyncExperimentManager</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangsmith_1_1evaluation_1_1__arunner_1_1AsyncExperimentResults.html">AsyncExperimentResults</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:aecde26418c2b433d51126d5df15fb791"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangsmith_1_1evaluation_1_1__arunner_1_1AsyncExperimentResults.html">AsyncExperimentResults</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#aecde26418c2b433d51126d5df15fb791">aevaluate</a> (Union[<a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#a1c4de224e210c46bf6fd60ce3af49258">ATARGET_T</a>, AsyncIterable[dict], <a class="el" href="classlangchain__core_1_1runnables_1_1base_1_1Runnable.html">Runnable</a>, str, uuid.UUID, <a class="el" href="classlangsmith_1_1schemas_1_1TracerSession.html">schemas.TracerSession</a>] target, Union[DATA_T, AsyncIterable[<a class="el" href="classlangsmith_1_1schemas_1_1Example.html">schemas.Example</a>], Iterable[<a class="el" href="classlangsmith_1_1schemas_1_1Example.html">schemas.Example</a>], None] data=None, Optional[Sequence[Union[EVALUATOR_T, AEVALUATOR_T]]] evaluators=None, Optional[Sequence[SUMMARY_EVALUATOR_T]] summary_evaluators=None, Optional[dict] metadata=None, Optional[str] experiment_prefix=None, Optional[str] description=None, Optional[int] max_concurrency=0, int num_repetitions=1, Optional[<a class="el" href="classlangsmith_1_1client_1_1Client.html">langsmith.Client</a>] client=None, bool blocking=True, Optional[Union[<a class="el" href="classlangsmith_1_1schemas_1_1TracerSession.html">schemas.TracerSession</a>, str, uuid.UUID]] experiment=None, bool upload_results=True, **Any kwargs)</td></tr>
<tr class="separator:aecde26418c2b433d51126d5df15fb791"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c2fe4ff8475c44c9081deb3971d631e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangsmith_1_1evaluation_1_1__arunner_1_1AsyncExperimentResults.html">AsyncExperimentResults</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#a8c2fe4ff8475c44c9081deb3971d631e">aevaluate_existing</a> (Union[str, uuid.UUID, <a class="el" href="classlangsmith_1_1schemas_1_1TracerSession.html">schemas.TracerSession</a>] experiment, Optional[Sequence[Union[EVALUATOR_T, AEVALUATOR_T]]] evaluators=None, Optional[Sequence[SUMMARY_EVALUATOR_T]] summary_evaluators=None, Optional[dict] metadata=None, Optional[int] max_concurrency=0, Optional[<a class="el" href="classlangsmith_1_1client_1_1Client.html">langsmith.Client</a>] client=None, bool load_nested=False, bool blocking=True)</td></tr>
<tr class="separator:a8c2fe4ff8475c44c9081deb3971d631e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83a27305f5e5207d619046157ab35c44"><td class="memItemLeft" align="right" valign="top">AsyncIterator[<a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#ae9342e2c8354690d7cb17bcf84be20f6">T</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#a83a27305f5e5207d619046157ab35c44">async_chain_from_iterable</a> (Iterable[AsyncIterable[<a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#ae9342e2c8354690d7cb17bcf84be20f6">T</a>]] iterable)</td></tr>
<tr class="separator:a83a27305f5e5207d619046157ab35c44"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98e6fb13a9b559485df3d852715edd48"><td class="memItemLeft" align="right" valign="top">AsyncIterable[<a class="el" href="classlangsmith_1_1schemas_1_1Example.html">schemas.Example</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#a98e6fb13a9b559485df3d852715edd48">async_iter_from_list</a> (List[<a class="el" href="classlangsmith_1_1schemas_1_1Example.html">schemas.Example</a>] examples)</td></tr>
<tr class="separator:a98e6fb13a9b559485df3d852715edd48"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a4bd9792af5441a04081de67330f4578e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#a4bd9792af5441a04081de67330f4578e">DataFrame</a> = pd.DataFrame</td></tr>
<tr class="separator:a4bd9792af5441a04081de67330f4578e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46ae841cc400faf1e7bf47b5661abb15"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#a46ae841cc400faf1e7bf47b5661abb15">logger</a> = logging.getLogger(__name__)</td></tr>
<tr class="separator:a46ae841cc400faf1e7bf47b5661abb15"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c4de224e210c46bf6fd60ce3af49258"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#a1c4de224e210c46bf6fd60ce3af49258">ATARGET_T</a></td></tr>
<tr class="separator:a1c4de224e210c46bf6fd60ce3af49258"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9342e2c8354690d7cb17bcf84be20f6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#ae9342e2c8354690d7cb17bcf84be20f6">T</a> = TypeVar(&quot;T&quot;)</td></tr>
<tr class="separator:ae9342e2c8354690d7cb17bcf84be20f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">V2 Evaluation Interface.</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="aecde26418c2b433d51126d5df15fb791"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aecde26418c2b433d51126d5df15fb791">&#9670;&nbsp;</a></span>aevaluate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> <a class="el" href="classlangsmith_1_1evaluation_1_1__arunner_1_1AsyncExperimentResults.html">AsyncExperimentResults</a> langsmith.evaluation._arunner.aevaluate </td>
          <td>(</td>
          <td class="paramtype">Union[
        <a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#a1c4de224e210c46bf6fd60ce3af49258">ATARGET_T</a>, AsyncIterable[dict], <a class="el" href="classlangchain__core_1_1runnables_1_1base_1_1Runnable.html">Runnable</a>, str, uuid.UUID, <a class="el" href="classlangsmith_1_1schemas_1_1TracerSession.html">schemas.TracerSession</a>
    ]&#160;</td>
          <td class="paramname"><em>target</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[
        DATA_T, AsyncIterable[<a class="el" href="classlangsmith_1_1schemas_1_1Example.html">schemas.Example</a>], Iterable[<a class="el" href="classlangsmith_1_1schemas_1_1Example.html">schemas.Example</a>], None
    ] &#160;</td>
          <td class="paramname"><em>data</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence[Union[EVALUATOR_T, AEVALUATOR_T]]] &#160;</td>
          <td class="paramname"><em>evaluators</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence[SUMMARY_EVALUATOR_T]] &#160;</td>
          <td class="paramname"><em>summary_evaluators</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[dict] &#160;</td>
          <td class="paramname"><em>metadata</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>experiment_prefix</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[str] &#160;</td>
          <td class="paramname"><em>description</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[int] &#160;</td>
          <td class="paramname"><em>max_concurrency</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>num_repetitions</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[<a class="el" href="classlangsmith_1_1client_1_1Client.html">langsmith.Client</a>] &#160;</td>
          <td class="paramname"><em>client</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>blocking</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Union[<a class="el" href="classlangsmith_1_1schemas_1_1TracerSession.html">schemas.TracerSession</a>, str, uuid.UUID]] &#160;</td>
          <td class="paramname"><em>experiment</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>upload_results</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Evaluate an async target system on a given dataset.

Args:
    target (AsyncCallable[[dict], dict] | AsyncIterable[dict] | Runnable | EXPERIMENT_T | Tuple[EXPERIMENT_T, EXPERIMENT_T]):
        The target system or experiment(s) to evaluate. Can be an async function
        that takes a dict and returns a dict, a langchain Runnable, an
        existing experiment ID, or a two-tuple of experiment IDs.
    data (Union[DATA_T, AsyncIterable[schemas.Example]]): The dataset to evaluate on. Can be a dataset name, a list of
        examples, an async generator of examples, or an async iterable of examples.
    evaluators (Optional[Sequence[EVALUATOR_T]]): A list of evaluators to run
        on each example. Defaults to None.
    summary_evaluators (Optional[Sequence[SUMMARY_EVALUATOR_T]]): A list of summary
        evaluators to run on the entire dataset. Defaults to None.
    metadata (Optional[dict]): Metadata to attach to the experiment.
        Defaults to None.
    experiment_prefix (Optional[str]): A prefix to provide for your experiment name.
        Defaults to None.
    description (Optional[str]): A description of the experiment.
    max_concurrency (int | None): The maximum number of concurrent
        evaluations to run. If None then no limit is set. If 0 then no concurrency.
        Defaults to 0.
    num_repetitions (int): The number of times to run the evaluation.
        Each item in the dataset will be run and evaluated this many times.
        Defaults to 1.
    client (Optional[langsmith.Client]): The LangSmith client to use.
        Defaults to None.
    blocking (bool): Whether to block until the evaluation is complete.
        Defaults to True.
    experiment (Optional[schemas.TracerSession]): An existing experiment to
        extend. If provided, experiment_prefix is ignored. For advanced
        usage only.
    load_nested: Whether to load all child runs for the experiment.
        Default is to only load the top-level root runs. Should only be specified
        when evaluating an existing experiment.

Returns:
    AsyncIterator[ExperimentResultRow]: An async iterator over the experiment results.

Environment:
    - LANGSMITH_TEST_CACHE: If set, API calls will be cached to disk to save time and
        cost during testing. Recommended to commit the cache files to your repository
        for faster CI/CD runs.
        Requires the 'langsmith[vcr]' package to be installed.

Examples:
    &gt;&gt;&gt; from typing import Sequence
    &gt;&gt;&gt; from langsmith import Client, aevaluate
    &gt;&gt;&gt; from langsmith.schemas import Example, Run
    &gt;&gt;&gt; client = Client()
    &gt;&gt;&gt; dataset = client.clone_public_dataset(
    ...     "https://smith.langchain.com/public/419dcab2-1d66-4b94-8901-0357ead390df/d"
    ... )
    &gt;&gt;&gt; dataset_name = "Evaluate Examples"

    Basic usage:

    &gt;&gt;&gt; def accuracy(run: Run, example: Example):
    ...     # Row-level evaluator for accuracy.
    ...     pred = run.outputs["output"]
    ...     expected = example.outputs["answer"]
    ...     return {"score": expected.lower() == pred.lower()}

    &gt;&gt;&gt; def precision(runs: Sequence[Run], examples: Sequence[Example]):
    ...     # Experiment-level evaluator for precision.
    ...     # TP / (TP + FP)
    ...     predictions = [run.outputs["output"].lower() for run in runs]
    ...     expected = [example.outputs["answer"].lower() for example in examples]
    ...     # yes and no are the only possible answers
    ...     tp = sum([p == e for p, e in zip(predictions, expected) if p == "yes"])
    ...     fp = sum([p == "yes" and e == "no" for p, e in zip(predictions, expected)])
    ...     return {"score": tp / (tp + fp)}

    &gt;&gt;&gt; import asyncio
    &gt;&gt;&gt; async def apredict(inputs: dict) -&gt; dict:
    ...     # This can be any async function or just an API call to your app.
    ...     await asyncio.sleep(0.1)
    ...     return {"output": "Yes"}
    &gt;&gt;&gt; results = asyncio.run(
    ...     aevaluate(
    ...         apredict,
    ...         data=dataset_name,
    ...         evaluators=[accuracy],
    ...         summary_evaluators=[precision],
    ...         experiment_prefix="My Experiment",
    ...         description="Evaluate the accuracy of the model asynchronously.",
    ...         metadata={
    ...             "my-prompt-version": "abcd-1234",
    ...         },
    ...     )
    ... )  # doctest: +ELLIPSIS
    View the evaluation results for experiment:...

    Evaluating over only a subset of the examples using an async generator:

    &gt;&gt;&gt; async def example_generator():
    ...     examples = client.list_examples(dataset_name=dataset_name, limit=5)
    ...     for example in examples:
    ...         yield example
    &gt;&gt;&gt; results = asyncio.run(
    ...     aevaluate(
    ...         apredict,
    ...         data=example_generator(),
    ...         evaluators=[accuracy],
    ...         summary_evaluators=[precision],
    ...         experiment_prefix="My Subset Experiment",
    ...         description="Evaluate a subset of examples asynchronously.",
    ...     )
    ... )  # doctest: +ELLIPSIS
    View the evaluation results for experiment:...

    Streaming each prediction to more easily + eagerly debug.

    &gt;&gt;&gt; results = asyncio.run(
    ...     aevaluate(
    ...         apredict,
    ...         data=dataset_name,
    ...         evaluators=[accuracy],
    ...         summary_evaluators=[precision],
    ...         experiment_prefix="My Streaming Experiment",
    ...         description="Streaming predictions for debugging.",
    ...         blocking=False,
    ...     )
    ... )  # doctest: +ELLIPSIS
    View the evaluation results for experiment:...

    &gt;&gt;&gt; async def aenumerate(iterable):
    ...     async for elem in iterable:
    ...         print(elem)
    &gt;&gt;&gt; asyncio.run(aenumerate(results))

    Running without concurrency:

    &gt;&gt;&gt; results = asyncio.run(
    ...     aevaluate(
    ...         apredict,
    ...         data=dataset_name,
    ...         evaluators=[accuracy],
    ...         summary_evaluators=[precision],
    ...         experiment_prefix="My Experiment Without Concurrency",
    ...         description="This was run without concurrency.",
    ...         max_concurrency=0,
    ...     )
    ... )  # doctest: +ELLIPSIS
    View the evaluation results for experiment:...

    Using Async evaluators:

    &gt;&gt;&gt; async def helpfulness(run: Run, example: Example):
    ...     # Row-level evaluator for helpfulness.
    ...     await asyncio.sleep(5)  # Replace with your LLM API call
    ...     return {"score": run.outputs["output"] == "Yes"}

    &gt;&gt;&gt; results = asyncio.run(
    ...     aevaluate(
    ...         apredict,
    ...         data=dataset_name,
    ...         evaluators=[helpfulness],
    ...         summary_evaluators=[precision],
    ...         experiment_prefix="My Helpful Experiment",
    ...         description="Applying async evaluators example.",
    ...     )
    ... )  # doctest: +ELLIPSIS
    View the evaluation results for experiment:...


.. versionchanged:: 0.2.0

    'max_concurrency' default updated from None (no limit on concurrency)
    to 0 (no concurrency at all).
</pre> 
</div>
</div>
<a id="a8c2fe4ff8475c44c9081deb3971d631e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8c2fe4ff8475c44c9081deb3971d631e">&#9670;&nbsp;</a></span>aevaluate_existing()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> <a class="el" href="classlangsmith_1_1evaluation_1_1__arunner_1_1AsyncExperimentResults.html">AsyncExperimentResults</a> langsmith.evaluation._arunner.aevaluate_existing </td>
          <td>(</td>
          <td class="paramtype">Union[str, uuid.UUID, <a class="el" href="classlangsmith_1_1schemas_1_1TracerSession.html">schemas.TracerSession</a>]&#160;</td>
          <td class="paramname"><em>experiment</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence[Union[EVALUATOR_T, AEVALUATOR_T]]] &#160;</td>
          <td class="paramname"><em>evaluators</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence[SUMMARY_EVALUATOR_T]] &#160;</td>
          <td class="paramname"><em>summary_evaluators</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[dict] &#160;</td>
          <td class="paramname"><em>metadata</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[int] &#160;</td>
          <td class="paramname"><em>max_concurrency</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[<a class="el" href="classlangsmith_1_1client_1_1Client.html">langsmith.Client</a>] &#160;</td>
          <td class="paramname"><em>client</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>load_nested</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>blocking</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Evaluate existing experiment runs asynchronously.

Args:
    experiment (Union[str, uuid.UUID]): The identifier of the experiment to evaluate.
    evaluators (Optional[Sequence[EVALUATOR_T]]): Optional sequence of evaluators to use for individual run evaluation.
    summary_evaluators (Optional[Sequence[SUMMARY_EVALUATOR_T]]): Optional sequence of evaluators
        to apply over the entire dataset.
    metadata (Optional[dict]): Optional metadata to include in the evaluation results.
    max_concurrency (int | None): The maximum number of concurrent
        evaluations to run. If None then no limit is set. If 0 then no concurrency.
        Defaults to 0.
    client (Optional[langsmith.Client]): Optional Langsmith client to use for evaluation.
    load_nested: Whether to load all child runs for the experiment.
        Default is to only load the top-level root runs.
    blocking (bool): Whether to block until evaluation is complete.

Returns:
    AsyncIterator[ExperimentResultRow]: An async iterator over the experiment results.

Examples:
    Define your evaluators

    &gt;&gt;&gt; from typing import Sequence
    &gt;&gt;&gt; from langsmith.schemas import Example, Run
    &gt;&gt;&gt; def accuracy(run: Run, example: Example):
    ...     # Row-level evaluator for accuracy.
    ...     pred = run.outputs["output"]
    ...     expected = example.outputs["answer"]
    ...     return {"score": expected.lower() == pred.lower()}
    &gt;&gt;&gt; def precision(runs: Sequence[Run], examples: Sequence[Example]):
    ...     # Experiment-level evaluator for precision.
    ...     # TP / (TP + FP)
    ...     predictions = [run.outputs["output"].lower() for run in runs]
    ...     expected = [example.outputs["answer"].lower() for example in examples]
    ...     # yes and no are the only possible answers
    ...     tp = sum([p == e for p, e in zip(predictions, expected) if p == "yes"])
    ...     fp = sum([p == "yes" and e == "no" for p, e in zip(predictions, expected)])
    ...     return {"score": tp / (tp + fp)}

    Load the experiment and run the evaluation.

    &gt;&gt;&gt; from langsmith import aevaluate, aevaluate_existing
    &gt;&gt;&gt; dataset_name = "Evaluate Examples"
    &gt;&gt;&gt; async def apredict(inputs: dict) -&gt; dict:
    ...     # This can be any async function or just an API call to your app.
    ...     await asyncio.sleep(0.1)
    ...     return {"output": "Yes"}
    &gt;&gt;&gt; # First run inference on the dataset
    ... results = asyncio.run(
    ...     aevaluate(
    ...         apredict,
    ...         data=dataset_name,
    ...     )
    ... )  # doctest: +ELLIPSIS
    View the evaluation results for experiment:...

    Then evaluate the results
    &gt;&gt;&gt; experiment_name = "My Experiment:64e6e91"  # Or manually specify
    &gt;&gt;&gt; results = asyncio.run(
    ...     aevaluate_existing(
    ...         experiment_name,
    ...         evaluators=[accuracy],
    ...         summary_evaluators=[precision],
    ...     )
    ... )  # doctest: +ELLIPSIS
    View the evaluation results for experiment:...</pre> 
</div>
</div>
<a id="a83a27305f5e5207d619046157ab35c44"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83a27305f5e5207d619046157ab35c44">&#9670;&nbsp;</a></span>async_chain_from_iterable()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> AsyncIterator[<a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#ae9342e2c8354690d7cb17bcf84be20f6">T</a>] langsmith.evaluation._arunner.async_chain_from_iterable </td>
          <td>(</td>
          <td class="paramtype">Iterable[AsyncIterable[<a class="el" href="namespacelangsmith_1_1evaluation_1_1__arunner.html#ae9342e2c8354690d7cb17bcf84be20f6">T</a>]]&#160;</td>
          <td class="paramname"><em>iterable</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Chain multiple async iterables.</pre> 
</div>
</div>
<a id="a98e6fb13a9b559485df3d852715edd48"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a98e6fb13a9b559485df3d852715edd48">&#9670;&nbsp;</a></span>async_iter_from_list()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> AsyncIterable[<a class="el" href="classlangsmith_1_1schemas_1_1Example.html">schemas.Example</a>] langsmith.evaluation._arunner.async_iter_from_list </td>
          <td>(</td>
          <td class="paramtype">List[<a class="el" href="classlangsmith_1_1schemas_1_1Example.html">schemas.Example</a>]&#160;</td>
          <td class="paramname"><em>examples</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert a list of examples to an async iterable.</pre> 
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a1c4de224e210c46bf6fd60ce3af49258"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c4de224e210c46bf6fd60ce3af49258">&#9670;&nbsp;</a></span>ATARGET_T</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">langsmith.evaluation._arunner.ATARGET_T</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;=  Union[</div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;    Callable[[dict], Awaitable[dict]], Callable[[dict, dict], Awaitable[dict]]</div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;]</div>
</div><!-- fragment -->
</div>
</div>
<a id="a4bd9792af5441a04081de67330f4578e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4bd9792af5441a04081de67330f4578e">&#9670;&nbsp;</a></span>DataFrame</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">langsmith.evaluation._arunner.DataFrame = pd.DataFrame</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a46ae841cc400faf1e7bf47b5661abb15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46ae841cc400faf1e7bf47b5661abb15">&#9670;&nbsp;</a></span>logger</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">langsmith.evaluation._arunner.logger = logging.getLogger(__name__)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ae9342e2c8354690d7cb17bcf84be20f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9342e2c8354690d7cb17bcf84be20f6">&#9670;&nbsp;</a></span>T</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">langsmith.evaluation._arunner.T = TypeVar(&quot;T&quot;)</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
