<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: langchain_core.messages.utils Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacelangchain__core.html">langchain_core</a></li><li class="navelem"><a class="el" href="namespacelangchain__core_1_1messages.html">messages</a></li><li class="navelem"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html">utils</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">langchain_core.messages.utils Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a604fb5c475a5715cdd5bc0cada03a36d"><td class="memItemLeft" align="right" valign="top">str&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#a604fb5c475a5715cdd5bc0cada03a36d">get_buffer_string</a> (Sequence[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>] messages, str human_prefix=&quot;Human&quot;, str ai_prefix=&quot;AI&quot;)</td></tr>
<tr class="separator:a604fb5c475a5715cdd5bc0cada03a36d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61ba3a43a96aa673f427c2507f61755b"><td class="memItemLeft" align="right" valign="top">list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#a61ba3a43a96aa673f427c2507f61755b">messages_from_dict</a> (Sequence[dict] messages)</td></tr>
<tr class="separator:a61ba3a43a96aa673f427c2507f61755b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a36ffc07313a22192c9dc09334aa182e5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#a36ffc07313a22192c9dc09334aa182e5">message_chunk_to_message</a> (<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessageChunk.html">BaseMessageChunk</a> chunk)</td></tr>
<tr class="separator:a36ffc07313a22192c9dc09334aa182e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2a3ea98046879e66b53888dbf31de10b"><td class="memItemLeft" align="right" valign="top">list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#a2a3ea98046879e66b53888dbf31de10b">convert_to_messages</a> (Union[Iterable[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>], <a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] messages)</td></tr>
<tr class="separator:a2a3ea98046879e66b53888dbf31de10b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9095adb0c6ee23d27d37cddd78f7a19d"><td class="memItemLeft" align="right" valign="top">list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#a9095adb0c6ee23d27d37cddd78f7a19d">filter_messages</a> (Union[Iterable[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>], <a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] messages, *Optional[Sequence[str]] include_names=None, Optional[Sequence[str]] exclude_names=None, Optional[Sequence[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]]]] include_types=None, Optional[Sequence[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]]]] exclude_types=None, Optional[Sequence[str]] include_ids=None, Optional[Sequence[str]] exclude_ids=None)</td></tr>
<tr class="separator:a9095adb0c6ee23d27d37cddd78f7a19d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad75d200624073fc1f90b81d7acbacd2e"><td class="memItemLeft" align="right" valign="top">list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#ad75d200624073fc1f90b81d7acbacd2e">merge_message_runs</a> (Union[Iterable[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>], <a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] messages, *str chunk_separator=&quot;\n&quot;)</td></tr>
<tr class="separator:ad75d200624073fc1f90b81d7acbacd2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9094bad6c6f69895ab5e246c540bd8cf"><td class="memItemLeft" align="right" valign="top">list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#a9094bad6c6f69895ab5e246c540bd8cf">trim_messages</a> (Union[Iterable[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>], <a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>] messages, *int max_tokens, Union[Callable[[list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]], int], Callable[[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>], int], <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html">BaseLanguageModel</a>,] token_counter, Literal[&quot;first&quot;, &quot;last&quot;] strategy=&quot;last&quot;, bool allow_partial=False, Optional[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>], Sequence[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]]]]] end_on=None, Optional[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>], Sequence[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]]]]] start_on=None, bool include_system=False, Optional[Union[Callable[[str], list[str]], TextSplitter]] text_splitter=None)</td></tr>
<tr class="separator:a9094bad6c6f69895ab5e246c540bd8cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25f9d59a9744e928b4dcd8644c07586f"><td class="memItemLeft" align="right" valign="top">Union[dict, list[dict]]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#a25f9d59a9744e928b4dcd8644c07586f">convert_to_openai_messages</a> (Union[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>, Sequence[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>]] messages, *Literal[&quot;string&quot;, &quot;block&quot;] text_format=&quot;string&quot;)</td></tr>
<tr class="separator:a25f9d59a9744e928b4dcd8644c07586f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a15d15a793ab96ab36106994edb91e47c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#a15d15a793ab96ab36106994edb91e47c">AnyMessage</a></td></tr>
<tr class="separator:a15d15a793ab96ab36106994edb91e47c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf0194234e4ca54755e2fe2a3d90170f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a></td></tr>
<tr class="separator:abf0194234e4ca54755e2fe2a3d90170f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Module contains utility functions for working with messages.

Some examples of what you can do with these functions include:

* Convert messages to strings (serialization)
* Convert messages from dicts to Message objects (deserialization)
* Filter messages from a list of messages based on name, type or id etc.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a2a3ea98046879e66b53888dbf31de10b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2a3ea98046879e66b53888dbf31de10b">&#9670;&nbsp;</a></span>convert_to_messages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>] langchain_core.messages.utils.convert_to_messages </td>
          <td>(</td>
          <td class="paramtype">Union[Iterable[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>], <a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>]&#160;</td>
          <td class="paramname"><em>messages</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert a sequence of messages to a list of messages.

Args:
    messages: Sequence of messages to convert.

Returns:
    list of messages (BaseMessages).
</pre> 
</div>
</div>
<a id="a25f9d59a9744e928b4dcd8644c07586f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a25f9d59a9744e928b4dcd8644c07586f">&#9670;&nbsp;</a></span>convert_to_openai_messages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Union[dict, list[dict]] langchain_core.messages.utils.convert_to_openai_messages </td>
          <td>(</td>
          <td class="paramtype">Union[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>, Sequence[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>]]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Literal[&quot;string&quot;, &quot;block&quot;] &#160;</td>
          <td class="paramname"><em>text_format</em> = <code>&quot;string&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert LangChain messages into OpenAI message dicts.

Args:
    messages: Message-like object or iterable of objects whose contents are
        in OpenAI, Anthropic, Bedrock Converse, or VertexAI formats.
    text_format: How to format string or text block contents:

            - "string":
                If a message has a string content, this is left as a string. If
                a message has content blocks that are all of type 'text', these are
                joined with a newline to make a single string. If a message has
                content blocks and at least one isn't of type 'text', then
                all blocks are left as dicts.
            - "block":
                If a message has a string content, this is turned into a list
                with a single content block of type 'text'. If a message has content
                blocks these are left as is.

Returns:
    The return type depends on the input type:
        - dict:
            If a single message-like object is passed in, a single OpenAI message
            dict is returned.
        - list[dict]:
            If a sequence of message-like objects are passed in, a list of OpenAI
            message dicts is returned.

Example:

    .. code-block:: python

        from langchain_core.messages import (
            convert_to_openai_messages,
            AIMessage,
            SystemMessage,
            ToolMessage,
        )

        messages = [
            SystemMessage([{"type": "text", "text": "foo"}]),
            {"role": "user", "content": [{"type": "text", "text": "whats in this"}, {"type": "image_url", "image_url": {"url": "data:image/png;base64,'/9j/4AAQSk'"}}]},
            AIMessage("", tool_calls=[{"name": "analyze", "args": {"baz": "buz"}, "id": "1", "type": "tool_call"}]),
            ToolMessage("foobar", tool_call_id="1", name="bar"),
            {"role": "assistant", "content": "thats nice"},
        ]
        oai_messages = convert_to_openai_messages(messages)
        # -&gt; [
        #   {'role': 'system', 'content': 'foo'},
        #   {'role': 'user', 'content': [{'type': 'text', 'text': 'whats in this'}, {'type': 'image_url', 'image_url': {'url': "data:image/png;base64,'/9j/4AAQSk'"}}]},
        #   {'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': '1','function': {'name': 'analyze', 'arguments': '{"baz": "buz"}'}}], 'content': ''},
        #   {'role': 'tool', 'name': 'bar', 'content': 'foobar'},
        #   {'role': 'assistant', 'content': 'thats nice'}
        # ]

.. versionadded:: 0.3.11</pre> 
</div>
</div>
<a id="a9095adb0c6ee23d27d37cddd78f7a19d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9095adb0c6ee23d27d37cddd78f7a19d">&#9670;&nbsp;</a></span>filter_messages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>] langchain_core.messages.utils.filter_messages </td>
          <td>(</td>
          <td class="paramtype">Union[Iterable[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>], <a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>include_names</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>exclude_names</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]]]] &#160;</td>
          <td class="paramname"><em>include_types</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]]]] &#160;</td>
          <td class="paramname"><em>exclude_types</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>include_ids</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Sequence[str]] &#160;</td>
          <td class="paramname"><em>exclude_ids</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Filter messages based on name, type or id.

Args:
    messages: Sequence Message-like objects to filter.
    include_names: Message names to include. Default is None.
    exclude_names: Messages names to exclude. Default is None.
    include_types: Message types to include. Can be specified as string names (e.g.
        "system", "human", "ai", ...) or as BaseMessage classes (e.g.
        SystemMessage, HumanMessage, AIMessage, ...). Default is None.
    exclude_types: Message types to exclude. Can be specified as string names (e.g.
        "system", "human", "ai", ...) or as BaseMessage classes (e.g.
        SystemMessage, HumanMessage, AIMessage, ...). Default is None.
    include_ids: Message IDs to include. Default is None.
    exclude_ids: Message IDs to exclude. Default is None.

Returns:
    A list of Messages that meets at least one of the incl_* conditions and none
    of the excl_* conditions. If not incl_* conditions are specified then
    anything that is not explicitly excluded will be included.

Raises:
    ValueError if two incompatible arguments are provided.

Example:
    .. code-block:: python

        from langchain_core.messages import filter_messages, AIMessage, HumanMessage, SystemMessage

        messages = [
            SystemMessage("you're a good assistant."),
            HumanMessage("what's your name", id="foo", name="example_user"),
            AIMessage("steve-o", id="bar", name="example_assistant"),
            HumanMessage("what's your favorite color", id="baz",),
            AIMessage("silicon blue", id="blah",),
        ]

        filter_messages(
            messages,
            incl_names=("example_user", "example_assistant"),
            incl_types=("system",),
            excl_ids=("bar",),
        )

    .. code-block:: python

        [
            SystemMessage("you're a good assistant."),
            HumanMessage("what's your name", id="foo", name="example_user"),
        ]
</pre> 
</div>
</div>
<a id="a604fb5c475a5715cdd5bc0cada03a36d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a604fb5c475a5715cdd5bc0cada03a36d">&#9670;&nbsp;</a></span>get_buffer_string()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> str langchain_core.messages.utils.get_buffer_string </td>
          <td>(</td>
          <td class="paramtype">Sequence[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>human_prefix</em> = <code>&quot;Human&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>ai_prefix</em> = <code>&quot;AI&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert a sequence of Messages to strings and concatenate them into one string.

Args:
    messages: Messages to be converted to strings.
    human_prefix: The prefix to prepend to contents of HumanMessages.
        Default is "Human".
    ai_prefix: THe prefix to prepend to contents of AIMessages. Default is "AI".

Returns:
    A single string concatenation of all input messages.

Raises:
    ValueError: If an unsupported message type is encountered.

Example:
    .. code-block:: python

        from langchain_core import AIMessage, HumanMessage

        messages = [
            HumanMessage(content="Hi, how are you?"),
            AIMessage(content="Good, how are you?"),
        ]
        get_buffer_string(messages)
        # -&gt; "Human: Hi, how are you?\nAI: Good, how are you?"
</pre> 
</div>
</div>
<a id="ad75d200624073fc1f90b81d7acbacd2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad75d200624073fc1f90b81d7acbacd2e">&#9670;&nbsp;</a></span>merge_message_runs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>] langchain_core.messages.utils.merge_message_runs </td>
          <td>(</td>
          <td class="paramtype">Union[Iterable[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>], <a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*str &#160;</td>
          <td class="paramname"><em>chunk_separator</em> = <code>&quot;\n&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Merge consecutive Messages of the same type.

**NOTE**: ToolMessages are not merged, as each has a distinct tool call id that
can't be merged.

Args:
    messages: Sequence Message-like objects to merge.
    chunk_separator: Specify the string to be inserted between message chunks.
    Default is "\n".

Returns:
    list of BaseMessages with consecutive runs of message types merged into single
    messages. By default, if two messages being merged both have string contents,
    the merged content is a concatenation of the two strings with a new-line separator.
    The separator inserted between message chunks can be controlled by specifying
    any string with ``chunk_separator``. If at least one of the messages has a list of
    content blocks, the merged content is a list of content blocks.

Example:
    .. code-block:: python

        from langchain_core.messages import (
            merge_message_runs,
            AIMessage,
            HumanMessage,
            SystemMessage,
            ToolCall,
        )

        messages = [
            SystemMessage("you're a good assistant."),
            HumanMessage("what's your favorite color", id="foo",),
            HumanMessage("wait your favorite food", id="bar",),
            AIMessage(
                "my favorite colo",
                tool_calls=[ToolCall(name="blah_tool", args={"x": 2}, id="123", type="tool_call")],
                id="baz",
            ),
            AIMessage(
                [{"type": "text", "text": "my favorite dish is lasagna"}],
                tool_calls=[ToolCall(name="blah_tool", args={"x": -10}, id="456", type="tool_call")],
                id="blur",
            ),
        ]

        merge_message_runs(messages)

    .. code-block:: python

        [
            SystemMessage("you're a good assistant."),
            HumanMessage("what's your favorite color\\nwait your favorite food", id="foo",),
            AIMessage(
                [
                    "my favorite colo",
                    {"type": "text", "text": "my favorite dish is lasagna"}
                ],
                tool_calls=[
                    ToolCall({"name": "blah_tool", "args": {"x": 2}, "id": "123", "type": "tool_call"}),
                    ToolCall({"name": "blah_tool", "args": {"x": -10}, "id": "456", "type": "tool_call"})
                ]
                id="baz"
            ),
        ]</pre> 
</div>
</div>
<a id="a36ffc07313a22192c9dc09334aa182e5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a36ffc07313a22192c9dc09334aa182e5">&#9670;&nbsp;</a></span>message_chunk_to_message()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> <a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a> langchain_core.messages.utils.message_chunk_to_message </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessageChunk.html">BaseMessageChunk</a>&#160;</td>
          <td class="paramname"><em>chunk</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert a message chunk to a message.

Args:
    chunk: Message chunk to convert.

Returns:
    Message.
</pre> 
</div>
</div>
<a id="a61ba3a43a96aa673f427c2507f61755b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a61ba3a43a96aa673f427c2507f61755b">&#9670;&nbsp;</a></span>messages_from_dict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>] langchain_core.messages.utils.messages_from_dict </td>
          <td>(</td>
          <td class="paramtype">Sequence[dict]&#160;</td>
          <td class="paramname"><em>messages</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert a sequence of messages from dicts to Message objects.

Args:
    messages: Sequence of messages (as dicts) to convert.

Returns:
    list of messages (BaseMessages).
</pre> 
</div>
</div>
<a id="a9094bad6c6f69895ab5e246c540bd8cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9094bad6c6f69895ab5e246c540bd8cf">&#9670;&nbsp;</a></span>trim_messages()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>] langchain_core.messages.utils.trim_messages </td>
          <td>(</td>
          <td class="paramtype">Union[Iterable[<a class="el" href="namespacelangchain__core_1_1messages_1_1utils.html#abf0194234e4ca54755e2fe2a3d90170f">MessageLikeRepresentation</a>], <a class="el" href="classlangchain__core_1_1prompt__values_1_1PromptValue.html">PromptValue</a>]&#160;</td>
          <td class="paramname"><em>messages</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*int&#160;</td>
          <td class="paramname"><em>max_tokens</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Union[
        Callable[[list[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]], int],
        Callable[[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>], int],
        <a class="el" href="classlangchain__core_1_1language__models_1_1base_1_1BaseLanguageModel.html">BaseLanguageModel</a>,
    ]&#160;</td>
          <td class="paramname"><em>token_counter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Literal[&quot;first&quot;, &quot;last&quot;] &#160;</td>
          <td class="paramname"><em>strategy</em> = <code>&quot;last&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>allow_partial</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[
        Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>], Sequence[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]]]]
    ] &#160;</td>
          <td class="paramname"><em>end_on</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[
        Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>], Sequence[Union[str, type[<a class="el" href="classlangchain__core_1_1messages_1_1base_1_1BaseMessage.html">BaseMessage</a>]]]]
    ] &#160;</td>
          <td class="paramname"><em>start_on</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool &#160;</td>
          <td class="paramname"><em>include_system</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">Optional[Union[Callable[[str], list[str]], TextSplitter]] &#160;</td>
          <td class="paramname"><em>text_splitter</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Trim messages to be below a token count.

trim_messages can be used to reduce the size of a chat history to a specified token
count or specified message count.

In either case, if passing the trimmed chat history back into a chat model
directly, the resulting chat history should usually satisfy the following
properties:

1. The resulting chat history should be valid. Most chat models expect that chat
   history starts with either (1) a `HumanMessage` or (2) a `SystemMessage` followed
   by a `HumanMessage`. To achieve this, set `start_on="human"`.
   In addition, generally a `ToolMessage` can only appear after an `AIMessage`
   that involved a tool call.
   Please see the following link for more information about messages:
   https://python.langchain.com/docs/concepts/#messages
2. It includes recent messages and drops old messages in the chat history.
   To achieve this set the `strategy="last"`.
3. Usually, the new chat history should include the `SystemMessage` if it
   was present in the original chat history since the `SystemMessage` includes
   special instructions to the chat model. The `SystemMessage` is almost always
   the first message in the history if present. To achieve this set the
   `include_system=True`.

**Note** The examples below show how to configure `trim_messages` to achieve
    a behavior consistent with the above properties.

Args:
    messages: Sequence of Message-like objects to trim.
    max_tokens: Max token count of trimmed messages.
    token_counter: Function or llm for counting tokens in a BaseMessage or a list of
        BaseMessage. If a BaseLanguageModel is passed in then
        BaseLanguageModel.get_num_tokens_from_messages() will be used.
        Set to `len` to count the number of **messages** in the chat history.
    strategy: Strategy for trimming.
        - "first": Keep the first &lt;= n_count tokens of the messages.
        - "last": Keep the last &lt;= n_count tokens of the messages.
        Default is "last".
    allow_partial: Whether to split a message if only part of the message can be
        included. If ``strategy="last"`` then the last partial contents of a message
        are included. If ``strategy="first"`` then the first partial contents of a
        message are included.
        Default is False.
    end_on: The message type to end on. If specified then every message after the
        last occurrence of this type is ignored. If ``strategy=="last"`` then this
        is done before we attempt to get the last ``max_tokens``. If
        ``strategy=="first"`` then this is done after we get the first
        ``max_tokens``. Can be specified as string names (e.g. "system", "human",
        "ai", ...) or as BaseMessage classes (e.g. SystemMessage, HumanMessage,
        AIMessage, ...). Can be a single type or a list of types.
        Default is None.
    start_on: The message type to start on. Should only be specified if
        ``strategy="last"``. If specified then every message before
        the first occurrence of this type is ignored. This is done after we trim
        the initial messages to the last ``max_tokens``. Does not
        apply to a SystemMessage at index 0 if ``include_system=True``. Can be
        specified as string names (e.g. "system", "human", "ai", ...) or as
        BaseMessage classes (e.g. SystemMessage, HumanMessage, AIMessage, ...). Can
        be a single type or a list of types.
        Default is None.
    include_system: Whether to keep the SystemMessage if there is one at index 0.
        Should only be specified if ``strategy="last"``.
        Default is False.
    text_splitter: Function or ``langchain_text_splitters.TextSplitter`` for
        splitting the string contents of a message. Only used if
        ``allow_partial=True``. If ``strategy="last"`` then the last split tokens
        from a partial message will be included. if ``strategy=="first"`` then the
        first split tokens from a partial message will be included. Token splitter
        assumes that separators are kept, so that split contents can be directly
        concatenated to recreate the original text. Defaults to splitting on
        newlines.

Returns:
    list of trimmed BaseMessages.

Raises:
    ValueError: if two incompatible arguments are specified or an unrecognized
        ``strategy`` is specified.

Example:
    Trim chat history based on token count, keeping the SystemMessage if
    present, and ensuring that the chat history starts with a HumanMessage (
    or a SystemMessage followed by a HumanMessage).

    .. code-block:: python

        from typing import list

        from langchain_core.messages import (
            AIMessage,
            HumanMessage,
            BaseMessage,
            SystemMessage,
            trim_messages,
        )

        messages = [
            SystemMessage("you're a good assistant, you always respond with a joke."),
            HumanMessage("i wonder why it's called langchain"),
            AIMessage(
                'Well, I guess they thought "WordRope" and "SentenceString" just didn\'t have the same ring to it!'
            ),
            HumanMessage("and who is harrison chasing anyways"),
            AIMessage(
                "Hmmm let me think.\n\nWhy, he's probably chasing after the last cup of coffee in the office!"
            ),
            HumanMessage("what do you call a speechless parrot"),
        ]


        trim_messages(
            messages,
            max_tokens=45,
            strategy="last",
            token_counter=ChatOpenAI(model="gpt-4o"),
            # Most chat models expect that chat history starts with either:
            # (1) a HumanMessage or
            # (2) a SystemMessage followed by a HumanMessage
            start_on="human",
            # Usually, we want to keep the SystemMessage
            # if it's present in the original history.
            # The SystemMessage has special instructions for the model.
            include_system=True,
            allow_partial=False,
        )

    .. code-block:: python

        [
            SystemMessage(content="you're a good assistant, you always respond with a joke."),
            HumanMessage(content='what do you call a speechless parrot'),
        ]

    Trim chat history based on the message count, keeping the SystemMessage if
    present, and ensuring that the chat history starts with a HumanMessage (
    or a SystemMessage followed by a HumanMessage).

        trim_messages(
            messages,
            # When `len` is passed in as the token counter function,
            # max_tokens will count the number of messages in the chat history.
            max_tokens=4,
            strategy="last",
            # Passing in `len` as a token counter function will
            # count the number of messages in the chat history.
            token_counter=len,
            # Most chat models expect that chat history starts with either:
            # (1) a HumanMessage or
            # (2) a SystemMessage followed by a HumanMessage
            start_on="human",
            # Usually, we want to keep the SystemMessage
            # if it's present in the original history.
            # The SystemMessage has special instructions for the model.
            include_system=True,
            allow_partial=False,
        )

    .. code-block:: python

        [
            SystemMessage(content="you're a good assistant, you always respond with a joke."),
            HumanMessage(content='and who is harrison chasing anyways'),
            AIMessage(content="Hmmm let me think.\n\nWhy, he's probably chasing after the last cup of coffee in the office!"),
            HumanMessage(content='what do you call a speechless parrot'),
        ]


    Trim chat history using a custom token counter function that counts the
    number of tokens in each message.

    .. code-block:: python

        messages = [
            SystemMessage("This is a 4 token text. The full message is 10 tokens."),
            HumanMessage("This is a 4 token text. The full message is 10 tokens.", id="first"),
            AIMessage(
                [
                    {"type": "text", "text": "This is the FIRST 4 token block."},
                    {"type": "text", "text": "This is the SECOND 4 token block."},
                ],
                id="second",
            ),
            HumanMessage("This is a 4 token text. The full message is 10 tokens.", id="third"),
            AIMessage("This is a 4 token text. The full message is 10 tokens.", id="fourth"),
        ]

        def dummy_token_counter(messages: list[BaseMessage]) -&gt; int:
            # treat each message like it adds 3 default tokens at the beginning
            # of the message and at the end of the message. 3 + 4 + 3 = 10 tokens
            # per message.

            default_content_len = 4
            default_msg_prefix_len = 3
            default_msg_suffix_len = 3

            count = 0
            for msg in messages:
                if isinstance(msg.content, str):
                    count += default_msg_prefix_len + default_content_len + default_msg_suffix_len
                if isinstance(msg.content, list):
                    count += default_msg_prefix_len + len(msg.content) *  default_content_len + default_msg_suffix_len
            return count

    First 30 tokens, allowing partial messages:
        .. code-block:: python

            trim_messages(
                messages,
                max_tokens=30,
                token_counter=dummy_token_counter,
                strategy="first",
                allow_partial=True,
            )

        .. code-block:: python

            [
                SystemMessage("This is a 4 token text. The full message is 10 tokens."),
                HumanMessage("This is a 4 token text. The full message is 10 tokens.", id="first"),
                AIMessage( [{"type": "text", "text": "This is the FIRST 4 token block."}], id="second"),
            ]
</pre> 
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a15d15a793ab96ab36106994edb91e47c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a15d15a793ab96ab36106994edb91e47c">&#9670;&nbsp;</a></span>AnyMessage</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.messages.utils.AnyMessage</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;=  Annotated[</div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;    Union[</div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;        Annotated[AIMessage, Tag(tag=<span class="stringliteral">&quot;ai&quot;</span>)],</div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;        Annotated[HumanMessage, Tag(tag=<span class="stringliteral">&quot;human&quot;</span>)],</div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;        Annotated[ChatMessage, Tag(tag=<span class="stringliteral">&quot;chat&quot;</span>)],</div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;        Annotated[SystemMessage, Tag(tag=<span class="stringliteral">&quot;system&quot;</span>)],</div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;        Annotated[FunctionMessage, Tag(tag=<span class="stringliteral">&quot;function&quot;</span>)],</div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;        Annotated[ToolMessage, Tag(tag=<span class="stringliteral">&quot;tool&quot;</span>)],</div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;        Annotated[AIMessageChunk, Tag(tag=<span class="stringliteral">&quot;AIMessageChunk&quot;</span>)],</div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;        Annotated[HumanMessageChunk, Tag(tag=<span class="stringliteral">&quot;HumanMessageChunk&quot;</span>)],</div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;        Annotated[ChatMessageChunk, Tag(tag=<span class="stringliteral">&quot;ChatMessageChunk&quot;</span>)],</div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;        Annotated[SystemMessageChunk, Tag(tag=<span class="stringliteral">&quot;SystemMessageChunk&quot;</span>)],</div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;        Annotated[FunctionMessageChunk, Tag(tag=<span class="stringliteral">&quot;FunctionMessageChunk&quot;</span>)],</div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;        Annotated[ToolMessageChunk, Tag(tag=<span class="stringliteral">&quot;ToolMessageChunk&quot;</span>)],</div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;    ],</div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;    <a class="code" href="namespacepydantic_1_1fields.html#a4fffd16346f862a3cff705faccaf6261">Field</a>(discriminator=Discriminator(_get_type)),</div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;]</div>
<div class="ttc" id="anamespacepydantic_1_1fields_html_a4fffd16346f862a3cff705faccaf6261"><div class="ttname"><a href="namespacepydantic_1_1fields.html#a4fffd16346f862a3cff705faccaf6261">pydantic.fields.Field</a></div><div class="ttdeci">Any Field(ellipsis default, *str|None alias=_Unset, int|None alias_priority=_Unset, str|AliasPath|AliasChoices|None validation_alias=_Unset, str|None serialization_alias=_Unset, str|None title=_Unset, Callable[[str, FieldInfo], str]|None field_title_generator=_Unset, str|None description=_Unset, list[Any]|None examples=_Unset, bool|None exclude=_Unset, str|types.Discriminator|None discriminator=_Unset, Deprecated|str|bool|None deprecated=_Unset, JsonDict|Callable[[JsonDict], None]|None json_schema_extra=_Unset, bool|None frozen=_Unset, bool|None validate_default=_Unset, bool repr=_Unset, bool|None init=_Unset, bool|None init_var=_Unset, bool|None kw_only=_Unset, str|typing.Pattern[str]|None pattern=_Unset, bool|None strict=_Unset, bool|None coerce_numbers_to_str=_Unset, annotated_types.SupportsGt|None gt=_Unset, annotated_types.SupportsGe|None ge=_Unset, annotated_types.SupportsLt|None lt=_Unset, annotated_types.SupportsLe|None le=_Unset, float|None multiple_of=_Unset, bool|None allow_inf_nan=_Unset, int|None max_digits=_Unset, int|None decimal_places=_Unset, int|None min_length=_Unset, int|None max_length=_Unset, Literal['smart', 'left_to_right'] union_mode=_Unset, bool|None fail_fast=_Unset, **Unpack[_EmptyKwargs] extra)</div><div class="ttdef"><b>Definition:</b> fields.py:816</div></div>
</div><!-- fragment -->
</div>
</div>
<a id="abf0194234e4ca54755e2fe2a3d90170f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf0194234e4ca54755e2fe2a3d90170f">&#9670;&nbsp;</a></span>MessageLikeRepresentation</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">langchain_core.messages.utils.MessageLikeRepresentation</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;=  Union[</div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;    BaseMessage, list[str], tuple[str, str], str, dict[str, Any]</div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;]</div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
