<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: numpy.linalg._linalg Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>numpy</b></li><li class="navelem"><a class="el" href="namespacenumpy_1_1linalg.html">linalg</a></li><li class="navelem"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html">_linalg</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">numpy.linalg._linalg Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnumpy_1_1linalg_1_1__linalg_1_1EigResult.html">EigResult</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnumpy_1_1linalg_1_1__linalg_1_1EighResult.html">EighResult</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnumpy_1_1linalg_1_1__linalg_1_1QRResult.html">QRResult</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnumpy_1_1linalg_1_1__linalg_1_1SlogdetResult.html">SlogdetResult</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnumpy_1_1linalg_1_1__linalg_1_1SVDResult.html">SVDResult</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnumpy_1_1linalg_1_1__linalg_1_1LinAlgError.html">LinAlgError</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a83378a3701ceea528b2c327b8f256455"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a83378a3701ceea528b2c327b8f256455">isComplexType</a> (t)</td></tr>
<tr class="separator:a83378a3701ceea528b2c327b8f256455"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a995d7a81586bad8eaabaa46f56f90598"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a995d7a81586bad8eaabaa46f56f90598">transpose</a> (a)</td></tr>
<tr class="separator:a995d7a81586bad8eaabaa46f56f90598"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7791600aa8ed4f3cbacd8508f8488725"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a7791600aa8ed4f3cbacd8508f8488725">tensorsolve</a> (a, b, axes=None)</td></tr>
<tr class="separator:a7791600aa8ed4f3cbacd8508f8488725"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0065bff134b26388efc6de907132c989"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a0065bff134b26388efc6de907132c989">solve</a> (a, b)</td></tr>
<tr class="separator:a0065bff134b26388efc6de907132c989"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb1b6124622937662eada2571aab934d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#afb1b6124622937662eada2571aab934d">tensorinv</a> (a, ind=2)</td></tr>
<tr class="separator:afb1b6124622937662eada2571aab934d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf173287fe07b76a1128adee0fa3f9af"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#abf173287fe07b76a1128adee0fa3f9af">inv</a> (a)</td></tr>
<tr class="separator:abf173287fe07b76a1128adee0fa3f9af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53d6a3c96f633281c4e7f617aad30d80"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a53d6a3c96f633281c4e7f617aad30d80">matrix_power</a> (a, n)</td></tr>
<tr class="separator:a53d6a3c96f633281c4e7f617aad30d80"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a68b6b43e91fb600e27d0df66e0dbe135"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a68b6b43e91fb600e27d0df66e0dbe135">cholesky</a> (a, *upper=False)</td></tr>
<tr class="separator:a68b6b43e91fb600e27d0df66e0dbe135"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8e2c48125fe394c9e9b2ff5ce7fd59f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#aa8e2c48125fe394c9e9b2ff5ce7fd59f">outer</a> (x1, x2)</td></tr>
<tr class="separator:aa8e2c48125fe394c9e9b2ff5ce7fd59f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f8cebf7494f653e022ba25a732d8fa6"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a3f8cebf7494f653e022ba25a732d8fa6">qr</a> (a, mode='reduced')</td></tr>
<tr class="separator:a3f8cebf7494f653e022ba25a732d8fa6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeff6ebbed424f072e1d5a7f046ccb58a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#aeff6ebbed424f072e1d5a7f046ccb58a">eigvals</a> (a)</td></tr>
<tr class="separator:aeff6ebbed424f072e1d5a7f046ccb58a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0c19534cd5d6bef6f0340618c2bc1d4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#aa0c19534cd5d6bef6f0340618c2bc1d4">eigvalsh</a> (a, UPLO='L')</td></tr>
<tr class="separator:aa0c19534cd5d6bef6f0340618c2bc1d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a099a5cc7ef0450911cd50f4398171b4f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a099a5cc7ef0450911cd50f4398171b4f">eig</a> (a)</td></tr>
<tr class="separator:a099a5cc7ef0450911cd50f4398171b4f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a66ab80b71c5bda65272c11bb187c40ea"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a66ab80b71c5bda65272c11bb187c40ea">eigh</a> (a, UPLO='L')</td></tr>
<tr class="separator:a66ab80b71c5bda65272c11bb187c40ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28cf54df726b6cde636297a0bfbfa28a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a28cf54df726b6cde636297a0bfbfa28a">svd</a> (a, full_matrices=True, compute_uv=True, hermitian=False)</td></tr>
<tr class="separator:a28cf54df726b6cde636297a0bfbfa28a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c81ef0245eedd325880bcae43dba031"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a1c81ef0245eedd325880bcae43dba031">svdvals</a> (x)</td></tr>
<tr class="separator:a1c81ef0245eedd325880bcae43dba031"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0f2655aa4ab084ce3ea142d4daffd26a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a0f2655aa4ab084ce3ea142d4daffd26a">cond</a> (x, p=None)</td></tr>
<tr class="separator:a0f2655aa4ab084ce3ea142d4daffd26a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3898f651cd8501f3b6145f633128232c"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a3898f651cd8501f3b6145f633128232c">matrix_rank</a> (A, tol=None, hermitian=False, *rtol=None)</td></tr>
<tr class="separator:a3898f651cd8501f3b6145f633128232c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4ca1647fbc15babda64de6ef161b685b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a4ca1647fbc15babda64de6ef161b685b">pinv</a> (a, rcond=None, hermitian=False, *rtol=_NoValue)</td></tr>
<tr class="separator:a4ca1647fbc15babda64de6ef161b685b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9bc9be05b4b2a9bfd463b7803f653299"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a9bc9be05b4b2a9bfd463b7803f653299">slogdet</a> (a)</td></tr>
<tr class="separator:a9bc9be05b4b2a9bfd463b7803f653299"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a73750602823d7a8667d991e52bb93aa5"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a73750602823d7a8667d991e52bb93aa5">det</a> (a)</td></tr>
<tr class="separator:a73750602823d7a8667d991e52bb93aa5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54b0b605bfcd7c2d118dcfbb0045f528"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a54b0b605bfcd7c2d118dcfbb0045f528">lstsq</a> (a, b, rcond=None)</td></tr>
<tr class="separator:a54b0b605bfcd7c2d118dcfbb0045f528"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae667181925aa0b20a339f260a1c8fa9a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#ae667181925aa0b20a339f260a1c8fa9a">norm</a> (x, ord=None, axis=None, keepdims=False)</td></tr>
<tr class="separator:ae667181925aa0b20a339f260a1c8fa9a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3740758ad45d6559a78a637417f9d3af"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a3740758ad45d6559a78a637417f9d3af">multi_dot</a> (arrays, *out=None)</td></tr>
<tr class="separator:a3740758ad45d6559a78a637417f9d3af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac3c59ed6db18757222aa88e3a33c6bd8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#ac3c59ed6db18757222aa88e3a33c6bd8">diagonal</a> (x, *offset=0)</td></tr>
<tr class="separator:ac3c59ed6db18757222aa88e3a33c6bd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4d908f18674aa60b92020060fed52b2b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a4d908f18674aa60b92020060fed52b2b">trace</a> (x, *offset=0, dtype=None)</td></tr>
<tr class="separator:a4d908f18674aa60b92020060fed52b2b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa82fb0c6b9ff94dbfbecd1bff0f5a773"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#aa82fb0c6b9ff94dbfbecd1bff0f5a773">cross</a> (x1, x2, *axis=-1)</td></tr>
<tr class="separator:aa82fb0c6b9ff94dbfbecd1bff0f5a773"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e1543e0579f4fe645e2e794ade194c4"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a0e1543e0579f4fe645e2e794ade194c4">matmul</a> (x1, x2)</td></tr>
<tr class="separator:a0e1543e0579f4fe645e2e794ade194c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2a2becf79fdc487aa3fede24ae13a53"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#ad2a2becf79fdc487aa3fede24ae13a53">tensordot</a> (x1, x2, *axes=2)</td></tr>
<tr class="separator:ad2a2becf79fdc487aa3fede24ae13a53"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af5f11e4f94009e163343d8ac8e77f03f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#af5f11e4f94009e163343d8ac8e77f03f">matrix_transpose</a> (x)</td></tr>
<tr class="separator:af5f11e4f94009e163343d8ac8e77f03f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad279b310c24e8038a3f3d162ca7bc32a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#ad279b310c24e8038a3f3d162ca7bc32a">matrix_norm</a> (x, *keepdims=False, ord=&quot;fro&quot;)</td></tr>
<tr class="separator:ad279b310c24e8038a3f3d162ca7bc32a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9d3023ec0d4ea51069999a1056e44970"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a9d3023ec0d4ea51069999a1056e44970">vector_norm</a> (x, *axis=None, keepdims=False, ord=2)</td></tr>
<tr class="separator:a9d3023ec0d4ea51069999a1056e44970"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a862848fe7a4c54757819cbadd31efbb9"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a862848fe7a4c54757819cbadd31efbb9">vecdot</a> (x1, x2, *axis=-1)</td></tr>
<tr class="separator:a862848fe7a4c54757819cbadd31efbb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a0882dc90edbc29418c3a42c1d3c1d6d8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#a0882dc90edbc29418c3a42c1d3c1d6d8">array_function_dispatch</a></td></tr>
<tr class="separator:a0882dc90edbc29418c3a42c1d3c1d6d8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad9473eaede4ac4db2f5a8d23c07caf56"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacenumpy_1_1linalg_1_1__linalg.html#ad9473eaede4ac4db2f5a8d23c07caf56">fortran_int</a> = intc</td></tr>
<tr class="separator:ad9473eaede4ac4db2f5a8d23c07caf56"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Lite version of scipy.linalg.

Notes
-----
This module is a lite version of the linalg.py module in SciPy which
contains high-level Python interface to the LAPACK library.  The lite
version only accesses the following LAPACK functions: dgesv, zgesv,
dgeev, zgeev, dgesdd, zgesdd, dgelsd, zgelsd, dsyevd, zheevd, dgetrf,
zgetrf, dpotrf, zpotrf, dgeqrf, zgeqrf, zungqr, dorgqr.
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a68b6b43e91fb600e27d0df66e0dbe135"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68b6b43e91fb600e27d0df66e0dbe135">&#9670;&nbsp;</a></span>cholesky()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.cholesky </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>upper</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Cholesky decomposition.

Return the lower or upper Cholesky decomposition, ``L * L.H`` or
``U.H * U``, of the square matrix ``a``, where ``L`` is lower-triangular,
``U`` is upper-triangular, and ``.H`` is the conjugate transpose operator
(which is the ordinary transpose if ``a`` is real-valued). ``a`` must be
Hermitian (symmetric if real-valued) and positive-definite. No checking is
performed to verify whether ``a`` is Hermitian or not. In addition, only
the lower or upper-triangular and diagonal elements of ``a`` are used.
Only ``L`` or ``U`` is actually returned.

Parameters
----------
a : (..., M, M) array_like
    Hermitian (symmetric if all elements are real), positive-definite
    input matrix.
upper : bool
    If ``True``, the result must be the upper-triangular Cholesky factor.
    If ``False``, the result must be the lower-triangular Cholesky factor.
    Default: ``False``.

Returns
-------
L : (..., M, M) array_like
    Lower or upper-triangular Cholesky factor of `a`. Returns a matrix
    object if `a` is a matrix object.

Raises
------
LinAlgError
   If the decomposition fails, for example, if `a` is not
   positive-definite.

See Also
--------
scipy.linalg.cholesky : Similar function in SciPy.
scipy.linalg.cholesky_banded : Cholesky decompose a banded Hermitian
                               positive-definite matrix.
scipy.linalg.cho_factor : Cholesky decomposition of a matrix, to use in
                          `scipy.linalg.cho_solve`.

Notes
-----
Broadcasting rules apply, see the `numpy.linalg` documentation for
details.

The Cholesky decomposition is often used as a fast way of solving

.. math:: A \\mathbf{x} = \\mathbf{b}

(when `A` is both Hermitian/symmetric and positive-definite).

First, we solve for :math:`\\mathbf{y}` in

.. math:: L \\mathbf{y} = \\mathbf{b},

and then for :math:`\\mathbf{x}` in

.. math:: L^{H} \\mathbf{x} = \\mathbf{y}.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; A = np.array([[1,-2j],[2j,5]])
&gt;&gt;&gt; A
array([[ 1.+0.j, -0.-2.j],
       [ 0.+2.j,  5.+0.j]])
&gt;&gt;&gt; L = np.linalg.cholesky(A)
&gt;&gt;&gt; L
array([[1.+0.j, 0.+0.j],
       [0.+2.j, 1.+0.j]])
&gt;&gt;&gt; np.dot(L, L.T.conj()) # verify that L * L.H = A
array([[1.+0.j, 0.-2.j],
       [0.+2.j, 5.+0.j]])
&gt;&gt;&gt; A = [[1,-2j],[2j,5]] # what happens if A is only array_like?
&gt;&gt;&gt; np.linalg.cholesky(A) # an ndarray object is returned
array([[1.+0.j, 0.+0.j],
       [0.+2.j, 1.+0.j]])
&gt;&gt;&gt; # But a matrix object is returned if A is a matrix object
&gt;&gt;&gt; np.linalg.cholesky(np.matrix(A))
matrix([[ 1.+0.j,  0.+0.j],
        [ 0.+2.j,  1.+0.j]])
&gt;&gt;&gt; # The upper-triangular Cholesky factor can also be obtained.
&gt;&gt;&gt; np.linalg.cholesky(A, upper=True)
array([[1.-0.j, 0.-2.j],
       [0.-0.j, 1.-0.j]])</pre> 
</div>
</div>
<a id="a0f2655aa4ab084ce3ea142d4daffd26a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0f2655aa4ab084ce3ea142d4daffd26a">&#9670;&nbsp;</a></span>cond()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.cond </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>p</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the condition number of a matrix.

This function is capable of returning the condition number using
one of seven different norms, depending on the value of `p` (see
Parameters below).

Parameters
----------
x : (..., M, N) array_like
    The matrix whose condition number is sought.
p : {None, 1, -1, 2, -2, inf, -inf, 'fro'}, optional
    Order of the norm used in the condition number computation:

    =====  ============================
    p      norm for matrices
    =====  ============================
    None   2-norm, computed directly using the ``SVD``
    'fro'  Frobenius norm
    inf    max(sum(abs(x), axis=1))
    -inf   min(sum(abs(x), axis=1))
    1      max(sum(abs(x), axis=0))
    -1     min(sum(abs(x), axis=0))
    2      2-norm (largest sing. value)
    -2     smallest singular value
    =====  ============================

    inf means the `numpy.inf` object, and the Frobenius norm is
    the root-of-sum-of-squares norm.

Returns
-------
c : {float, inf}
    The condition number of the matrix. May be infinite.

See Also
--------
numpy.linalg.norm

Notes
-----
The condition number of `x` is defined as the norm of `x` times the
norm of the inverse of `x` [1]_; the norm can be the usual L2-norm
(root-of-sum-of-squares) or one of a number of other matrix norms.

References
----------
.. [1] G. Strang, *Linear Algebra and Its Applications*, Orlando, FL,
       Academic Press, Inc., 1980, pg. 285.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy import linalg as LA
&gt;&gt;&gt; a = np.array([[1, 0, -1], [0, 1, 0], [1, 0, 1]])
&gt;&gt;&gt; a
array([[ 1,  0, -1],
       [ 0,  1,  0],
       [ 1,  0,  1]])
&gt;&gt;&gt; LA.cond(a)
1.4142135623730951
&gt;&gt;&gt; LA.cond(a, 'fro')
3.1622776601683795
&gt;&gt;&gt; LA.cond(a, np.inf)
2.0
&gt;&gt;&gt; LA.cond(a, -np.inf)
1.0
&gt;&gt;&gt; LA.cond(a, 1)
2.0
&gt;&gt;&gt; LA.cond(a, -1)
1.0
&gt;&gt;&gt; LA.cond(a, 2)
1.4142135623730951
&gt;&gt;&gt; LA.cond(a, -2)
0.70710678118654746 # may vary
&gt;&gt;&gt; (min(LA.svd(a, compute_uv=False)) *
... min(LA.svd(LA.inv(a), compute_uv=False)))
0.70710678118654746 # may vary</pre> 
</div>
</div>
<a id="aa82fb0c6b9ff94dbfbecd1bff0f5a773"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa82fb0c6b9ff94dbfbecd1bff0f5a773">&#9670;&nbsp;</a></span>cross()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.cross </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>axis</em> = <code>-1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the cross product of 3-element vectors.

If ``x1`` and/or ``x2`` are multi-dimensional arrays, then
the cross-product of each pair of corresponding 3-element vectors
is independently computed.

This function is Array API compatible, contrary to
:func:`numpy.cross`.

Parameters
----------
x1 : array_like
    The first input array.
x2 : array_like
    The second input array. Must be compatible with ``x1`` for all
    non-compute axes. The size of the axis over which to compute
    the cross-product must be the same size as the respective axis
    in ``x1``.
axis : int, optional
    The axis (dimension) of ``x1`` and ``x2`` containing the vectors for
    which to compute the cross-product. Default: ``-1``.

Returns
-------
out : ndarray
    An array containing the cross products.

See Also
--------
numpy.cross

Examples
--------
Vector cross-product.

&gt;&gt;&gt; x = np.array([1, 2, 3])
&gt;&gt;&gt; y = np.array([4, 5, 6])
&gt;&gt;&gt; np.linalg.cross(x, y)
array([-3,  6, -3])

Multiple vector cross-products. Note that the direction of the cross
product vector is defined by the *right-hand rule*.

&gt;&gt;&gt; x = np.array([[1,2,3], [4,5,6]])
&gt;&gt;&gt; y = np.array([[4,5,6], [1,2,3]])
&gt;&gt;&gt; np.linalg.cross(x, y)
array([[-3,  6, -3],
       [ 3, -6,  3]])

&gt;&gt;&gt; x = np.array([[1, 2], [3, 4], [5, 6]])
&gt;&gt;&gt; y = np.array([[4, 5], [6, 1], [2, 3]])
&gt;&gt;&gt; np.linalg.cross(x, y, axis=0)
array([[-24,  6],
       [ 18, 24],
       [-6,  -18]])</pre> 
</div>
</div>
<a id="a73750602823d7a8667d991e52bb93aa5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a73750602823d7a8667d991e52bb93aa5">&#9670;&nbsp;</a></span>det()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.det </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the determinant of an array.

Parameters
----------
a : (..., M, M) array_like
    Input array to compute determinants for.

Returns
-------
det : (...) array_like
    Determinant of `a`.

See Also
--------
slogdet : Another way to represent the determinant, more suitable
  for large matrices where underflow/overflow may occur.
scipy.linalg.det : Similar function in SciPy.

Notes
-----
Broadcasting rules apply, see the `numpy.linalg` documentation for
details.

The determinant is computed via LU factorization using the LAPACK
routine ``z/dgetrf``.

Examples
--------
The determinant of a 2-D array [[a, b], [c, d]] is ad - bc:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.array([[1, 2], [3, 4]])
&gt;&gt;&gt; np.linalg.det(a)
-2.0 # may vary

Computing determinants for a stack of matrices:

&gt;&gt;&gt; a = np.array([ [[1, 2], [3, 4]], [[1, 2], [2, 1]], [[1, 3], [3, 1]] ])
&gt;&gt;&gt; a.shape
(3, 2, 2)
&gt;&gt;&gt; np.linalg.det(a)
array([-2., -3., -8.])</pre> 
</div>
</div>
<a id="ac3c59ed6db18757222aa88e3a33c6bd8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac3c59ed6db18757222aa88e3a33c6bd8">&#9670;&nbsp;</a></span>diagonal()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.diagonal </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>offset</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns specified diagonals of a matrix (or a stack of matrices) ``x``.

This function is Array API compatible, contrary to
:py:func:`numpy.diagonal`, the matrix is assumed
to be defined by the last two dimensions.

Parameters
----------
x : (...,M,N) array_like
    Input array having shape (..., M, N) and whose innermost two
    dimensions form MxN matrices.
offset : int, optional
    Offset specifying the off-diagonal relative to the main diagonal,
    where::

        * offset = 0: the main diagonal.
        * offset &gt; 0: off-diagonal above the main diagonal.
        * offset &lt; 0: off-diagonal below the main diagonal.

Returns
-------
out : (...,min(N,M)) ndarray
    An array containing the diagonals and whose shape is determined by
    removing the last two dimensions and appending a dimension equal to
    the size of the resulting diagonals. The returned array must have
    the same data type as ``x``.

See Also
--------
numpy.diagonal

Examples
--------
&gt;&gt;&gt; a = np.arange(4).reshape(2, 2); a
array([[0, 1],
       [2, 3]])
&gt;&gt;&gt; np.linalg.diagonal(a)
array([0, 3])

A 3-D example:

&gt;&gt;&gt; a = np.arange(8).reshape(2, 2, 2); a
array([[[0, 1],
        [2, 3]],
       [[4, 5],
        [6, 7]]])
&gt;&gt;&gt; np.linalg.diagonal(a)
array([[0, 3],
       [4, 7]])

Diagonals adjacent to the main diagonal can be obtained by using the
`offset` argument:

&gt;&gt;&gt; a = np.arange(9).reshape(3, 3)
&gt;&gt;&gt; a
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])
&gt;&gt;&gt; np.linalg.diagonal(a, offset=1)  # First superdiagonal
array([1, 5])
&gt;&gt;&gt; np.linalg.diagonal(a, offset=2)  # Second superdiagonal
array([2])
&gt;&gt;&gt; np.linalg.diagonal(a, offset=-1)  # First subdiagonal
array([3, 7])
&gt;&gt;&gt; np.linalg.diagonal(a, offset=-2)  # Second subdiagonal
array([6])

The anti-diagonal can be obtained by reversing the order of elements
using either `numpy.flipud` or `numpy.fliplr`.

&gt;&gt;&gt; a = np.arange(9).reshape(3, 3)
&gt;&gt;&gt; a
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])
&gt;&gt;&gt; np.linalg.diagonal(np.fliplr(a))  # Horizontal flip
array([2, 4, 6])
&gt;&gt;&gt; np.linalg.diagonal(np.flipud(a))  # Vertical flip
array([6, 4, 2])

Note that the order in which the diagonal is retrieved varies depending
on the flip function.</pre> 
</div>
</div>
<a id="a099a5cc7ef0450911cd50f4398171b4f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a099a5cc7ef0450911cd50f4398171b4f">&#9670;&nbsp;</a></span>eig()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.eig </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the eigenvalues and right eigenvectors of a square array.

Parameters
----------
a : (..., M, M) array
    Matrices for which the eigenvalues and right eigenvectors will
    be computed

Returns
-------
A namedtuple with the following attributes:

eigenvalues : (..., M) array
    The eigenvalues, each repeated according to its multiplicity.
    The eigenvalues are not necessarily ordered. The resulting
    array will be of complex type, unless the imaginary part is
    zero in which case it will be cast to a real type. When `a`
    is real the resulting eigenvalues will be real (0 imaginary
    part) or occur in conjugate pairs

eigenvectors : (..., M, M) array
    The normalized (unit "length") eigenvectors, such that the
    column ``eigenvectors[:,i]`` is the eigenvector corresponding to the
    eigenvalue ``eigenvalues[i]``.

Raises
------
LinAlgError
    If the eigenvalue computation does not converge.

See Also
--------
eigvals : eigenvalues of a non-symmetric array.
eigh : eigenvalues and eigenvectors of a real symmetric or complex
       Hermitian (conjugate symmetric) array.
eigvalsh : eigenvalues of a real symmetric or complex Hermitian
           (conjugate symmetric) array.
scipy.linalg.eig : Similar function in SciPy that also solves the
                   generalized eigenvalue problem.
scipy.linalg.schur : Best choice for unitary and other non-Hermitian
                     normal matrices.

Notes
-----
Broadcasting rules apply, see the `numpy.linalg` documentation for
details.

This is implemented using the ``_geev`` LAPACK routines which compute
the eigenvalues and eigenvectors of general square arrays.

The number `w` is an eigenvalue of `a` if there exists a vector `v` such
that ``a @ v = w * v``. Thus, the arrays `a`, `eigenvalues`, and
`eigenvectors` satisfy the equations ``a @ eigenvectors[:,i] =
eigenvalues[i] * eigenvectors[:,i]`` for :math:`i \\in \\{0,...,M-1\\}`.

The array `eigenvectors` may not be of maximum rank, that is, some of the
columns may be linearly dependent, although round-off error may obscure
that fact. If the eigenvalues are all different, then theoretically the
eigenvectors are linearly independent and `a` can be diagonalized by a
similarity transformation using `eigenvectors`, i.e, ``inv(eigenvectors) @
a @ eigenvectors`` is diagonal.

For non-Hermitian normal matrices the SciPy function `scipy.linalg.schur`
is preferred because the matrix `eigenvectors` is guaranteed to be
unitary, which is not the case when using `eig`. The Schur factorization
produces an upper triangular matrix rather than a diagonal matrix, but for
normal matrices only the diagonal of the upper triangular matrix is
needed, the rest is roundoff error.

Finally, it is emphasized that `eigenvectors` consists of the *right* (as
in right-hand side) eigenvectors of `a`. A vector `y` satisfying ``y.T @ a
= z * y.T`` for some number `z` is called a *left* eigenvector of `a`,
and, in general, the left and right eigenvectors of a matrix are not
necessarily the (perhaps conjugate) transposes of each other.

References
----------
G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando, FL,
Academic Press, Inc., 1980, Various pp.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy import linalg as LA

(Almost) trivial example with real eigenvalues and eigenvectors.

&gt;&gt;&gt; eigenvalues, eigenvectors = LA.eig(np.diag((1, 2, 3)))
&gt;&gt;&gt; eigenvalues
array([1., 2., 3.])
&gt;&gt;&gt; eigenvectors
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]])

Real matrix possessing complex eigenvalues and eigenvectors;
note that the eigenvalues are complex conjugates of each other.

&gt;&gt;&gt; eigenvalues, eigenvectors = LA.eig(np.array([[1, -1], [1, 1]]))
&gt;&gt;&gt; eigenvalues
array([1.+1.j, 1.-1.j])
&gt;&gt;&gt; eigenvectors
array([[0.70710678+0.j        , 0.70710678-0.j        ],
       [0.        -0.70710678j, 0.        +0.70710678j]])

Complex-valued matrix with real eigenvalues (but complex-valued
eigenvectors); note that ``a.conj().T == a``, i.e., `a` is Hermitian.

&gt;&gt;&gt; a = np.array([[1, 1j], [-1j, 1]])
&gt;&gt;&gt; eigenvalues, eigenvectors = LA.eig(a)
&gt;&gt;&gt; eigenvalues
array([2.+0.j, 0.+0.j])
&gt;&gt;&gt; eigenvectors
array([[ 0.        +0.70710678j,  0.70710678+0.j        ], # may vary
       [ 0.70710678+0.j        , -0.        +0.70710678j]])

Be careful about round-off error!

&gt;&gt;&gt; a = np.array([[1 + 1e-9, 0], [0, 1 - 1e-9]])
&gt;&gt;&gt; # Theor. eigenvalues are 1 +/- 1e-9
&gt;&gt;&gt; eigenvalues, eigenvectors = LA.eig(a)
&gt;&gt;&gt; eigenvalues
array([1., 1.])
&gt;&gt;&gt; eigenvectors
array([[1., 0.],
       [0., 1.]])</pre> 
</div>
</div>
<a id="a66ab80b71c5bda65272c11bb187c40ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a66ab80b71c5bda65272c11bb187c40ea">&#9670;&nbsp;</a></span>eigh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.eigh </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>UPLO</em> = <code>'L'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return the eigenvalues and eigenvectors of a complex Hermitian
(conjugate symmetric) or a real symmetric matrix.

Returns two objects, a 1-D array containing the eigenvalues of `a`, and
a 2-D square array or matrix (depending on the input type) of the
corresponding eigenvectors (in columns).

Parameters
----------
a : (..., M, M) array
    Hermitian or real symmetric matrices whose eigenvalues and
    eigenvectors are to be computed.
UPLO : {'L', 'U'}, optional
    Specifies whether the calculation is done with the lower triangular
    part of `a` ('L', default) or the upper triangular part ('U').
    Irrespective of this value only the real parts of the diagonal will
    be considered in the computation to preserve the notion of a Hermitian
    matrix. It therefore follows that the imaginary part of the diagonal
    will always be treated as zero.

Returns
-------
A namedtuple with the following attributes:

eigenvalues : (..., M) ndarray
    The eigenvalues in ascending order, each repeated according to
    its multiplicity.
eigenvectors : {(..., M, M) ndarray, (..., M, M) matrix}
    The column ``eigenvectors[:, i]`` is the normalized eigenvector
    corresponding to the eigenvalue ``eigenvalues[i]``.  Will return a
    matrix object if `a` is a matrix object.

Raises
------
LinAlgError
    If the eigenvalue computation does not converge.

See Also
--------
eigvalsh : eigenvalues of real symmetric or complex Hermitian
           (conjugate symmetric) arrays.
eig : eigenvalues and right eigenvectors for non-symmetric arrays.
eigvals : eigenvalues of non-symmetric arrays.
scipy.linalg.eigh : Similar function in SciPy (but also solves the
                    generalized eigenvalue problem).

Notes
-----
Broadcasting rules apply, see the `numpy.linalg` documentation for
details.

The eigenvalues/eigenvectors are computed using LAPACK routines ``_syevd``,
``_heevd``.

The eigenvalues of real symmetric or complex Hermitian matrices are always
real. [1]_ The array `eigenvalues` of (column) eigenvectors is unitary and
`a`, `eigenvalues`, and `eigenvectors` satisfy the equations ``dot(a,
eigenvectors[:, i]) = eigenvalues[i] * eigenvectors[:, i]``.

References
----------
.. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,
       FL, Academic Press, Inc., 1980, pg. 222.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy import linalg as LA
&gt;&gt;&gt; a = np.array([[1, -2j], [2j, 5]])
&gt;&gt;&gt; a
array([[ 1.+0.j, -0.-2.j],
       [ 0.+2.j,  5.+0.j]])
&gt;&gt;&gt; eigenvalues, eigenvectors = LA.eigh(a)
&gt;&gt;&gt; eigenvalues
array([0.17157288, 5.82842712])
&gt;&gt;&gt; eigenvectors
array([[-0.92387953+0.j        , -0.38268343+0.j        ], # may vary
       [ 0.        +0.38268343j,  0.        -0.92387953j]])

&gt;&gt;&gt; (np.dot(a, eigenvectors[:, 0]) -
... eigenvalues[0] * eigenvectors[:, 0])  # verify 1st eigenval/vec pair
array([5.55111512e-17+0.0000000e+00j, 0.00000000e+00+1.2490009e-16j])
&gt;&gt;&gt; (np.dot(a, eigenvectors[:, 1]) -
... eigenvalues[1] * eigenvectors[:, 1])  # verify 2nd eigenval/vec pair
array([0.+0.j, 0.+0.j])

&gt;&gt;&gt; A = np.matrix(a) # what happens if input is a matrix object
&gt;&gt;&gt; A
matrix([[ 1.+0.j, -0.-2.j],
        [ 0.+2.j,  5.+0.j]])
&gt;&gt;&gt; eigenvalues, eigenvectors = LA.eigh(A)
&gt;&gt;&gt; eigenvalues
array([0.17157288, 5.82842712])
&gt;&gt;&gt; eigenvectors
matrix([[-0.92387953+0.j        , -0.38268343+0.j        ], # may vary
        [ 0.        +0.38268343j,  0.        -0.92387953j]])

&gt;&gt;&gt; # demonstrate the treatment of the imaginary part of the diagonal
&gt;&gt;&gt; a = np.array([[5+2j, 9-2j], [0+2j, 2-1j]])
&gt;&gt;&gt; a
array([[5.+2.j, 9.-2.j],
       [0.+2.j, 2.-1.j]])
&gt;&gt;&gt; # with UPLO='L' this is numerically equivalent to using LA.eig() with:
&gt;&gt;&gt; b = np.array([[5.+0.j, 0.-2.j], [0.+2.j, 2.-0.j]])
&gt;&gt;&gt; b
array([[5.+0.j, 0.-2.j],
       [0.+2.j, 2.+0.j]])
&gt;&gt;&gt; wa, va = LA.eigh(a)
&gt;&gt;&gt; wb, vb = LA.eig(b)
&gt;&gt;&gt; wa
array([1., 6.])
&gt;&gt;&gt; wb
array([6.+0.j, 1.+0.j])
&gt;&gt;&gt; va
array([[-0.4472136 +0.j        , -0.89442719+0.j        ], # may vary
       [ 0.        +0.89442719j,  0.        -0.4472136j ]])
&gt;&gt;&gt; vb
array([[ 0.89442719+0.j       , -0.        +0.4472136j],
       [-0.        +0.4472136j,  0.89442719+0.j       ]])</pre> 
</div>
</div>
<a id="aeff6ebbed424f072e1d5a7f046ccb58a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeff6ebbed424f072e1d5a7f046ccb58a">&#9670;&nbsp;</a></span>eigvals()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.eigvals </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the eigenvalues of a general matrix.

Main difference between `eigvals` and `eig`: the eigenvectors aren't
returned.

Parameters
----------
a : (..., M, M) array_like
    A complex- or real-valued matrix whose eigenvalues will be computed.

Returns
-------
w : (..., M,) ndarray
    The eigenvalues, each repeated according to its multiplicity.
    They are not necessarily ordered, nor are they necessarily
    real for real matrices.

Raises
------
LinAlgError
    If the eigenvalue computation does not converge.

See Also
--------
eig : eigenvalues and right eigenvectors of general arrays
eigvalsh : eigenvalues of real symmetric or complex Hermitian
           (conjugate symmetric) arrays.
eigh : eigenvalues and eigenvectors of real symmetric or complex
       Hermitian (conjugate symmetric) arrays.
scipy.linalg.eigvals : Similar function in SciPy.

Notes
-----
Broadcasting rules apply, see the `numpy.linalg` documentation for
details.

This is implemented using the ``_geev`` LAPACK routines which compute
the eigenvalues and eigenvectors of general square arrays.

Examples
--------
Illustration, using the fact that the eigenvalues of a diagonal matrix
are its diagonal elements, that multiplying a matrix on the left
by an orthogonal matrix, `Q`, and on the right by `Q.T` (the transpose
of `Q`), preserves the eigenvalues of the "middle" matrix. In other words,
if `Q` is orthogonal, then ``Q * A * Q.T`` has the same eigenvalues as
``A``:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy import linalg as LA
&gt;&gt;&gt; x = np.random.random()
&gt;&gt;&gt; Q = np.array([[np.cos(x), -np.sin(x)], [np.sin(x), np.cos(x)]])
&gt;&gt;&gt; LA.norm(Q[0, :]), LA.norm(Q[1, :]), np.dot(Q[0, :],Q[1, :])
(1.0, 1.0, 0.0)

Now multiply a diagonal matrix by ``Q`` on one side and
by ``Q.T`` on the other:

&gt;&gt;&gt; D = np.diag((-1,1))
&gt;&gt;&gt; LA.eigvals(D)
array([-1.,  1.])
&gt;&gt;&gt; A = np.dot(Q, D)
&gt;&gt;&gt; A = np.dot(A, Q.T)
&gt;&gt;&gt; LA.eigvals(A)
array([ 1., -1.]) # random</pre> 
</div>
</div>
<a id="aa0c19534cd5d6bef6f0340618c2bc1d4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0c19534cd5d6bef6f0340618c2bc1d4">&#9670;&nbsp;</a></span>eigvalsh()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.eigvalsh </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>UPLO</em> = <code>'L'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the eigenvalues of a complex Hermitian or real symmetric matrix.

Main difference from eigh: the eigenvectors are not computed.

Parameters
----------
a : (..., M, M) array_like
    A complex- or real-valued matrix whose eigenvalues are to be
    computed.
UPLO : {'L', 'U'}, optional
    Specifies whether the calculation is done with the lower triangular
    part of `a` ('L', default) or the upper triangular part ('U').
    Irrespective of this value only the real parts of the diagonal will
    be considered in the computation to preserve the notion of a Hermitian
    matrix. It therefore follows that the imaginary part of the diagonal
    will always be treated as zero.

Returns
-------
w : (..., M,) ndarray
    The eigenvalues in ascending order, each repeated according to
    its multiplicity.

Raises
------
LinAlgError
    If the eigenvalue computation does not converge.

See Also
--------
eigh : eigenvalues and eigenvectors of real symmetric or complex Hermitian
       (conjugate symmetric) arrays.
eigvals : eigenvalues of general real or complex arrays.
eig : eigenvalues and right eigenvectors of general real or complex
      arrays.
scipy.linalg.eigvalsh : Similar function in SciPy.

Notes
-----
Broadcasting rules apply, see the `numpy.linalg` documentation for
details.

The eigenvalues are computed using LAPACK routines ``_syevd``, ``_heevd``.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy import linalg as LA
&gt;&gt;&gt; a = np.array([[1, -2j], [2j, 5]])
&gt;&gt;&gt; LA.eigvalsh(a)
array([ 0.17157288,  5.82842712]) # may vary

&gt;&gt;&gt; # demonstrate the treatment of the imaginary part of the diagonal
&gt;&gt;&gt; a = np.array([[5+2j, 9-2j], [0+2j, 2-1j]])
&gt;&gt;&gt; a
array([[5.+2.j, 9.-2.j],
       [0.+2.j, 2.-1.j]])
&gt;&gt;&gt; # with UPLO='L' this is numerically equivalent to using LA.eigvals()
&gt;&gt;&gt; # with:
&gt;&gt;&gt; b = np.array([[5.+0.j, 0.-2.j], [0.+2.j, 2.-0.j]])
&gt;&gt;&gt; b
array([[5.+0.j, 0.-2.j],
       [0.+2.j, 2.+0.j]])
&gt;&gt;&gt; wa = LA.eigvalsh(a)
&gt;&gt;&gt; wb = LA.eigvals(b)
&gt;&gt;&gt; wa; wb
array([1., 6.])
array([6.+0.j, 1.+0.j])</pre> 
</div>
</div>
<a id="abf173287fe07b76a1128adee0fa3f9af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf173287fe07b76a1128adee0fa3f9af">&#9670;&nbsp;</a></span>inv()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.inv </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the inverse of a matrix.

Given a square matrix `a`, return the matrix `ainv` satisfying
``a @ ainv = ainv @ a = eye(a.shape[0])``.

Parameters
----------
a : (..., M, M) array_like
    Matrix to be inverted.

Returns
-------
ainv : (..., M, M) ndarray or matrix
    Inverse of the matrix `a`.

Raises
------
LinAlgError
    If `a` is not square or inversion fails.

See Also
--------
scipy.linalg.inv : Similar function in SciPy.
numpy.linalg.cond : Compute the condition number of a matrix.
numpy.linalg.svd : Compute the singular value decomposition of a matrix.

Notes
-----
Broadcasting rules apply, see the `numpy.linalg` documentation for
details.

If `a` is detected to be singular, a `LinAlgError` is raised. If `a` is
ill-conditioned, a `LinAlgError` may or may not be raised, and results may
be inaccurate due to floating-point errors.

References
----------
.. [1] Wikipedia, "Condition number",
       https://en.wikipedia.org/wiki/Condition_number

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy.linalg import inv
&gt;&gt;&gt; a = np.array([[1., 2.], [3., 4.]])
&gt;&gt;&gt; ainv = inv(a)
&gt;&gt;&gt; np.allclose(a @ ainv, np.eye(2))
True
&gt;&gt;&gt; np.allclose(ainv @ a, np.eye(2))
True

If a is a matrix object, then the return value is a matrix as well:

&gt;&gt;&gt; ainv = inv(np.matrix(a))
&gt;&gt;&gt; ainv
matrix([[-2. ,  1. ],
        [ 1.5, -0.5]])

Inverses of several matrices can be computed at once:

&gt;&gt;&gt; a = np.array([[[1., 2.], [3., 4.]], [[1, 3], [3, 5]]])
&gt;&gt;&gt; inv(a)
array([[[-2.  ,  1.  ],
        [ 1.5 , -0.5 ]],
       [[-1.25,  0.75],
        [ 0.75, -0.25]]])

If a matrix is close to singular, the computed inverse may not satisfy
``a @ ainv = ainv @ a = eye(a.shape[0])`` even if a `LinAlgError`
is not raised:

&gt;&gt;&gt; a = np.array([[2,4,6],[2,0,2],[6,8,14]])
&gt;&gt;&gt; inv(a)  # No errors raised
array([[-1.12589991e+15, -5.62949953e+14,  5.62949953e+14],
   [-1.12589991e+15, -5.62949953e+14,  5.62949953e+14],
   [ 1.12589991e+15,  5.62949953e+14, -5.62949953e+14]])
&gt;&gt;&gt; a @ inv(a)
array([[ 0.   , -0.5  ,  0.   ],  # may vary
       [-0.5  ,  0.625,  0.25 ],
       [ 0.   ,  0.   ,  1.   ]])

To detect ill-conditioned matrices, you can use `numpy.linalg.cond` to
compute its *condition number* [1]_. The larger the condition number, the
more ill-conditioned the matrix is. As a rule of thumb, if the condition
number ``cond(a) = 10**k``, then you may lose up to ``k`` digits of
accuracy on top of what would be lost to the numerical method due to loss
of precision from arithmetic methods.

&gt;&gt;&gt; from numpy.linalg import cond
&gt;&gt;&gt; cond(a)
np.float64(8.659885634118668e+17)  # may vary

It is also possible to detect ill-conditioning by inspecting the matrix's
singular values directly. The ratio between the largest and the smallest
singular value is the condition number:

&gt;&gt;&gt; from numpy.linalg import svd
&gt;&gt;&gt; sigma = svd(a, compute_uv=False)  # Do not compute singular vectors
&gt;&gt;&gt; sigma.max()/sigma.min()
8.659885634118668e+17  # may vary</pre> 
</div>
</div>
<a id="a83378a3701ceea528b2c327b8f256455"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83378a3701ceea528b2c327b8f256455">&#9670;&nbsp;</a></span>isComplexType()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.isComplexType </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a54b0b605bfcd7c2d118dcfbb0045f528"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54b0b605bfcd7c2d118dcfbb0045f528">&#9670;&nbsp;</a></span>lstsq()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.lstsq </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rcond</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return the least-squares solution to a linear matrix equation.

Computes the vector `x` that approximately solves the equation
``a @ x = b``. The equation may be under-, well-, or over-determined
(i.e., the number of linearly independent rows of `a` can be less than,
equal to, or greater than its number of linearly independent columns).
If `a` is square and of full rank, then `x` (but for round-off error)
is the "exact" solution of the equation. Else, `x` minimizes the
Euclidean 2-norm :math:`||b - ax||`. If there are multiple minimizing
solutions, the one with the smallest 2-norm :math:`||x||` is returned.

Parameters
----------
a : (M, N) array_like
    "Coefficient" matrix.
b : {(M,), (M, K)} array_like
    Ordinate or "dependent variable" values. If `b` is two-dimensional,
    the least-squares solution is calculated for each of the `K` columns
    of `b`.
rcond : float, optional
    Cut-off ratio for small singular values of `a`.
    For the purposes of rank determination, singular values are treated
    as zero if they are smaller than `rcond` times the largest singular
    value of `a`.
    The default uses the machine precision times ``max(M, N)``.  Passing
    ``-1`` will use machine precision.

    .. versionchanged:: 2.0
        Previously, the default was ``-1``, but a warning was given that
        this would change.

Returns
-------
x : {(N,), (N, K)} ndarray
    Least-squares solution. If `b` is two-dimensional,
    the solutions are in the `K` columns of `x`.
residuals : {(1,), (K,), (0,)} ndarray
    Sums of squared residuals: Squared Euclidean 2-norm for each column in
    ``b - a @ x``.
    If the rank of `a` is &lt; N or M &lt;= N, this is an empty array.
    If `b` is 1-dimensional, this is a (1,) shape array.
    Otherwise the shape is (K,).
rank : int
    Rank of matrix `a`.
s : (min(M, N),) ndarray
    Singular values of `a`.

Raises
------
LinAlgError
    If computation does not converge.

See Also
--------
scipy.linalg.lstsq : Similar function in SciPy.

Notes
-----
If `b` is a matrix, then all array results are returned as matrices.

Examples
--------
Fit a line, ``y = mx + c``, through some noisy data-points:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; x = np.array([0, 1, 2, 3])
&gt;&gt;&gt; y = np.array([-1, 0.2, 0.9, 2.1])

By examining the coefficients, we see that the line should have a
gradient of roughly 1 and cut the y-axis at, more or less, -1.

We can rewrite the line equation as ``y = Ap``, where ``A = [[x 1]]``
and ``p = [[m], [c]]``.  Now use `lstsq` to solve for `p`:

&gt;&gt;&gt; A = np.vstack([x, np.ones(len(x))]).T
&gt;&gt;&gt; A
array([[ 0.,  1.],
       [ 1.,  1.],
       [ 2.,  1.],
       [ 3.,  1.]])

&gt;&gt;&gt; m, c = np.linalg.lstsq(A, y)[0]
&gt;&gt;&gt; m, c
(1.0 -0.95) # may vary

Plot the data along with the fitted line:

&gt;&gt;&gt; import matplotlib.pyplot as plt
&gt;&gt;&gt; _ = plt.plot(x, y, 'o', label='Original data', markersize=10)
&gt;&gt;&gt; _ = plt.plot(x, m*x + c, 'r', label='Fitted line')
&gt;&gt;&gt; _ = plt.legend()
&gt;&gt;&gt; plt.show()</pre> 
</div>
</div>
<a id="a0e1543e0579f4fe645e2e794ade194c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e1543e0579f4fe645e2e794ade194c4">&#9670;&nbsp;</a></span>matmul()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.matmul </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x2</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Computes the matrix product.

This function is Array API compatible, contrary to
:func:`numpy.matmul`.

Parameters
----------
x1 : array_like
    The first input array.
x2 : array_like
    The second input array.

Returns
-------
out : ndarray
    The matrix product of the inputs.
    This is a scalar only when both ``x1``, ``x2`` are 1-d vectors.

Raises
------
ValueError
    If the last dimension of ``x1`` is not the same size as
    the second-to-last dimension of ``x2``.

    If a scalar value is passed in.

See Also
--------
numpy.matmul

Examples
--------
For 2-D arrays it is the matrix product:

&gt;&gt;&gt; a = np.array([[1, 0],
...               [0, 1]])
&gt;&gt;&gt; b = np.array([[4, 1],
...               [2, 2]])
&gt;&gt;&gt; np.linalg.matmul(a, b)
array([[4, 1],
       [2, 2]])

For 2-D mixed with 1-D, the result is the usual.

&gt;&gt;&gt; a = np.array([[1, 0],
...               [0, 1]])
&gt;&gt;&gt; b = np.array([1, 2])
&gt;&gt;&gt; np.linalg.matmul(a, b)
array([1, 2])
&gt;&gt;&gt; np.linalg.matmul(b, a)
array([1, 2])


Broadcasting is conventional for stacks of arrays

&gt;&gt;&gt; a = np.arange(2 * 2 * 4).reshape((2, 2, 4))
&gt;&gt;&gt; b = np.arange(2 * 2 * 4).reshape((2, 4, 2))
&gt;&gt;&gt; np.linalg.matmul(a,b).shape
(2, 2, 2)
&gt;&gt;&gt; np.linalg.matmul(a, b)[0, 1, 1]
98
&gt;&gt;&gt; sum(a[0, 1, :] * b[0 , :, 1])
98

Vector, vector returns the scalar inner product, but neither argument
is complex-conjugated:

&gt;&gt;&gt; np.linalg.matmul([2j, 3j], [2j, 3j])
(-13+0j)

Scalar multiplication raises an error.

&gt;&gt;&gt; np.linalg.matmul([1,2], 3)
Traceback (most recent call last):
...
ValueError: matmul: Input operand 1 does not have enough dimensions ...</pre> 
</div>
</div>
<a id="ad279b310c24e8038a3f3d162ca7bc32a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad279b310c24e8038a3f3d162ca7bc32a">&#9670;&nbsp;</a></span>matrix_norm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.matrix_norm </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>keepdims</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ord</em> = <code>&quot;fro&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Computes the matrix norm of a matrix (or a stack of matrices) ``x``.

This function is Array API compatible.

Parameters
----------
x : array_like
    Input array having shape (..., M, N) and whose two innermost
    dimensions form ``MxN`` matrices.
keepdims : bool, optional
    If this is set to True, the axes which are normed over are left in
    the result as dimensions with size one. Default: False.
ord : {1, -1, 2, -2, inf, -inf, 'fro', 'nuc'}, optional
    The order of the norm. For details see the table under ``Notes``
    in `numpy.linalg.norm`.

See Also
--------
numpy.linalg.norm : Generic norm function

Examples
--------
&gt;&gt;&gt; from numpy import linalg as LA
&gt;&gt;&gt; a = np.arange(9) - 4
&gt;&gt;&gt; a
array([-4, -3, -2, ...,  2,  3,  4])
&gt;&gt;&gt; b = a.reshape((3, 3))
&gt;&gt;&gt; b
array([[-4, -3, -2],
       [-1,  0,  1],
       [ 2,  3,  4]])

&gt;&gt;&gt; LA.matrix_norm(b)
7.745966692414834
&gt;&gt;&gt; LA.matrix_norm(b, ord='fro')
7.745966692414834
&gt;&gt;&gt; LA.matrix_norm(b, ord=np.inf)
9.0
&gt;&gt;&gt; LA.matrix_norm(b, ord=-np.inf)
2.0

&gt;&gt;&gt; LA.matrix_norm(b, ord=1)
7.0
&gt;&gt;&gt; LA.matrix_norm(b, ord=-1)
6.0
&gt;&gt;&gt; LA.matrix_norm(b, ord=2)
7.3484692283495345
&gt;&gt;&gt; LA.matrix_norm(b, ord=-2)
1.8570331885190563e-016 # may vary</pre> 
</div>
</div>
<a id="a53d6a3c96f633281c4e7f617aad30d80"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a53d6a3c96f633281c4e7f617aad30d80">&#9670;&nbsp;</a></span>matrix_power()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.matrix_power </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Raise a square matrix to the (integer) power `n`.

For positive integers `n`, the power is computed by repeated matrix
squarings and matrix multiplications. If ``n == 0``, the identity matrix
of the same shape as M is returned. If ``n &lt; 0``, the inverse
is computed and then raised to the ``abs(n)``.

.. note:: Stacks of object matrices are not currently supported.

Parameters
----------
a : (..., M, M) array_like
    Matrix to be "powered".
n : int
    The exponent can be any integer or long integer, positive,
    negative, or zero.

Returns
-------
a**n : (..., M, M) ndarray or matrix object
    The return value is the same shape and type as `M`;
    if the exponent is positive or zero then the type of the
    elements is the same as those of `M`. If the exponent is
    negative the elements are floating-point.

Raises
------
LinAlgError
    For matrices that are not square or that (for negative powers) cannot
    be inverted numerically.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy.linalg import matrix_power
&gt;&gt;&gt; i = np.array([[0, 1], [-1, 0]]) # matrix equiv. of the imaginary unit
&gt;&gt;&gt; matrix_power(i, 3) # should = -i
array([[ 0, -1],
       [ 1,  0]])
&gt;&gt;&gt; matrix_power(i, 0)
array([[1, 0],
       [0, 1]])
&gt;&gt;&gt; matrix_power(i, -3) # should = 1/(-i) = i, but w/ f.p. elements
array([[ 0.,  1.],
       [-1.,  0.]])

Somewhat more sophisticated example

&gt;&gt;&gt; q = np.zeros((4, 4))
&gt;&gt;&gt; q[0:2, 0:2] = -i
&gt;&gt;&gt; q[2:4, 2:4] = i
&gt;&gt;&gt; q # one of the three quaternion units not equal to 1
array([[ 0., -1.,  0.,  0.],
       [ 1.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  1.],
       [ 0.,  0., -1.,  0.]])
&gt;&gt;&gt; matrix_power(q, 2) # = -np.eye(4)
array([[-1.,  0.,  0.,  0.],
       [ 0., -1.,  0.,  0.],
       [ 0.,  0., -1.,  0.],
       [ 0.,  0.,  0., -1.]])</pre> 
</div>
</div>
<a id="a3898f651cd8501f3b6145f633128232c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3898f651cd8501f3b6145f633128232c">&#9670;&nbsp;</a></span>matrix_rank()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.matrix_rank </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>A</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tol</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hermitian</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>rtol</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Return matrix rank of array using SVD method

Rank of the array is the number of singular values of the array that are
greater than `tol`.

Parameters
----------
A : {(M,), (..., M, N)} array_like
    Input vector or stack of matrices.
tol : (...) array_like, float, optional
    Threshold below which SVD values are considered zero. If `tol` is
    None, and ``S`` is an array with singular values for `M`, and
    ``eps`` is the epsilon value for datatype of ``S``, then `tol` is
    set to ``S.max() * max(M, N) * eps``.
hermitian : bool, optional
    If True, `A` is assumed to be Hermitian (symmetric if real-valued),
    enabling a more efficient method for finding singular values.
    Defaults to False.
rtol : (...) array_like, float, optional
    Parameter for the relative tolerance component. Only ``tol`` or
    ``rtol`` can be set at a time. Defaults to ``max(M, N) * eps``.

    .. versionadded:: 2.0.0

Returns
-------
rank : (...) array_like
    Rank of A.

Notes
-----
The default threshold to detect rank deficiency is a test on the magnitude
of the singular values of `A`.  By default, we identify singular values
less than ``S.max() * max(M, N) * eps`` as indicating rank deficiency
(with the symbols defined above). This is the algorithm MATLAB uses [1].
It also appears in *Numerical recipes* in the discussion of SVD solutions
for linear least squares [2].

This default threshold is designed to detect rank deficiency accounting
for the numerical errors of the SVD computation. Imagine that there
is a column in `A` that is an exact (in floating point) linear combination
of other columns in `A`. Computing the SVD on `A` will not produce
a singular value exactly equal to 0 in general: any difference of
the smallest SVD value from 0 will be caused by numerical imprecision
in the calculation of the SVD. Our threshold for small SVD values takes
this numerical imprecision into account, and the default threshold will
detect such numerical rank deficiency. The threshold may declare a matrix
`A` rank deficient even if the linear combination of some columns of `A`
is not exactly equal to another column of `A` but only numerically very
close to another column of `A`.

We chose our default threshold because it is in wide use. Other thresholds
are possible.  For example, elsewhere in the 2007 edition of *Numerical
recipes* there is an alternative threshold of ``S.max() *
np.finfo(A.dtype).eps / 2. * np.sqrt(m + n + 1.)``. The authors describe
this threshold as being based on "expected roundoff error" (p 71).

The thresholds above deal with floating point roundoff error in the
calculation of the SVD.  However, you may have more information about
the sources of error in `A` that would make you consider other tolerance
values to detect *effective* rank deficiency. The most useful measure
of the tolerance depends on the operations you intend to use on your
matrix. For example, if your data come from uncertain measurements with
uncertainties greater than floating point epsilon, choosing a tolerance
near that uncertainty may be preferable. The tolerance may be absolute
if the uncertainties are absolute rather than relative.

References
----------
.. [1] MATLAB reference documentation, "Rank"
       https://www.mathworks.com/help/techdoc/ref/rank.html
.. [2] W. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery,
       "Numerical Recipes (3rd edition)", Cambridge University Press, 2007,
       page 795.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy.linalg import matrix_rank
&gt;&gt;&gt; matrix_rank(np.eye(4)) # Full rank matrix
4
&gt;&gt;&gt; I=np.eye(4); I[-1,-1] = 0. # rank deficient matrix
&gt;&gt;&gt; matrix_rank(I)
3
&gt;&gt;&gt; matrix_rank(np.ones((4,))) # 1 dimension - rank 1 unless all 0
1
&gt;&gt;&gt; matrix_rank(np.zeros((4,)))
0
</pre> 
</div>
</div>
<a id="af5f11e4f94009e163343d8ac8e77f03f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af5f11e4f94009e163343d8ac8e77f03f">&#9670;&nbsp;</a></span>matrix_transpose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.matrix_transpose </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a3740758ad45d6559a78a637417f9d3af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3740758ad45d6559a78a637417f9d3af">&#9670;&nbsp;</a></span>multi_dot()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.multi_dot </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>arrays</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>out</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the dot product of two or more arrays in a single function call,
while automatically selecting the fastest evaluation order.

`multi_dot` chains `numpy.dot` and uses optimal parenthesization
of the matrices [1]_ [2]_. Depending on the shapes of the matrices,
this can speed up the multiplication a lot.

If the first argument is 1-D it is treated as a row vector.
If the last argument is 1-D it is treated as a column vector.
The other arguments must be 2-D.

Think of `multi_dot` as::

    def multi_dot(arrays): return functools.reduce(np.dot, arrays)


Parameters
----------
arrays : sequence of array_like
    If the first argument is 1-D it is treated as row vector.
    If the last argument is 1-D it is treated as column vector.
    The other arguments must be 2-D.
out : ndarray, optional
    Output argument. This must have the exact kind that would be returned
    if it was not used. In particular, it must have the right type, must be
    C-contiguous, and its dtype must be the dtype that would be returned
    for `dot(a, b)`. This is a performance feature. Therefore, if these
    conditions are not met, an exception is raised, instead of attempting
    to be flexible.

Returns
-------
output : ndarray
    Returns the dot product of the supplied arrays.

See Also
--------
numpy.dot : dot multiplication with two arguments.

References
----------

.. [1] Cormen, "Introduction to Algorithms", Chapter 15.2, p. 370-378
.. [2] https://en.wikipedia.org/wiki/Matrix_chain_multiplication

Examples
--------
`multi_dot` allows you to write::

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy.linalg import multi_dot
&gt;&gt;&gt; # Prepare some data
&gt;&gt;&gt; A = np.random.random((10000, 100))
&gt;&gt;&gt; B = np.random.random((100, 1000))
&gt;&gt;&gt; C = np.random.random((1000, 5))
&gt;&gt;&gt; D = np.random.random((5, 333))
&gt;&gt;&gt; # the actual dot multiplication
&gt;&gt;&gt; _ = multi_dot([A, B, C, D])

instead of::

&gt;&gt;&gt; _ = np.dot(np.dot(np.dot(A, B), C), D)
&gt;&gt;&gt; # or
&gt;&gt;&gt; _ = A.dot(B).dot(C).dot(D)

Notes
-----
The cost for a matrix multiplication can be calculated with the
following function::

    def cost(A, B):
        return A.shape[0] * A.shape[1] * B.shape[1]

Assume we have three matrices
:math:`A_{10x100}, B_{100x5}, C_{5x50}`.

The costs for the two different parenthesizations are as follows::

    cost((AB)C) = 10*100*5 + 10*5*50   = 5000 + 2500   = 7500
    cost(A(BC)) = 10*100*50 + 100*5*50 = 50000 + 25000 = 75000</pre> 
</div>
</div>
<a id="ae667181925aa0b20a339f260a1c8fa9a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae667181925aa0b20a339f260a1c8fa9a">&#9670;&nbsp;</a></span>norm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.norm </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ord</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>axis</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>keepdims</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Matrix or vector norm.

This function is able to return one of eight different matrix norms,
or one of an infinite number of vector norms (described below), depending
on the value of the ``ord`` parameter.

Parameters
----------
x : array_like
    Input array.  If `axis` is None, `x` must be 1-D or 2-D, unless `ord`
    is None. If both `axis` and `ord` are None, the 2-norm of
    ``x.ravel`` will be returned.
ord : {int, float, inf, -inf, 'fro', 'nuc'}, optional
    Order of the norm (see table under ``Notes`` for what values are
    supported for matrices and vectors respectively). inf means numpy's
    `inf` object. The default is None.
axis : {None, int, 2-tuple of ints}, optional.
    If `axis` is an integer, it specifies the axis of `x` along which to
    compute the vector norms.  If `axis` is a 2-tuple, it specifies the
    axes that hold 2-D matrices, and the matrix norms of these matrices
    are computed.  If `axis` is None then either a vector norm (when `x`
    is 1-D) or a matrix norm (when `x` is 2-D) is returned. The default
    is None.

keepdims : bool, optional
    If this is set to True, the axes which are normed over are left in the
    result as dimensions with size one.  With this option the result will
    broadcast correctly against the original `x`.

Returns
-------
n : float or ndarray
    Norm of the matrix or vector(s).

See Also
--------
scipy.linalg.norm : Similar function in SciPy.

Notes
-----
For values of ``ord &lt; 1``, the result is, strictly speaking, not a
mathematical 'norm', but it may still be useful for various numerical
purposes.

The following norms can be calculated:

=====  ============================  ==========================
ord    norm for matrices             norm for vectors
=====  ============================  ==========================
None   Frobenius norm                2-norm
'fro'  Frobenius norm                --
'nuc'  nuclear norm                  --
inf    max(sum(abs(x), axis=1))      max(abs(x))
-inf   min(sum(abs(x), axis=1))      min(abs(x))
0      --                            sum(x != 0)
1      max(sum(abs(x), axis=0))      as below
-1     min(sum(abs(x), axis=0))      as below
2      2-norm (largest sing. value)  as below
-2     smallest singular value       as below
other  --                            sum(abs(x)**ord)**(1./ord)
=====  ============================  ==========================

The Frobenius norm is given by [1]_:

:math:`||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}`

The nuclear norm is the sum of the singular values.

Both the Frobenius and nuclear norm orders are only defined for
matrices and raise a ValueError when ``x.ndim != 2``.

References
----------
.. [1] G. H. Golub and C. F. Van Loan, *Matrix Computations*,
       Baltimore, MD, Johns Hopkins University Press, 1985, pg. 15

Examples
--------

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from numpy import linalg as LA
&gt;&gt;&gt; a = np.arange(9) - 4
&gt;&gt;&gt; a
array([-4, -3, -2, ...,  2,  3,  4])
&gt;&gt;&gt; b = a.reshape((3, 3))
&gt;&gt;&gt; b
array([[-4, -3, -2],
       [-1,  0,  1],
       [ 2,  3,  4]])

&gt;&gt;&gt; LA.norm(a)
7.745966692414834
&gt;&gt;&gt; LA.norm(b)
7.745966692414834
&gt;&gt;&gt; LA.norm(b, 'fro')
7.745966692414834
&gt;&gt;&gt; LA.norm(a, np.inf)
4.0
&gt;&gt;&gt; LA.norm(b, np.inf)
9.0
&gt;&gt;&gt; LA.norm(a, -np.inf)
0.0
&gt;&gt;&gt; LA.norm(b, -np.inf)
2.0

&gt;&gt;&gt; LA.norm(a, 1)
20.0
&gt;&gt;&gt; LA.norm(b, 1)
7.0
&gt;&gt;&gt; LA.norm(a, -1)
-4.6566128774142013e-010
&gt;&gt;&gt; LA.norm(b, -1)
6.0
&gt;&gt;&gt; LA.norm(a, 2)
7.745966692414834
&gt;&gt;&gt; LA.norm(b, 2)
7.3484692283495345

&gt;&gt;&gt; LA.norm(a, -2)
0.0
&gt;&gt;&gt; LA.norm(b, -2)
1.8570331885190563e-016 # may vary
&gt;&gt;&gt; LA.norm(a, 3)
5.8480354764257312 # may vary
&gt;&gt;&gt; LA.norm(a, -3)
0.0

Using the `axis` argument to compute vector norms:

&gt;&gt;&gt; c = np.array([[ 1, 2, 3],
...               [-1, 1, 4]])
&gt;&gt;&gt; LA.norm(c, axis=0)
array([ 1.41421356,  2.23606798,  5.        ])
&gt;&gt;&gt; LA.norm(c, axis=1)
array([ 3.74165739,  4.24264069])
&gt;&gt;&gt; LA.norm(c, ord=1, axis=1)
array([ 6.,  6.])

Using the `axis` argument to compute matrix norms:

&gt;&gt;&gt; m = np.arange(8).reshape(2,2,2)
&gt;&gt;&gt; LA.norm(m, axis=(1,2))
array([  3.74165739,  11.22497216])
&gt;&gt;&gt; LA.norm(m[0, :, :]), LA.norm(m[1, :, :])
(3.7416573867739413, 11.224972160321824)</pre> 
</div>
</div>
<a id="aa8e2c48125fe394c9e9b2ff5ce7fd59f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa8e2c48125fe394c9e9b2ff5ce7fd59f">&#9670;&nbsp;</a></span>outer()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.outer </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x2</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the outer product of two vectors.

This function is Array API compatible. Compared to ``np.outer``
it accepts 1-dimensional inputs only.

Parameters
----------
x1 : (M,) array_like
    One-dimensional input array of size ``N``.
    Must have a numeric data type.
x2 : (N,) array_like
    One-dimensional input array of size ``M``.
    Must have a numeric data type.

Returns
-------
out : (M, N) ndarray
    ``out[i, j] = a[i] * b[j]``

See also
--------
outer

Examples
--------
Make a (*very* coarse) grid for computing a Mandelbrot set:

&gt;&gt;&gt; rl = np.linalg.outer(np.ones((5,)), np.linspace(-2, 2, 5))
&gt;&gt;&gt; rl
array([[-2., -1.,  0.,  1.,  2.],
       [-2., -1.,  0.,  1.,  2.],
       [-2., -1.,  0.,  1.,  2.],
       [-2., -1.,  0.,  1.,  2.],
       [-2., -1.,  0.,  1.,  2.]])
&gt;&gt;&gt; im = np.linalg.outer(1j*np.linspace(2, -2, 5), np.ones((5,)))
&gt;&gt;&gt; im
array([[0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j, 0.+2.j],
       [0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j, 0.+1.j],
       [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],
       [0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j, 0.-1.j],
       [0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j, 0.-2.j]])
&gt;&gt;&gt; grid = rl + im
&gt;&gt;&gt; grid
array([[-2.+2.j, -1.+2.j,  0.+2.j,  1.+2.j,  2.+2.j],
       [-2.+1.j, -1.+1.j,  0.+1.j,  1.+1.j,  2.+1.j],
       [-2.+0.j, -1.+0.j,  0.+0.j,  1.+0.j,  2.+0.j],
       [-2.-1.j, -1.-1.j,  0.-1.j,  1.-1.j,  2.-1.j],
       [-2.-2.j, -1.-2.j,  0.-2.j,  1.-2.j,  2.-2.j]])

An example using a "vector" of letters:

&gt;&gt;&gt; x = np.array(['a', 'b', 'c'], dtype=object)
&gt;&gt;&gt; np.linalg.outer(x, [1, 2, 3])
array([['a', 'aa', 'aaa'],
       ['b', 'bb', 'bbb'],
       ['c', 'cc', 'ccc']], dtype=object)</pre> 
</div>
</div>
<a id="a4ca1647fbc15babda64de6ef161b685b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4ca1647fbc15babda64de6ef161b685b">&#9670;&nbsp;</a></span>pinv()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.pinv </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rcond</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hermitian</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>rtol</em> = <code>_NoValue</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the (Moore-Penrose) pseudo-inverse of a matrix.

Calculate the generalized inverse of a matrix using its
singular-value decomposition (SVD) and including all
*large* singular values.

Parameters
----------
a : (..., M, N) array_like
    Matrix or stack of matrices to be pseudo-inverted.
rcond : (...) array_like of float, optional
    Cutoff for small singular values.
    Singular values less than or equal to
    ``rcond * largest_singular_value`` are set to zero.
    Broadcasts against the stack of matrices. Default: ``1e-15``.
hermitian : bool, optional
    If True, `a` is assumed to be Hermitian (symmetric if real-valued),
    enabling a more efficient method for finding singular values.
    Defaults to False.
rtol : (...) array_like of float, optional
    Same as `rcond`, but it's an Array API compatible parameter name.
    Only `rcond` or `rtol` can be set at a time. If none of them are
    provided then NumPy's ``1e-15`` default is used. If ``rtol=None``
    is passed then the API standard default is used.

    .. versionadded:: 2.0.0

Returns
-------
B : (..., N, M) ndarray
    The pseudo-inverse of `a`. If `a` is a `matrix` instance, then so
    is `B`.

Raises
------
LinAlgError
    If the SVD computation does not converge.

See Also
--------
scipy.linalg.pinv : Similar function in SciPy.
scipy.linalg.pinvh : Compute the (Moore-Penrose) pseudo-inverse of a
                     Hermitian matrix.

Notes
-----
The pseudo-inverse of a matrix A, denoted :math:`A^+`, is
defined as: "the matrix that 'solves' [the least-squares problem]
:math:`Ax = b`," i.e., if :math:`\\bar{x}` is said solution, then
:math:`A^+` is that matrix such that :math:`\\bar{x} = A^+b`.

It can be shown that if :math:`Q_1 \\Sigma Q_2^T = A` is the singular
value decomposition of A, then
:math:`A^+ = Q_2 \\Sigma^+ Q_1^T`, where :math:`Q_{1,2}` are
orthogonal matrices, :math:`\\Sigma` is a diagonal matrix consisting
of A's so-called singular values, (followed, typically, by
zeros), and then :math:`\\Sigma^+` is simply the diagonal matrix
consisting of the reciprocals of A's singular values
(again, followed by zeros). [1]_

References
----------
.. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,
       FL, Academic Press, Inc., 1980, pp. 139-142.

Examples
--------
The following example checks that ``a * a+ * a == a`` and
``a+ * a * a+ == a+``:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; a = rng.normal(size=(9, 6))
&gt;&gt;&gt; B = np.linalg.pinv(a)
&gt;&gt;&gt; np.allclose(a, np.dot(a, np.dot(B, a)))
True
&gt;&gt;&gt; np.allclose(B, np.dot(B, np.dot(a, B)))
True</pre> 
</div>
</div>
<a id="a3f8cebf7494f653e022ba25a732d8fa6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3f8cebf7494f653e022ba25a732d8fa6">&#9670;&nbsp;</a></span>qr()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.qr </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mode</em> = <code>'reduced'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the qr factorization of a matrix.

Factor the matrix `a` as *qr*, where `q` is orthonormal and `r` is
upper-triangular.

Parameters
----------
a : array_like, shape (..., M, N)
    An array-like object with the dimensionality of at least 2.
mode : {'reduced', 'complete', 'r', 'raw'}, optional, default: 'reduced'
    If K = min(M, N), then

    * 'reduced'  : returns Q, R with dimensions (..., M, K), (..., K, N)
    * 'complete' : returns Q, R with dimensions (..., M, M), (..., M, N)
    * 'r'        : returns R only with dimensions (..., K, N)
    * 'raw'      : returns h, tau with dimensions (..., N, M), (..., K,)

    The options 'reduced', 'complete, and 'raw' are new in numpy 1.8,
    see the notes for more information. The default is 'reduced', and to
    maintain backward compatibility with earlier versions of numpy both
    it and the old default 'full' can be omitted. Note that array h
    returned in 'raw' mode is transposed for calling Fortran. The
    'economic' mode is deprecated.  The modes 'full' and 'economic' may
    be passed using only the first letter for backwards compatibility,
    but all others must be spelled out. See the Notes for more
    explanation.


Returns
-------
When mode is 'reduced' or 'complete', the result will be a namedtuple with
the attributes `Q` and `R`.

Q : ndarray of float or complex, optional
    A matrix with orthonormal columns. When mode = 'complete' the
    result is an orthogonal/unitary matrix depending on whether or not
    a is real/complex. The determinant may be either +/- 1 in that
    case. In case the number of dimensions in the input array is
    greater than 2 then a stack of the matrices with above properties
    is returned.
R : ndarray of float or complex, optional
    The upper-triangular matrix or a stack of upper-triangular
    matrices if the number of dimensions in the input array is greater
    than 2.
(h, tau) : ndarrays of np.double or np.cdouble, optional
    The array h contains the Householder reflectors that generate q
    along with r. The tau array contains scaling factors for the
    reflectors. In the deprecated  'economic' mode only h is returned.

Raises
------
LinAlgError
    If factoring fails.

See Also
--------
scipy.linalg.qr : Similar function in SciPy.
scipy.linalg.rq : Compute RQ decomposition of a matrix.

Notes
-----
This is an interface to the LAPACK routines ``dgeqrf``, ``zgeqrf``,
``dorgqr``, and ``zungqr``.

For more information on the qr factorization, see for example:
https://en.wikipedia.org/wiki/QR_factorization

Subclasses of `ndarray` are preserved except for the 'raw' mode. So if
`a` is of type `matrix`, all the return values will be matrices too.

New 'reduced', 'complete', and 'raw' options for mode were added in
NumPy 1.8.0 and the old option 'full' was made an alias of 'reduced'.  In
addition the options 'full' and 'economic' were deprecated.  Because
'full' was the previous default and 'reduced' is the new default,
backward compatibility can be maintained by letting `mode` default.
The 'raw' option was added so that LAPACK routines that can multiply
arrays by q using the Householder reflectors can be used. Note that in
this case the returned arrays are of type np.double or np.cdouble and
the h array is transposed to be FORTRAN compatible.  No routines using
the 'raw' return are currently exposed by numpy, but some are available
in lapack_lite and just await the necessary work.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; a = rng.normal(size=(9, 6))
&gt;&gt;&gt; Q, R = np.linalg.qr(a)
&gt;&gt;&gt; np.allclose(a, np.dot(Q, R))  # a does equal QR
True
&gt;&gt;&gt; R2 = np.linalg.qr(a, mode='r')
&gt;&gt;&gt; np.allclose(R, R2)  # mode='r' returns the same R as mode='full'
True
&gt;&gt;&gt; a = np.random.normal(size=(3, 2, 2)) # Stack of 2 x 2 matrices as input
&gt;&gt;&gt; Q, R = np.linalg.qr(a)
&gt;&gt;&gt; Q.shape
(3, 2, 2)
&gt;&gt;&gt; R.shape
(3, 2, 2)
&gt;&gt;&gt; np.allclose(a, np.matmul(Q, R))
True

Example illustrating a common use of `qr`: solving of least squares
problems

What are the least-squares-best `m` and `y0` in ``y = y0 + mx`` for
the following data: {(0,1), (1,0), (1,2), (2,1)}. (Graph the points
and you'll see that it should be y0 = 0, m = 1.)  The answer is provided
by solving the over-determined matrix equation ``Ax = b``, where::

  A = array([[0, 1], [1, 1], [1, 1], [2, 1]])
  x = array([[y0], [m]])
  b = array([[1], [0], [2], [1]])

If A = QR such that Q is orthonormal (which is always possible via
Gram-Schmidt), then ``x = inv(R) * (Q.T) * b``.  (In numpy practice,
however, we simply use `lstsq`.)

&gt;&gt;&gt; A = np.array([[0, 1], [1, 1], [1, 1], [2, 1]])
&gt;&gt;&gt; A
array([[0, 1],
       [1, 1],
       [1, 1],
       [2, 1]])
&gt;&gt;&gt; b = np.array([1, 2, 2, 3])
&gt;&gt;&gt; Q, R = np.linalg.qr(A)
&gt;&gt;&gt; p = np.dot(Q.T, b)
&gt;&gt;&gt; np.dot(np.linalg.inv(R), p)
array([  1.,   1.])</pre> 
</div>
</div>
<a id="a9bc9be05b4b2a9bfd463b7803f653299"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9bc9be05b4b2a9bfd463b7803f653299">&#9670;&nbsp;</a></span>slogdet()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.slogdet </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the sign and (natural) logarithm of the determinant of an array.

If an array has a very small or very large determinant, then a call to
`det` may overflow or underflow. This routine is more robust against such
issues, because it computes the logarithm of the determinant rather than
the determinant itself.

Parameters
----------
a : (..., M, M) array_like
    Input array, has to be a square 2-D array.

Returns
-------
A namedtuple with the following attributes:

sign : (...) array_like
    A number representing the sign of the determinant. For a real matrix,
    this is 1, 0, or -1. For a complex matrix, this is a complex number
    with absolute value 1 (i.e., it is on the unit circle), or else 0.
logabsdet : (...) array_like
    The natural log of the absolute value of the determinant.

If the determinant is zero, then `sign` will be 0 and `logabsdet`
will be -inf. In all cases, the determinant is equal to
``sign * np.exp(logabsdet)``.

See Also
--------
det

Notes
-----
Broadcasting rules apply, see the `numpy.linalg` documentation for
details.

The determinant is computed via LU factorization using the LAPACK
routine ``z/dgetrf``.

Examples
--------
The determinant of a 2-D array ``[[a, b], [c, d]]`` is ``ad - bc``:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.array([[1, 2], [3, 4]])
&gt;&gt;&gt; (sign, logabsdet) = np.linalg.slogdet(a)
&gt;&gt;&gt; (sign, logabsdet)
(-1, 0.69314718055994529) # may vary
&gt;&gt;&gt; sign * np.exp(logabsdet)
-2.0

Computing log-determinants for a stack of matrices:

&gt;&gt;&gt; a = np.array([ [[1, 2], [3, 4]], [[1, 2], [2, 1]], [[1, 3], [3, 1]] ])
&gt;&gt;&gt; a.shape
(3, 2, 2)
&gt;&gt;&gt; sign, logabsdet = np.linalg.slogdet(a)
&gt;&gt;&gt; (sign, logabsdet)
(array([-1., -1., -1.]), array([ 0.69314718,  1.09861229,  2.07944154]))
&gt;&gt;&gt; sign * np.exp(logabsdet)
array([-2., -3., -8.])

This routine succeeds where ordinary `det` does not:

&gt;&gt;&gt; np.linalg.det(np.eye(500) * 0.1)
0.0
&gt;&gt;&gt; np.linalg.slogdet(np.eye(500) * 0.1)
(1, -1151.2925464970228)</pre> 
</div>
</div>
<a id="a0065bff134b26388efc6de907132c989"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0065bff134b26388efc6de907132c989">&#9670;&nbsp;</a></span>solve()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.solve </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Solve a linear matrix equation, or system of linear scalar equations.

Computes the "exact" solution, `x`, of the well-determined, i.e., full
rank, linear matrix equation `ax = b`.

Parameters
----------
a : (..., M, M) array_like
    Coefficient matrix.
b : {(M,), (..., M, K)}, array_like
    Ordinate or "dependent variable" values.

Returns
-------
x : {(..., M,), (..., M, K)} ndarray
    Solution to the system a x = b.  Returned shape is (..., M) if b is
    shape (M,) and (..., M, K) if b is (..., M, K), where the "..." part is
    broadcasted between a and b.

Raises
------
LinAlgError
    If `a` is singular or not square.

See Also
--------
scipy.linalg.solve : Similar function in SciPy.

Notes
-----
Broadcasting rules apply, see the `numpy.linalg` documentation for
details.

The solutions are computed using LAPACK routine ``_gesv``.

`a` must be square and of full-rank, i.e., all rows (or, equivalently,
columns) must be linearly independent; if either is not true, use
`lstsq` for the least-squares best "solution" of the
system/equation.

.. versionchanged:: 2.0

   The b array is only treated as a shape (M,) column vector if it is
   exactly 1-dimensional. In all other instances it is treated as a stack
   of (M, K) matrices. Previously b would be treated as a stack of (M,)
   vectors if b.ndim was equal to a.ndim - 1.

References
----------
.. [1] G. Strang, *Linear Algebra and Its Applications*, 2nd Ed., Orlando,
       FL, Academic Press, Inc., 1980, pg. 22.

Examples
--------
Solve the system of equations:
``x0 + 2 * x1 = 1`` and
``3 * x0 + 5 * x1 = 2``:

&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.array([[1, 2], [3, 5]])
&gt;&gt;&gt; b = np.array([1, 2])
&gt;&gt;&gt; x = np.linalg.solve(a, b)
&gt;&gt;&gt; x
array([-1.,  1.])

Check that the solution is correct:

&gt;&gt;&gt; np.allclose(np.dot(a, x), b)
True</pre> 
</div>
</div>
<a id="a28cf54df726b6cde636297a0bfbfa28a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a28cf54df726b6cde636297a0bfbfa28a">&#9670;&nbsp;</a></span>svd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.svd </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>full_matrices</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>compute_uv</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>hermitian</em> = <code>False</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Singular Value Decomposition.

When `a` is a 2D array, and ``full_matrices=False``, then it is
factorized as ``u @ np.diag(s) @ vh = (u * s) @ vh``, where
`u` and the Hermitian transpose of `vh` are 2D arrays with
orthonormal columns and `s` is a 1D array of `a`'s singular
values. When `a` is higher-dimensional, SVD is applied in
stacked mode as explained below.

Parameters
----------
a : (..., M, N) array_like
    A real or complex array with ``a.ndim &gt;= 2``.
full_matrices : bool, optional
    If True (default), `u` and `vh` have the shapes ``(..., M, M)`` and
    ``(..., N, N)``, respectively.  Otherwise, the shapes are
    ``(..., M, K)`` and ``(..., K, N)``, respectively, where
    ``K = min(M, N)``.
compute_uv : bool, optional
    Whether or not to compute `u` and `vh` in addition to `s`.  True
    by default.
hermitian : bool, optional
    If True, `a` is assumed to be Hermitian (symmetric if real-valued),
    enabling a more efficient method for finding singular values.
    Defaults to False.

Returns
-------
When `compute_uv` is True, the result is a namedtuple with the following
attribute names:

U : { (..., M, M), (..., M, K) } array
    Unitary array(s). The first ``a.ndim - 2`` dimensions have the same
    size as those of the input `a`. The size of the last two dimensions
    depends on the value of `full_matrices`. Only returned when
    `compute_uv` is True.
S : (..., K) array
    Vector(s) with the singular values, within each vector sorted in
    descending order. The first ``a.ndim - 2`` dimensions have the same
    size as those of the input `a`.
Vh : { (..., N, N), (..., K, N) } array
    Unitary array(s). The first ``a.ndim - 2`` dimensions have the same
    size as those of the input `a`. The size of the last two dimensions
    depends on the value of `full_matrices`. Only returned when
    `compute_uv` is True.

Raises
------
LinAlgError
    If SVD computation does not converge.

See Also
--------
scipy.linalg.svd : Similar function in SciPy.
scipy.linalg.svdvals : Compute singular values of a matrix.

Notes
-----
The decomposition is performed using LAPACK routine ``_gesdd``.

SVD is usually described for the factorization of a 2D matrix :math:`A`.
The higher-dimensional case will be discussed below. In the 2D case, SVD is
written as :math:`A = U S V^H`, where :math:`A = a`, :math:`U= u`,
:math:`S= \\mathtt{np.diag}(s)` and :math:`V^H = vh`. The 1D array `s`
contains the singular values of `a` and `u` and `vh` are unitary. The rows
of `vh` are the eigenvectors of :math:`A^H A` and the columns of `u` are
the eigenvectors of :math:`A A^H`. In both cases the corresponding
(possibly non-zero) eigenvalues are given by ``s**2``.

If `a` has more than two dimensions, then broadcasting rules apply, as
explained in :ref:`routines.linalg-broadcasting`. This means that SVD is
working in "stacked" mode: it iterates over all indices of the first
``a.ndim - 2`` dimensions and for each combination SVD is applied to the
last two indices. The matrix `a` can be reconstructed from the
decomposition with either ``(u * s[..., None, :]) @ vh`` or
``u @ (s[..., None] * vh)``. (The ``@`` operator can be replaced by the
function ``np.matmul`` for python versions below 3.5.)

If `a` is a ``matrix`` object (as opposed to an ``ndarray``), then so are
all the return values.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; a = rng.normal(size=(9, 6)) + 1j*rng.normal(size=(9, 6))
&gt;&gt;&gt; b = rng.normal(size=(2, 7, 8, 3)) + 1j*rng.normal(size=(2, 7, 8, 3))


Reconstruction based on full SVD, 2D case:

&gt;&gt;&gt; U, S, Vh = np.linalg.svd(a, full_matrices=True)
&gt;&gt;&gt; U.shape, S.shape, Vh.shape
((9, 9), (6,), (6, 6))
&gt;&gt;&gt; np.allclose(a, np.dot(U[:, :6] * S, Vh))
True
&gt;&gt;&gt; smat = np.zeros((9, 6), dtype=complex)
&gt;&gt;&gt; smat[:6, :6] = np.diag(S)
&gt;&gt;&gt; np.allclose(a, np.dot(U, np.dot(smat, Vh)))
True

Reconstruction based on reduced SVD, 2D case:

&gt;&gt;&gt; U, S, Vh = np.linalg.svd(a, full_matrices=False)
&gt;&gt;&gt; U.shape, S.shape, Vh.shape
((9, 6), (6,), (6, 6))
&gt;&gt;&gt; np.allclose(a, np.dot(U * S, Vh))
True
&gt;&gt;&gt; smat = np.diag(S)
&gt;&gt;&gt; np.allclose(a, np.dot(U, np.dot(smat, Vh)))
True

Reconstruction based on full SVD, 4D case:

&gt;&gt;&gt; U, S, Vh = np.linalg.svd(b, full_matrices=True)
&gt;&gt;&gt; U.shape, S.shape, Vh.shape
((2, 7, 8, 8), (2, 7, 3), (2, 7, 3, 3))
&gt;&gt;&gt; np.allclose(b, np.matmul(U[..., :3] * S[..., None, :], Vh))
True
&gt;&gt;&gt; np.allclose(b, np.matmul(U[..., :3], S[..., None] * Vh))
True

Reconstruction based on reduced SVD, 4D case:

&gt;&gt;&gt; U, S, Vh = np.linalg.svd(b, full_matrices=False)
&gt;&gt;&gt; U.shape, S.shape, Vh.shape
((2, 7, 8, 3), (2, 7, 3), (2, 7, 3, 3))
&gt;&gt;&gt; np.allclose(b, np.matmul(U * S[..., None, :], Vh))
True
&gt;&gt;&gt; np.allclose(b, np.matmul(U, S[..., None] * Vh))
True</pre> 
</div>
</div>
<a id="a1c81ef0245eedd325880bcae43dba031"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c81ef0245eedd325880bcae43dba031">&#9670;&nbsp;</a></span>svdvals()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.svdvals </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the singular values of a matrix (or a stack of matrices) ``x``.
When x is a stack of matrices, the function will compute the singular
values for each matrix in the stack.

This function is Array API compatible.

Calling ``np.svdvals(x)`` to get singular values is the same as
``np.svd(x, compute_uv=False, hermitian=False)``.

Parameters
----------
x : (..., M, N) array_like
    Input array having shape (..., M, N) and whose last two
    dimensions form matrices on which to perform singular value
    decomposition. Should have a floating-point data type.

Returns
-------
out : ndarray
    An array with shape (..., K) that contains the vector(s)
    of singular values of length K, where K = min(M, N).

See Also
--------
scipy.linalg.svdvals : Compute singular values of a matrix.

Examples
--------

&gt;&gt;&gt; np.linalg.svdvals([[1, 2, 3, 4, 5],
...                    [1, 4, 9, 16, 25],
...                    [1, 8, 27, 64, 125]])
array([146.68862757,   5.57510612,   0.60393245])

Determine the rank of a matrix using singular values:

&gt;&gt;&gt; s = np.linalg.svdvals([[1, 2, 3],
...                        [2, 4, 6],
...                        [-1, 1, -1]]); s
array([8.38434191e+00, 1.64402274e+00, 2.31534378e-16])
&gt;&gt;&gt; np.count_nonzero(s &gt; 1e-10)  # Matrix of rank 2
2</pre> 
</div>
</div>
<a id="ad2a2becf79fdc487aa3fede24ae13a53"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad2a2becf79fdc487aa3fede24ae13a53">&#9670;&nbsp;</a></span>tensordot()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.tensordot </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>axes</em> = <code>2</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="afb1b6124622937662eada2571aab934d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afb1b6124622937662eada2571aab934d">&#9670;&nbsp;</a></span>tensorinv()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.tensorinv </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ind</em> = <code>2</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute the 'inverse' of an N-dimensional array.

The result is an inverse for `a` relative to the tensordot operation
``tensordot(a, b, ind)``, i. e., up to floating-point accuracy,
``tensordot(tensorinv(a), a, ind)`` is the "identity" tensor for the
tensordot operation.

Parameters
----------
a : array_like
    Tensor to 'invert'. Its shape must be 'square', i. e.,
    ``prod(a.shape[:ind]) == prod(a.shape[ind:])``.
ind : int, optional
    Number of first indices that are involved in the inverse sum.
    Must be a positive integer, default is 2.

Returns
-------
b : ndarray
    `a`'s tensordot inverse, shape ``a.shape[ind:] + a.shape[:ind]``.

Raises
------
LinAlgError
    If `a` is singular or not 'square' (in the above sense).

See Also
--------
numpy.tensordot, tensorsolve

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.eye(4*6)
&gt;&gt;&gt; a.shape = (4, 6, 8, 3)
&gt;&gt;&gt; ainv = np.linalg.tensorinv(a, ind=2)
&gt;&gt;&gt; ainv.shape
(8, 3, 4, 6)
&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; b = rng.normal(size=(4, 6))
&gt;&gt;&gt; np.allclose(np.tensordot(ainv, b), np.linalg.tensorsolve(a, b))
True

&gt;&gt;&gt; a = np.eye(4*6)
&gt;&gt;&gt; a.shape = (24, 8, 3)
&gt;&gt;&gt; ainv = np.linalg.tensorinv(a, ind=1)
&gt;&gt;&gt; ainv.shape
(8, 3, 24)
&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; b = rng.normal(size=24)
&gt;&gt;&gt; np.allclose(np.tensordot(ainv, b, 1), np.linalg.tensorsolve(a, b))
True</pre> 
</div>
</div>
<a id="a7791600aa8ed4f3cbacd8508f8488725"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7791600aa8ed4f3cbacd8508f8488725">&#9670;&nbsp;</a></span>tensorsolve()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.tensorsolve </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>b</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>axes</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Solve the tensor equation ``a x = b`` for x.

It is assumed that all indices of `x` are summed over in the product,
together with the rightmost indices of `a`, as is done in, for example,
``tensordot(a, x, axes=x.ndim)``.

Parameters
----------
a : array_like
    Coefficient tensor, of shape ``b.shape + Q``. `Q`, a tuple, equals
    the shape of that sub-tensor of `a` consisting of the appropriate
    number of its rightmost indices, and must be such that
    ``prod(Q) == prod(b.shape)`` (in which sense `a` is said to be
    'square').
b : array_like
    Right-hand tensor, which can be of any shape.
axes : tuple of ints, optional
    Axes in `a` to reorder to the right, before inversion.
    If None (default), no reordering is done.

Returns
-------
x : ndarray, shape Q

Raises
------
LinAlgError
    If `a` is singular or not 'square' (in the above sense).

See Also
--------
numpy.tensordot, tensorinv, numpy.einsum

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.eye(2*3*4)
&gt;&gt;&gt; a.shape = (2*3, 4, 2, 3, 4)
&gt;&gt;&gt; rng = np.random.default_rng()
&gt;&gt;&gt; b = rng.normal(size=(2*3, 4))
&gt;&gt;&gt; x = np.linalg.tensorsolve(a, b)
&gt;&gt;&gt; x.shape
(2, 3, 4)
&gt;&gt;&gt; np.allclose(np.tensordot(a, x, axes=3), b)
True</pre> 
</div>
</div>
<a id="a4d908f18674aa60b92020060fed52b2b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4d908f18674aa60b92020060fed52b2b">&#9670;&nbsp;</a></span>trace()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.trace </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>offset</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the sum along the specified diagonals of a matrix
(or a stack of matrices) ``x``.

This function is Array API compatible, contrary to
:py:func:`numpy.trace`.

Parameters
----------
x : (...,M,N) array_like
    Input array having shape (..., M, N) and whose innermost two
    dimensions form MxN matrices.
offset : int, optional
    Offset specifying the off-diagonal relative to the main diagonal,
    where::

        * offset = 0: the main diagonal.
        * offset &gt; 0: off-diagonal above the main diagonal.
        * offset &lt; 0: off-diagonal below the main diagonal.

dtype : dtype, optional
    Data type of the returned array.

Returns
-------
out : ndarray
    An array containing the traces and whose shape is determined by
    removing the last two dimensions and storing the traces in the last
    array dimension. For example, if x has rank k and shape:
    (I, J, K, ..., L, M, N), then an output array has rank k-2 and shape:
    (I, J, K, ..., L) where::

        out[i, j, k, ..., l] = trace(a[i, j, k, ..., l, :, :])

    The returned array must have a data type as described by the dtype
    parameter above.

See Also
--------
numpy.trace

Examples
--------
&gt;&gt;&gt; np.linalg.trace(np.eye(3))
3.0
&gt;&gt;&gt; a = np.arange(8).reshape((2, 2, 2))
&gt;&gt;&gt; np.linalg.trace(a)
array([3, 11])

Trace is computed with the last two axes as the 2-d sub-arrays.
This behavior differs from :py:func:`numpy.trace` which uses the first two
axes by default.

&gt;&gt;&gt; a = np.arange(24).reshape((3, 2, 2, 2))
&gt;&gt;&gt; np.linalg.trace(a).shape
(3, 2)

Traces adjacent to the main diagonal can be obtained by using the
`offset` argument:

&gt;&gt;&gt; a = np.arange(9).reshape((3, 3)); a
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])
&gt;&gt;&gt; np.linalg.trace(a, offset=1)  # First superdiagonal
6
&gt;&gt;&gt; np.linalg.trace(a, offset=2)  # Second superdiagonal
2
&gt;&gt;&gt; np.linalg.trace(a, offset=-1)  # First subdiagonal
10
&gt;&gt;&gt; np.linalg.trace(a, offset=-2)  # Second subdiagonal
6</pre> 
</div>
</div>
<a id="a995d7a81586bad8eaabaa46f56f90598"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a995d7a81586bad8eaabaa46f56f90598">&#9670;&nbsp;</a></span>transpose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.transpose </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Transpose each matrix in a stack of matrices.

Unlike np.transpose, this only swaps the last two axes, rather than all of
them

Parameters
----------
a : (...,M,N) array_like

Returns
-------
aT : (...,N,M) ndarray
</pre> 
</div>
</div>
<a id="a862848fe7a4c54757819cbadd31efbb9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a862848fe7a4c54757819cbadd31efbb9">&#9670;&nbsp;</a></span>vecdot()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.vecdot </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>axis</em> = <code>-1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Computes the vector dot product.

This function is restricted to arguments compatible with the Array API,
contrary to :func:`numpy.vecdot`.

Let :math:`\\mathbf{a}` be a vector in ``x1`` and :math:`\\mathbf{b}` be
a corresponding vector in ``x2``. The dot product is defined as:

.. math::
   \\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=0}^{n-1} \\overline{a_i}b_i

over the dimension specified by ``axis`` and where :math:`\\overline{a_i}`
denotes the complex conjugate if :math:`a_i` is complex and the identity
otherwise.

Parameters
----------
x1 : array_like
    First input array.
x2 : array_like
    Second input array.
axis : int, optional
    Axis over which to compute the dot product. Default: ``-1``.

Returns
-------
output : ndarray
    The vector dot product of the input.

See Also
--------
numpy.vecdot

Examples
--------
Get the projected size along a given normal for an array of vectors.

&gt;&gt;&gt; v = np.array([[0., 5., 0.], [0., 0., 10.], [0., 6., 8.]])
&gt;&gt;&gt; n = np.array([0., 0.6, 0.8])
&gt;&gt;&gt; np.linalg.vecdot(v, n)
array([ 3.,  8., 10.])</pre> 
</div>
</div>
<a id="a9d3023ec0d4ea51069999a1056e44970"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9d3023ec0d4ea51069999a1056e44970">&#9670;&nbsp;</a></span>vector_norm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def numpy.linalg._linalg.vector_norm </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">*&#160;</td>
          <td class="paramname"><em>axis</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>keepdims</em> = <code>False</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ord</em> = <code>2</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Computes the vector norm of a vector (or batch of vectors) ``x``.

This function is Array API compatible.

Parameters
----------
x : array_like
    Input array.
axis : {None, int, 2-tuple of ints}, optional
    If an integer, ``axis`` specifies the axis (dimension) along which
    to compute vector norms. If an n-tuple, ``axis`` specifies the axes
    (dimensions) along which to compute batched vector norms. If ``None``,
    the vector norm must be computed over all array values (i.e.,
    equivalent to computing the vector norm of a flattened array).
    Default: ``None``.
keepdims : bool, optional
    If this is set to True, the axes which are normed over are left in
    the result as dimensions with size one. Default: False.
ord : {int, float, inf, -inf}, optional
    The order of the norm. For details see the table under ``Notes``
    in `numpy.linalg.norm`.

See Also
--------
numpy.linalg.norm : Generic norm function

Examples
--------
&gt;&gt;&gt; from numpy import linalg as LA
&gt;&gt;&gt; a = np.arange(9) + 1
&gt;&gt;&gt; a
array([1, 2, 3, 4, 5, 6, 7, 8, 9])
&gt;&gt;&gt; b = a.reshape((3, 3))
&gt;&gt;&gt; b
array([[1, 2, 3],
       [4, 5, 6],
       [7, 8, 9]])

&gt;&gt;&gt; LA.vector_norm(b)
16.881943016134134
&gt;&gt;&gt; LA.vector_norm(b, ord=np.inf)
9.0
&gt;&gt;&gt; LA.vector_norm(b, ord=-np.inf)
1.0

&gt;&gt;&gt; LA.vector_norm(b, ord=0)
9.0
&gt;&gt;&gt; LA.vector_norm(b, ord=1)
45.0
&gt;&gt;&gt; LA.vector_norm(b, ord=-1)
0.3534857623790153
&gt;&gt;&gt; LA.vector_norm(b, ord=2)
16.881943016134134
&gt;&gt;&gt; LA.vector_norm(b, ord=-2)
0.8058837395885292</pre> 
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a0882dc90edbc29418c3a42c1d3c1d6d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0882dc90edbc29418c3a42c1d3c1d6d8">&#9670;&nbsp;</a></span>array_function_dispatch</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">numpy.linalg._linalg.array_function_dispatch</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;=  functools.partial(</div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;    overrides.array_function_dispatch, module=<span class="stringliteral">&#39;numpy.linalg&#39;</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;)</div>
</div><!-- fragment -->
</div>
</div>
<a id="ad9473eaede4ac4db2f5a8d23c07caf56"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad9473eaede4ac4db2f5a8d23c07caf56">&#9670;&nbsp;</a></span>fortran_int</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">numpy.linalg._linalg.fortran_int = intc</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
