<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: langchain_core.caches.BaseCache Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacelangchain__core.html">langchain_core</a></li><li class="navelem"><a class="el" href="namespacelangchain__core_1_1caches.html">caches</a></li><li class="navelem"><a class="el" href="classlangchain__core_1_1caches_1_1BaseCache.html">BaseCache</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classlangchain__core_1_1caches_1_1BaseCache-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">langchain_core.caches.BaseCache Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for langchain_core.caches.BaseCache:</div>
<div class="dyncontent">
<div class="center"><img src="classlangchain__core_1_1caches_1_1BaseCache__inherit__graph.png" border="0" usemap="#alangchain__core_8caches_8BaseCache_inherit__map" alt="Inheritance graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for langchain_core.caches.BaseCache:</div>
<div class="dyncontent">
<div class="center"><img src="classlangchain__core_1_1caches_1_1BaseCache__coll__graph.png" border="0" usemap="#alangchain__core_8caches_8BaseCache_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 1 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a063a47e2ffb6060b79eaf00c51adbf11"><td class="memItemLeft" align="right" valign="top">Optional[<a class="el" href="namespacelangchain__core_1_1caches.html#aa3548903541b6ec37ba799f25639db3e">RETURN_VAL_TYPE</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1caches_1_1BaseCache.html#a063a47e2ffb6060b79eaf00c51adbf11">lookup</a> (self, str prompt, str llm_string)</td></tr>
<tr class="separator:a063a47e2ffb6060b79eaf00c51adbf11"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3335c1a4ea4d7eb89c6cb586700fadf5"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1caches_1_1BaseCache.html#a3335c1a4ea4d7eb89c6cb586700fadf5">update</a> (self, str prompt, str llm_string, <a class="el" href="namespacelangchain__core_1_1caches.html#aa3548903541b6ec37ba799f25639db3e">RETURN_VAL_TYPE</a> return_val)</td></tr>
<tr class="separator:a3335c1a4ea4d7eb89c6cb586700fadf5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a83eaa6a0dc44cd544664c0c5645c919d"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1caches_1_1BaseCache.html#a83eaa6a0dc44cd544664c0c5645c919d">clear</a> (self, **Any kwargs)</td></tr>
<tr class="separator:a83eaa6a0dc44cd544664c0c5645c919d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04e6028a4dd10d42cdf449f8d102dca5"><td class="memItemLeft" align="right" valign="top">Optional[<a class="el" href="namespacelangchain__core_1_1caches.html#aa3548903541b6ec37ba799f25639db3e">RETURN_VAL_TYPE</a>]&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1caches_1_1BaseCache.html#a04e6028a4dd10d42cdf449f8d102dca5">alookup</a> (self, str prompt, str llm_string)</td></tr>
<tr class="separator:a04e6028a4dd10d42cdf449f8d102dca5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac943d2de654d22552cc513ed1c4275ec"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1caches_1_1BaseCache.html#ac943d2de654d22552cc513ed1c4275ec">aupdate</a> (self, str prompt, str llm_string, <a class="el" href="namespacelangchain__core_1_1caches.html#aa3548903541b6ec37ba799f25639db3e">RETURN_VAL_TYPE</a> return_val)</td></tr>
<tr class="separator:ac943d2de654d22552cc513ed1c4275ec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac37367a24b7754895c67eaada937da6c"><td class="memItemLeft" align="right" valign="top">None&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlangchain__core_1_1caches_1_1BaseCache.html#ac37367a24b7754895c67eaada937da6c">aclear</a> (self, **Any kwargs)</td></tr>
<tr class="separator:ac37367a24b7754895c67eaada937da6c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Interface for a caching layer for LLMs and Chat models.

The cache interface consists of the following methods:

- lookup: Look up a value based on a prompt and llm_string.
- update: Update the cache based on a prompt and llm_string.
- clear: Clear the cache.

In addition, the cache interface provides an async version of each method.

The default implementation of the async methods is to run the synchronous
method in an executor. It's recommended to override the async methods
and provide async implementations to avoid unnecessary overhead.
</pre> </div><h2 class="groupheader">Member Function Documentation</h2>
<a id="ac37367a24b7754895c67eaada937da6c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac37367a24b7754895c67eaada937da6c">&#9670;&nbsp;</a></span>aclear()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None langchain_core.caches.BaseCache.aclear </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Async clear cache that can take additional keyword arguments.</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1caches_1_1InMemoryCache.html#ae9da53111fd6db5d96c068a807b4194d">langchain_core.caches.InMemoryCache</a>.</p>

</div>
</div>
<a id="a04e6028a4dd10d42cdf449f8d102dca5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a04e6028a4dd10d42cdf449f8d102dca5">&#9670;&nbsp;</a></span>alookup()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Optional[<a class="el" href="namespacelangchain__core_1_1caches.html#aa3548903541b6ec37ba799f25639db3e">RETURN_VAL_TYPE</a>] langchain_core.caches.BaseCache.alookup </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>prompt</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>llm_string</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Async look up based on prompt and llm_string.

A cache implementation is expected to generate a key from the 2-tuple
of prompt and llm_string (e.g., by concatenating them with a delimiter).

Args:
    prompt: a string representation of the prompt.
        In the case of a Chat model, the prompt is a non-trivial
        serialization of the prompt into the language model.
    llm_string: A string representation of the LLM configuration.
        This is used to capture the invocation parameters of the LLM
        (e.g., model name, temperature, stop tokens, max tokens, etc.).
        These invocation parameters are serialized into a string
        representation.

Returns:
    On a cache miss, return None. On a cache hit, return the cached value.
    The cached value is a list of Generations (or subclasses).
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1caches_1_1InMemoryCache.html#a908db4b3ecbab886c659213ef60494af">langchain_core.caches.InMemoryCache</a>.</p>

</div>
</div>
<a id="ac943d2de654d22552cc513ed1c4275ec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac943d2de654d22552cc513ed1c4275ec">&#9670;&nbsp;</a></span>aupdate()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None langchain_core.caches.BaseCache.aupdate </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>prompt</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>llm_string</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacelangchain__core_1_1caches.html#aa3548903541b6ec37ba799f25639db3e">RETURN_VAL_TYPE</a>
    &#160;</td>
          <td class="paramname"><em>return_val</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Async update cache based on prompt and llm_string.

The prompt and llm_string are used to generate a key for the cache.
The key should match that of the look up method.

Args:
    prompt: a string representation of the prompt.
        In the case of a Chat model, the prompt is a non-trivial
        serialization of the prompt into the language model.
    llm_string: A string representation of the LLM configuration.
        This is used to capture the invocation parameters of the LLM
        (e.g., model name, temperature, stop tokens, max tokens, etc.).
        These invocation parameters are serialized into a string
        representation.
    return_val: The value to be cached. The value is a list of Generations
        (or subclasses).
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1caches_1_1InMemoryCache.html#a7e32d3d4f861bb10615c81a27984e57c">langchain_core.caches.InMemoryCache</a>.</p>

</div>
</div>
<a id="a83eaa6a0dc44cd544664c0c5645c919d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83eaa6a0dc44cd544664c0c5645c919d">&#9670;&nbsp;</a></span>clear()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None langchain_core.caches.BaseCache.clear </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**Any&#160;</td>
          <td class="paramname"><em>kwargs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Clear cache that can take additional keyword arguments.</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1caches_1_1InMemoryCache.html#a0404dafd7aa44a63adb0c61cde4b3275">langchain_core.caches.InMemoryCache</a>.</p>

</div>
</div>
<a id="a063a47e2ffb6060b79eaf00c51adbf11"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a063a47e2ffb6060b79eaf00c51adbf11">&#9670;&nbsp;</a></span>lookup()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> Optional[<a class="el" href="namespacelangchain__core_1_1caches.html#aa3548903541b6ec37ba799f25639db3e">RETURN_VAL_TYPE</a>] langchain_core.caches.BaseCache.lookup </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>prompt</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>llm_string</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Look up based on prompt and llm_string.

A cache implementation is expected to generate a key from the 2-tuple
of prompt and llm_string (e.g., by concatenating them with a delimiter).

Args:
    prompt: a string representation of the prompt.
        In the case of a Chat model, the prompt is a non-trivial
        serialization of the prompt into the language model.
    llm_string: A string representation of the LLM configuration.
        This is used to capture the invocation parameters of the LLM
        (e.g., model name, temperature, stop tokens, max tokens, etc.).
        These invocation parameters are serialized into a string
        representation.

Returns:
    On a cache miss, return None. On a cache hit, return the cached value.
    The cached value is a list of Generations (or subclasses).
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1caches_1_1InMemoryCache.html#a87ac55c55b22486b2074d218700099c3">langchain_core.caches.InMemoryCache</a>.</p>

</div>
</div>
<a id="a3335c1a4ea4d7eb89c6cb586700fadf5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3335c1a4ea4d7eb89c6cb586700fadf5">&#9670;&nbsp;</a></span>update()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"> None langchain_core.caches.BaseCache.update </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>prompt</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str&#160;</td>
          <td class="paramname"><em>llm_string</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacelangchain__core_1_1caches.html#aa3548903541b6ec37ba799f25639db3e">RETURN_VAL_TYPE</a>&#160;</td>
          <td class="paramname"><em>return_val</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update cache based on prompt and llm_string.

The prompt and llm_string are used to generate a key for the cache.
The key should match that of the lookup method.

Args:
    prompt: a string representation of the prompt.
        In the case of a Chat model, the prompt is a non-trivial
        serialization of the prompt into the language model.
    llm_string: A string representation of the LLM configuration.
        This is used to capture the invocation parameters of the LLM
        (e.g., model name, temperature, stop tokens, max tokens, etc.).
        These invocation parameters are serialized into a string
        representation.
    return_val: The value to be cached. The value is a list of Generations
        (or subclasses).
</pre> 
<p>Reimplemented in <a class="el" href="classlangchain__core_1_1caches_1_1InMemoryCache.html#a666a923adca9d399a272f0cc357d6300">langchain_core.caches.InMemoryCache</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>py3_env/lib/python3.10/site-packages/langchain_core/<a class="el" href="caches_8py.html">caches.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
