<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NAO Virtual Storyteller: onnxruntime.capi.onnxruntime_inference_collection.OrtValue Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NAO Virtual Storyteller
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceonnxruntime.html">onnxruntime</a></li><li class="navelem"><a class="el" href="namespaceonnxruntime_1_1capi.html">capi</a></li><li class="navelem"><a class="el" href="namespaceonnxruntime_1_1capi_1_1onnxruntime__inference__collection.html">onnxruntime_inference_collection</a></li><li class="navelem"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html">OrtValue</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">onnxruntime.capi.onnxruntime_inference_collection.OrtValue Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a592c41333386596c8fee5a0c877a2d23"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a592c41333386596c8fee5a0c877a2d23">__init__</a> (self, ortvalue, numpy_obj=None)</td></tr>
<tr class="separator:a592c41333386596c8fee5a0c877a2d23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9886e8493ca629b5c8edec6979967de7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a9886e8493ca629b5c8edec6979967de7">as_sparse_tensor</a> (self)</td></tr>
<tr class="separator:a9886e8493ca629b5c8edec6979967de7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0cc16a6bfcd96cfae06b5d2b1db2542"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#ae0cc16a6bfcd96cfae06b5d2b1db2542">data_ptr</a> (self)</td></tr>
<tr class="separator:ae0cc16a6bfcd96cfae06b5d2b1db2542"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a510f6af29326dc0b2c96ef37a1fccc27"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a510f6af29326dc0b2c96ef37a1fccc27">device_name</a> (self)</td></tr>
<tr class="separator:a510f6af29326dc0b2c96ef37a1fccc27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb4e6f91212eca062ee54fd1180f61ad"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#afb4e6f91212eca062ee54fd1180f61ad">shape</a> (self)</td></tr>
<tr class="separator:afb4e6f91212eca062ee54fd1180f61ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae97df1ce6a10e7c62a9ba384fe4bc12c"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#ae97df1ce6a10e7c62a9ba384fe4bc12c">data_type</a> (self)</td></tr>
<tr class="separator:ae97df1ce6a10e7c62a9ba384fe4bc12c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88bfdc5b3ee250caa919841fc5849d8d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a88bfdc5b3ee250caa919841fc5849d8d">element_type</a> (self)</td></tr>
<tr class="separator:a88bfdc5b3ee250caa919841fc5849d8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92299e660369a907d7b669c808916f93"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a92299e660369a907d7b669c808916f93">has_value</a> (self)</td></tr>
<tr class="separator:a92299e660369a907d7b669c808916f93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77bb34ea423b3a40e0bd109b7c9fc10b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a77bb34ea423b3a40e0bd109b7c9fc10b">is_tensor</a> (self)</td></tr>
<tr class="separator:a77bb34ea423b3a40e0bd109b7c9fc10b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aede8d0123c10b417026aa307155c5aad"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#aede8d0123c10b417026aa307155c5aad">is_sparse_tensor</a> (self)</td></tr>
<tr class="separator:aede8d0123c10b417026aa307155c5aad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85cc6f77715f9e2df8e6cf54adb52eaa"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a85cc6f77715f9e2df8e6cf54adb52eaa">is_tensor_sequence</a> (self)</td></tr>
<tr class="separator:a85cc6f77715f9e2df8e6cf54adb52eaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00cc1797ee22d5ce7bbaaf317807fff7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a00cc1797ee22d5ce7bbaaf317807fff7">numpy</a> (self)</td></tr>
<tr class="separator:a00cc1797ee22d5ce7bbaaf317807fff7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04729b99e56836029536258fdcad7158"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a04729b99e56836029536258fdcad7158">update_inplace</a> (self, np_arr)</td></tr>
<tr class="separator:a04729b99e56836029536258fdcad7158"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a592c41333386596c8fee5a0c877a2d23"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a592c41333386596c8fee5a0c877a2d23">__init__</a> (self, ortvalue, numpy_obj=None)</td></tr>
<tr class="separator:a592c41333386596c8fee5a0c877a2d23"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9886e8493ca629b5c8edec6979967de7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a9886e8493ca629b5c8edec6979967de7">as_sparse_tensor</a> (self)</td></tr>
<tr class="separator:a9886e8493ca629b5c8edec6979967de7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0cc16a6bfcd96cfae06b5d2b1db2542"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#ae0cc16a6bfcd96cfae06b5d2b1db2542">data_ptr</a> (self)</td></tr>
<tr class="separator:ae0cc16a6bfcd96cfae06b5d2b1db2542"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a510f6af29326dc0b2c96ef37a1fccc27"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a510f6af29326dc0b2c96ef37a1fccc27">device_name</a> (self)</td></tr>
<tr class="separator:a510f6af29326dc0b2c96ef37a1fccc27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afb4e6f91212eca062ee54fd1180f61ad"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#afb4e6f91212eca062ee54fd1180f61ad">shape</a> (self)</td></tr>
<tr class="separator:afb4e6f91212eca062ee54fd1180f61ad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae97df1ce6a10e7c62a9ba384fe4bc12c"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#ae97df1ce6a10e7c62a9ba384fe4bc12c">data_type</a> (self)</td></tr>
<tr class="separator:ae97df1ce6a10e7c62a9ba384fe4bc12c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a88bfdc5b3ee250caa919841fc5849d8d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a88bfdc5b3ee250caa919841fc5849d8d">element_type</a> (self)</td></tr>
<tr class="separator:a88bfdc5b3ee250caa919841fc5849d8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a92299e660369a907d7b669c808916f93"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a92299e660369a907d7b669c808916f93">has_value</a> (self)</td></tr>
<tr class="separator:a92299e660369a907d7b669c808916f93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a77bb34ea423b3a40e0bd109b7c9fc10b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a77bb34ea423b3a40e0bd109b7c9fc10b">is_tensor</a> (self)</td></tr>
<tr class="separator:a77bb34ea423b3a40e0bd109b7c9fc10b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aede8d0123c10b417026aa307155c5aad"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#aede8d0123c10b417026aa307155c5aad">is_sparse_tensor</a> (self)</td></tr>
<tr class="separator:aede8d0123c10b417026aa307155c5aad"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85cc6f77715f9e2df8e6cf54adb52eaa"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a85cc6f77715f9e2df8e6cf54adb52eaa">is_tensor_sequence</a> (self)</td></tr>
<tr class="separator:a85cc6f77715f9e2df8e6cf54adb52eaa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a00cc1797ee22d5ce7bbaaf317807fff7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a00cc1797ee22d5ce7bbaaf317807fff7">numpy</a> (self)</td></tr>
<tr class="separator:a00cc1797ee22d5ce7bbaaf317807fff7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04729b99e56836029536258fdcad7158"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a04729b99e56836029536258fdcad7158">update_inplace</a> (self, np_arr)</td></tr>
<tr class="separator:a04729b99e56836029536258fdcad7158"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:a20435928a071ad8a2c4cdb4b1dace854"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a20435928a071ad8a2c4cdb4b1dace854">ortvalue_from_numpy</a> (numpy_obj, device_type=&quot;cpu&quot;, device_id=0)</td></tr>
<tr class="separator:a20435928a071ad8a2c4cdb4b1dace854"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15066b95013d547da1fa05365b761d9b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a15066b95013d547da1fa05365b761d9b">ortvalue_from_numpy_with_onnx_type</a> (data, int onnx_element_type)</td></tr>
<tr class="separator:a15066b95013d547da1fa05365b761d9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3df7caefef0586f9784c8039740346c7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a3df7caefef0586f9784c8039740346c7">ortvalue_from_shape_and_type</a> (<a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#afb4e6f91212eca062ee54fd1180f61ad">shape</a>, <a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a88bfdc5b3ee250caa919841fc5849d8d">element_type</a>, str device_type=&quot;cpu&quot;, int device_id=0)</td></tr>
<tr class="separator:a3df7caefef0586f9784c8039740346c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d27f7bf814b1f2a2829f5eb4bffe26a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a7d27f7bf814b1f2a2829f5eb4bffe26a">ort_value_from_sparse_tensor</a> (sparse_tensor)</td></tr>
<tr class="separator:a7d27f7bf814b1f2a2829f5eb4bffe26a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20435928a071ad8a2c4cdb4b1dace854"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a20435928a071ad8a2c4cdb4b1dace854">ortvalue_from_numpy</a> (numpy_obj, device_type=&quot;cpu&quot;, device_id=0)</td></tr>
<tr class="separator:a20435928a071ad8a2c4cdb4b1dace854"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a15066b95013d547da1fa05365b761d9b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a15066b95013d547da1fa05365b761d9b">ortvalue_from_numpy_with_onnx_type</a> (data, int onnx_element_type)</td></tr>
<tr class="separator:a15066b95013d547da1fa05365b761d9b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3df7caefef0586f9784c8039740346c7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a3df7caefef0586f9784c8039740346c7">ortvalue_from_shape_and_type</a> (<a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#afb4e6f91212eca062ee54fd1180f61ad">shape</a>, <a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a88bfdc5b3ee250caa919841fc5849d8d">element_type</a>, str device_type=&quot;cpu&quot;, int device_id=0)</td></tr>
<tr class="separator:a3df7caefef0586f9784c8039740346c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d27f7bf814b1f2a2829f5eb4bffe26a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1capi_1_1onnxruntime__inference__collection_1_1OrtValue.html#a7d27f7bf814b1f2a2829f5eb4bffe26a">ort_value_from_sparse_tensor</a> (sparse_tensor)</td></tr>
<tr class="separator:a7d27f7bf814b1f2a2829f5eb4bffe26a"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">A data structure that supports all ONNX data formats (tensors and non-tensors) that allows users
to place the data backing these on a device, for example, on a CUDA supported device.
This class provides APIs to construct and deal with OrtValues.
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a592c41333386596c8fee5a0c877a2d23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a592c41333386596c8fee5a0c877a2d23">&#9670;&nbsp;</a></span>__init__() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ortvalue</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>numpy_obj</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a592c41333386596c8fee5a0c877a2d23"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a592c41333386596c8fee5a0c877a2d23">&#9670;&nbsp;</a></span>__init__() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ortvalue</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>numpy_obj</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a9886e8493ca629b5c8edec6979967de7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9886e8493ca629b5c8edec6979967de7">&#9670;&nbsp;</a></span>as_sparse_tensor() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.as_sparse_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">The function will return SparseTensor contained in this OrtValue
</pre> 
</div>
</div>
<a id="a9886e8493ca629b5c8edec6979967de7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9886e8493ca629b5c8edec6979967de7">&#9670;&nbsp;</a></span>as_sparse_tensor() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.as_sparse_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">The function will return SparseTensor contained in this OrtValue
</pre> 
</div>
</div>
<a id="ae0cc16a6bfcd96cfae06b5d2b1db2542"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae0cc16a6bfcd96cfae06b5d2b1db2542">&#9670;&nbsp;</a></span>data_ptr() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.data_ptr </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the address of the first element in the OrtValue's data buffer
</pre> 
</div>
</div>
<a id="ae0cc16a6bfcd96cfae06b5d2b1db2542"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae0cc16a6bfcd96cfae06b5d2b1db2542">&#9670;&nbsp;</a></span>data_ptr() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.data_ptr </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the address of the first element in the OrtValue's data buffer
</pre> 
</div>
</div>
<a id="ae97df1ce6a10e7c62a9ba384fe4bc12c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae97df1ce6a10e7c62a9ba384fe4bc12c">&#9670;&nbsp;</a></span>data_type() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.data_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the data type of the data in the OrtValue
</pre> 
</div>
</div>
<a id="ae97df1ce6a10e7c62a9ba384fe4bc12c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae97df1ce6a10e7c62a9ba384fe4bc12c">&#9670;&nbsp;</a></span>data_type() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.data_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the data type of the data in the OrtValue
</pre> 
</div>
</div>
<a id="a510f6af29326dc0b2c96ef37a1fccc27"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a510f6af29326dc0b2c96ef37a1fccc27">&#9670;&nbsp;</a></span>device_name() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.device_name </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the name of the device where the OrtValue's data buffer resides e.g. cpu, cuda, cann
</pre> 
</div>
</div>
<a id="a510f6af29326dc0b2c96ef37a1fccc27"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a510f6af29326dc0b2c96ef37a1fccc27">&#9670;&nbsp;</a></span>device_name() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.device_name </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the name of the device where the OrtValue's data buffer resides e.g. cpu, cuda, cann
</pre> 
</div>
</div>
<a id="a88bfdc5b3ee250caa919841fc5849d8d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a88bfdc5b3ee250caa919841fc5849d8d">&#9670;&nbsp;</a></span>element_type() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.element_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the proto type of the data in the OrtValue
if the OrtValue is a tensor.
</pre> 
</div>
</div>
<a id="a88bfdc5b3ee250caa919841fc5849d8d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a88bfdc5b3ee250caa919841fc5849d8d">&#9670;&nbsp;</a></span>element_type() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.element_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the proto type of the data in the OrtValue
if the OrtValue is a tensor.
</pre> 
</div>
</div>
<a id="a92299e660369a907d7b669c808916f93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a92299e660369a907d7b669c808916f93">&#9670;&nbsp;</a></span>has_value() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.has_value </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns True if the OrtValue corresponding to an
optional type contains data, else returns False
</pre> 
</div>
</div>
<a id="a92299e660369a907d7b669c808916f93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a92299e660369a907d7b669c808916f93">&#9670;&nbsp;</a></span>has_value() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.has_value </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns True if the OrtValue corresponding to an
optional type contains data, else returns False
</pre> 
</div>
</div>
<a id="aede8d0123c10b417026aa307155c5aad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aede8d0123c10b417026aa307155c5aad">&#9670;&nbsp;</a></span>is_sparse_tensor() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.is_sparse_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns True if the OrtValue contains a SparseTensor, else returns False
</pre> 
</div>
</div>
<a id="aede8d0123c10b417026aa307155c5aad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aede8d0123c10b417026aa307155c5aad">&#9670;&nbsp;</a></span>is_sparse_tensor() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.is_sparse_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns True if the OrtValue contains a SparseTensor, else returns False
</pre> 
</div>
</div>
<a id="a77bb34ea423b3a40e0bd109b7c9fc10b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a77bb34ea423b3a40e0bd109b7c9fc10b">&#9670;&nbsp;</a></span>is_tensor() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.is_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns True if the OrtValue contains a Tensor, else returns False
</pre> 
</div>
</div>
<a id="a77bb34ea423b3a40e0bd109b7c9fc10b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a77bb34ea423b3a40e0bd109b7c9fc10b">&#9670;&nbsp;</a></span>is_tensor() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.is_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns True if the OrtValue contains a Tensor, else returns False
</pre> 
</div>
</div>
<a id="a85cc6f77715f9e2df8e6cf54adb52eaa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85cc6f77715f9e2df8e6cf54adb52eaa">&#9670;&nbsp;</a></span>is_tensor_sequence() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.is_tensor_sequence </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns True if the OrtValue contains a Tensor Sequence, else returns False
</pre> 
</div>
</div>
<a id="a85cc6f77715f9e2df8e6cf54adb52eaa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85cc6f77715f9e2df8e6cf54adb52eaa">&#9670;&nbsp;</a></span>is_tensor_sequence() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.is_tensor_sequence </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns True if the OrtValue contains a Tensor Sequence, else returns False
</pre> 
</div>
</div>
<a id="a00cc1797ee22d5ce7bbaaf317807fff7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a00cc1797ee22d5ce7bbaaf317807fff7">&#9670;&nbsp;</a></span>numpy() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.numpy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns a Numpy object from the OrtValue.
Valid only for OrtValues holding Tensors. Throws for OrtValues holding non-Tensors.
Use accessors to gain a reference to non-Tensor objects such as SparseTensor
</pre> 
</div>
</div>
<a id="a00cc1797ee22d5ce7bbaaf317807fff7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a00cc1797ee22d5ce7bbaaf317807fff7">&#9670;&nbsp;</a></span>numpy() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.numpy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns a Numpy object from the OrtValue.
Valid only for OrtValues holding Tensors. Throws for OrtValues holding non-Tensors.
Use accessors to gain a reference to non-Tensor objects such as SparseTensor
</pre> 
</div>
</div>
<a id="a7d27f7bf814b1f2a2829f5eb4bffe26a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d27f7bf814b1f2a2829f5eb4bffe26a">&#9670;&nbsp;</a></span>ort_value_from_sparse_tensor() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.ort_value_from_sparse_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sparse_tensor</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">The function will construct an OrtValue instance from a valid SparseTensor
The new instance of OrtValue will assume the ownership of sparse_tensor
</pre> 
</div>
</div>
<a id="a7d27f7bf814b1f2a2829f5eb4bffe26a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d27f7bf814b1f2a2829f5eb4bffe26a">&#9670;&nbsp;</a></span>ort_value_from_sparse_tensor() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.ort_value_from_sparse_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>sparse_tensor</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">The function will construct an OrtValue instance from a valid SparseTensor
The new instance of OrtValue will assume the ownership of sparse_tensor
</pre> 
</div>
</div>
<a id="a20435928a071ad8a2c4cdb4b1dace854"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20435928a071ad8a2c4cdb4b1dace854">&#9670;&nbsp;</a></span>ortvalue_from_numpy() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.ortvalue_from_numpy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>numpy_obj</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device_type</em> = <code>&quot;cpu&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device_id</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Factory method to construct an OrtValue (which holds a Tensor) from a given Numpy object
A copy of the data in the Numpy object is held by the OrtValue only if the device is NOT cpu

:param numpy_obj: The Numpy object to construct the OrtValue from
:param device_type: e.g. cpu, cuda, cann, cpu by default
:param device_id: device id, e.g. 0
</pre> 
</div>
</div>
<a id="a20435928a071ad8a2c4cdb4b1dace854"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20435928a071ad8a2c4cdb4b1dace854">&#9670;&nbsp;</a></span>ortvalue_from_numpy() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.ortvalue_from_numpy </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>numpy_obj</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device_type</em> = <code>&quot;cpu&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>device_id</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Factory method to construct an OrtValue (which holds a Tensor) from a given Numpy object
A copy of the data in the Numpy object is held by the OrtValue only if the device is NOT cpu

:param numpy_obj: The Numpy object to construct the OrtValue from
:param device_type: e.g. cpu, cuda, cann, cpu by default
:param device_id: device id, e.g. 0
</pre> 
</div>
</div>
<a id="a15066b95013d547da1fa05365b761d9b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a15066b95013d547da1fa05365b761d9b">&#9670;&nbsp;</a></span>ortvalue_from_numpy_with_onnx_type() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.ortvalue_from_numpy_with_onnx_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>onnx_element_type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">This method creates an instance of OrtValue on top of the numpy array.
No data copy is made and the lifespan of the resulting OrtValue should never
exceed the lifespan of bytes object. The API attempts to reinterpret
the data type which is expected to be the same size. This is useful
when we want to use an ONNX data type that is not supported by numpy.

:param data: numpy.ndarray.
:param onnx_elemenet_type: a valid onnx TensorProto::DataType enum value
</pre> 
</div>
</div>
<a id="a15066b95013d547da1fa05365b761d9b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a15066b95013d547da1fa05365b761d9b">&#9670;&nbsp;</a></span>ortvalue_from_numpy_with_onnx_type() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.ortvalue_from_numpy_with_onnx_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>onnx_element_type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">This method creates an instance of OrtValue on top of the numpy array.
No data copy is made and the lifespan of the resulting OrtValue should never
exceed the lifespan of bytes object. The API attempts to reinterpret
the data type which is expected to be the same size. This is useful
when we want to use an ONNX data type that is not supported by numpy.

:param data: numpy.ndarray.
:param onnx_elemenet_type: a valid onnx TensorProto::DataType enum value
</pre> 
</div>
</div>
<a id="a3df7caefef0586f9784c8039740346c7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3df7caefef0586f9784c8039740346c7">&#9670;&nbsp;</a></span>ortvalue_from_shape_and_type() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.ortvalue_from_shape_and_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>element_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>device_type</em> = <code>&quot;cpu&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>device_id</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Factory method to construct an OrtValue (which holds a Tensor) from given shape and element_type

:param shape: List of integers indicating the shape of the OrtValue
:param element_type: The data type of the elements. It can be either numpy type (like numpy.float32) or an integer for onnx type (like onnx.TensorProto.BFLOAT16).
:param device_type: e.g. cpu, cuda, cann, cpu by default
:param device_id: device id, e.g. 0
</pre> 
</div>
</div>
<a id="a3df7caefef0586f9784c8039740346c7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3df7caefef0586f9784c8039740346c7">&#9670;&nbsp;</a></span>ortvalue_from_shape_and_type() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.ortvalue_from_shape_and_type </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>element_type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">str &#160;</td>
          <td class="paramname"><em>device_type</em> = <code>&quot;cpu&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int &#160;</td>
          <td class="paramname"><em>device_id</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Factory method to construct an OrtValue (which holds a Tensor) from given shape and element_type

:param shape: List of integers indicating the shape of the OrtValue
:param element_type: The data type of the elements. It can be either numpy type (like numpy.float32) or an integer for onnx type (like onnx.TensorProto.BFLOAT16).
:param device_type: e.g. cpu, cuda, cann, cpu by default
:param device_id: device id, e.g. 0
</pre> 
</div>
</div>
<a id="afb4e6f91212eca062ee54fd1180f61ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afb4e6f91212eca062ee54fd1180f61ad">&#9670;&nbsp;</a></span>shape() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.shape </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the shape of the data in the OrtValue
</pre> 
</div>
</div>
<a id="afb4e6f91212eca062ee54fd1180f61ad"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afb4e6f91212eca062ee54fd1180f61ad">&#9670;&nbsp;</a></span>shape() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.shape </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the shape of the data in the OrtValue
</pre> 
</div>
</div>
<a id="a04729b99e56836029536258fdcad7158"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a04729b99e56836029536258fdcad7158">&#9670;&nbsp;</a></span>update_inplace() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.update_inplace </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>np_arr</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update the OrtValue in place with a new Numpy array. The numpy contents
are copied over to the device memory backing the OrtValue. It can be used
to update the input valuess for an InferenceSession with CUDA graph
enabled or other scenarios where the OrtValue needs to be updated while
the memory address can not be changed.
</pre> 
</div>
</div>
<a id="a04729b99e56836029536258fdcad7158"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a04729b99e56836029536258fdcad7158">&#9670;&nbsp;</a></span>update_inplace() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def onnxruntime.capi.onnxruntime_inference_collection.OrtValue.update_inplace </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>np_arr</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update the OrtValue in place with a new Numpy array. The numpy contents
are copied over to the device memory backing the OrtValue. It can be used
to update the input valuess for an InferenceSession with CUDA graph
enabled or other scenarios where the OrtValue needs to be updated while
the memory address can not be changed.
</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>chromadb_rest_wrapper/venv/lib/python3.10/site-packages/onnxruntime/capi/<a class="el" href="chromadb__rest__wrapper_2venv_2lib_2python3_810_2site-packages_2onnxruntime_2capi_2onnxruntime__inference__collection_8py.html">onnxruntime_inference_collection.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
